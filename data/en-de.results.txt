===============================
====Annotation (`annoID` = 4257)====
text: So I have a big interest in education, and I think we all do.
frameName: Awareness
frameID: 14
luName: think.v
luID: 12780
lu_idx: [(45, 49, 1)]
fe_idx: [(43, 43, 'Cognizer', 57), (51, 59, 'Content', 58)]
tokenized_text: So I have a big interest in education , and I think we all do .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'think.v', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Awareness', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Cognizer', '-', 'Content', 'Content', 'Content', '-']

====Annotation (`annoID` = 10790)====
text: Ich habe ein großes Interesse an Bildung, und ich denke, das haben wir alle.
frameName: Cogitation
frameID: 17
luName: denken.v
luID: 29776
lu_idx: [(50, 54, 1577)]
fe_idx: [(57, 74, 'Topic', 71), (46, 48, 'Cognizer', 70)]
tokenized_text: Ich habe ein großes Interesse an Bildung , und ich denke , das haben wir alle .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'denken.v', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Cogitation', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', 'Cognizer', '-', '-', 'Topic', 'Topic', 'Topic', 'Topic', '-']

===============================
====Annotation (`annoID` = 2553)====
text: My contention is that creativity now is as important in education as literacy, and we should treat it with the same status.
frameName: Statement
frameID: 37
luName: contention.n
luID: 13378
lu_idx: [(3, 12, 1)]
fe_idx: [(17, 121, 'Message', 154), (0, 1, 'Speaker', 152)]
tokenized_text: My contention is that creativity now is as important in education as literacy , and we should treat it with the same status .
tokenized_lu_idx: ['-', 'contention.n', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', 'Statement', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['Speaker', '-', '-', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', '-']

====Annotation (`annoID` = 9316)====
text: Meine Überzeugung ist, dass Kreativität heute genauso wichtig für Bildung ist, wie Lesen und Schreiben, und wir sollten sie gleichwertig behandeln.
frameName: Opinion
frameID: 642
luName: überzeugung.n
luID: 29520
lu_idx: [(6, 16, 1577)]
fe_idx: [(0, 4, 'Cognizer', 5228), (23, 101, 'Opinion', 5229)]
tokenized_text: Meine Überzeugung ist , dass Kreativität heute genauso wichtig für Bildung ist , wie Lesen und Schreiben , und wir sollten sie gleichwertig behandeln .
tokenized_lu_idx: ['-', 'überzeugung.n', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', 'Opinion', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['Cognizer', '-', '-', '-', 'Opinion', 'Opinion', 'Opinion', 'Opinion', 'Opinion', 'Opinion', 'Opinion', 'Opinion', 'Opinion', 'Opinion', 'Opinion', 'Opinion', 'Opinion', '-', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 2439)====
text: Because it's one of those things that goes deep with people, am I right?
frameName: Causation
frameID: 1
luName: because.c
luID: 12518
lu_idx: [(0, 6, 1)]
fe_idx: [(8, 58, 'Cause', 3), (-1, -1, 'Effect', 5)]
tokenized_text: Because it 's one of those things that goes deep with people , am I right ?
tokenized_lu_idx: ['because.c', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['Causation', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', 'Cause', 'Cause', 'Cause', 'Cause', 'Cause', 'Cause', 'Cause', 'Cause', 'Cause', 'Cause', 'Cause', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 9900)====
text: Denn es ist eines dieser Themen, die Leute tief berühren, wie Religion, Geld und andere Sachen.
frameName: Reason
frameID: 417
luName: denn.adv
luID: 29798
lu_idx: [(0, 3, 1577)]
fe_idx: [(5, 93, 'State_of_affairs', 3094)]
tokenized_text: Denn es ist eines dieser Themen , die Leute tief berühren , wie Religion , Geld und andere Sachen .
tokenized_lu_idx: ['denn.adv', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['Reason', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', 'State_of_affairs', 'State_of_affairs', 'State_of_affairs', 'State_of_affairs', 'State_of_affairs', 'State_of_affairs', 'State_of_affairs', 'State_of_affairs', 'State_of_affairs', 'State_of_affairs', 'State_of_affairs', 'State_of_affairs', 'State_of_affairs', 'State_of_affairs', 'State_of_affairs', 'State_of_affairs', 'State_of_affairs', 'State_of_affairs', '-']

===============================
====Annotation (`annoID` = 2546)====
text: But if you are, and you say to somebody, you know, they say, 'What do you do?'and you say you work in education, you can see the blood run from their face.
frameName: Statement
frameID: 37
luName: say.v
luID: 13406
lu_idx: [(24, 26, 1)]
fe_idx: [(28, 38, 'Addressee', 153), (20, 22, 'Speaker', 152), (-1, -1, 'Message', 154)]
tokenized_text: But if you are , and you say to somebody , you know , they say , ' What do you do ?' and you say you work in education , you can see the blood run from their face .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', 'say.v', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', 'Statement', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', 'Speaker', '-', 'Addressee', 'Addressee', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 10377)====
text: Sind Sie aber eingeladen und reden mit jemandem, also wenn jemand fragt: 'Was machen Sie so?'und Sie: 'Ich arbeite im Bildungswesen', sieht man, wie den anderen das Blut aus dem Gesicht weicht.
frameName: Chatting
frameID: 477
luName: reden mit.v
luID: 29857
lu_idx: [(35, 37, 1577), (29, 33, 1577)]
fe_idx: [(5, 7, 'Interlocutor_1', 3863), (39, 46, 'Interlocutor_2', 3864)]
tokenized_text: Sind Sie aber eingeladen und reden mit jemandem , also wenn jemand fragt : ' Was machen Sie so ?' und Sie : ' Ich arbeite im Bildungswesen ' , sieht man , wie den anderen das Blut aus dem Gesicht weicht .
tokenized_lu_idx: ['-', '-', '-', '-', '-', 'reden mit.v', 'reden mit.v', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', 'Chatting', 'Chatting', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', 'Interlocutor_1', '-', '-', '-', '-', '-', 'Interlocutor_2', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 2558)====
text: She went over to her, and she said, 'What are you drawing?'
frameName: Statement
frameID: 37
luName: say.v
luID: 13406
lu_idx: [(30, 33, 1)]
fe_idx: [(37, 56, 'Message', 154), (26, 28, 'Speaker', 152)]
tokenized_text: She went over to her , and she said , ' What are you drawing ? '
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', 'say.v', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', 'Statement', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', 'Speaker', '-', '-', '-', 'Message', 'Message', 'Message', 'Message', '-', '-']

====Annotation (`annoID` = 9336)====
text: Die Lehrerin war fasziniert, ging zu ihr herüber und fragte: 'Was malst du denn da?'
frameName: Questioning
frameID: 34
luName: fragen.v
luID: 29491
lu_idx: [(53, 58, 1577)]
fe_idx: [(0, 11, 'Speaker', 136), (61, 83, 'Message', 138)]
tokenized_text: Die Lehrerin war fasziniert , ging zu ihr herüber und fragte : ' Was malst du denn da ? '
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'fragen.v', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Questioning', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['Speaker', 'Speaker', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message']

===============================
====Annotation (`annoID` = 4285)====
text: My contention is that creativity now is as important in education as literacy, and we should treat it with the same status.
frameName: Reading_perception
frameID: 254
luName: literacy.n
luID: 27221
lu_idx: [(69, 76, 1)]
fe_idx: [(-1, -1, 'Text', 1669), (-1, -1, 'Reader', 1668)]
tokenized_text: My contention is that creativity now is as important in education as literacy , and we should treat it with the same status .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'literacy.n', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Reading_perception', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 10804)====
text: Meine Überzeugung ist, dass Kreativität heute genauso wichtig für Bildung ist, wie Lesen und Schreiben, und wir sollten sie gleichwertig behandeln.
frameName: Reading_activity
frameID: 1177
luName: lesen.n
luID: 30035
lu_idx: [(83, 87, 1577)]
fe_idx: []
tokenized_text: Meine Überzeugung ist , dass Kreativität heute genauso wichtig für Bildung ist , wie Lesen und Schreiben , und wir sollten sie gleichwertig behandeln .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'lesen.n', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Reading_activity', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 2506)====
text: What you have there is a person of extraordinary dedication who found a talent.
frameName: Have_associated
frameID: 866
luName: have.v
luID: 24887
lu_idx: [(9, 12, 1)]
fe_idx: [(0, 3, 'Entity', 7984), (14, 18, 'Place', 7988), (5, 7, 'Topical_entity', 7993)]
tokenized_text: What you have there is a person of extraordinary dedication who found a talent .
tokenized_lu_idx: ['-', '-', 'have.v', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', 'Have_associated', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['Entity', 'Topical_entity', '-', 'Place', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 9720)====
text: Sie ist eine Person mit außerordentlicher Hingabe, die ihr Talent gefunden hat.
frameName: Being_in_category
frameID: 813
luName: sein.v
luID: 29784
lu_idx: [(4, 6, 1577)]
fe_idx: [(0, 2, 'Item', 7395), (8, 48, 'Category', 7396)]
tokenized_text: Sie ist eine Person mit außerordentlicher Hingabe , die ihr Talent gefunden hat .
tokenized_lu_idx: ['-', 'sein.v', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', 'Being_in_category', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['Item', '-', 'Category', 'Category', 'Category', 'Category', 'Category', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 2508)====
text: I have an interest in education.
frameName: Emotion_directed
frameID: 40
luName: interest.n
luID: 13643
lu_idx: [(10, 17, 1)]
fe_idx: [(0, 0, 'Experiencer', 163), (19, 30, 'Stimulus', 165)]
tokenized_text: I have an interest in education .
tokenized_lu_idx: ['-', '-', '-', 'interest.n', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', 'Emotion_directed', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', 'Stimulus', 'Stimulus', '-']

====Annotation (`annoID` = 10373)====
text: Ich interessiere mich für Bildung.
frameName: Experiencer_focus
frameID: 42
luName: interessiere mich.v
luID: 29853
lu_idx: [(17, 20, 1577), (4, 15, 1577)]
fe_idx: [(22, 32, 'Content', 169), (0, 2, 'Experiencer', 168)]
tokenized_text: Ich interessiere mich für Bildung .
tokenized_lu_idx: ['-', 'interessiere mich.v', 'interessiere mich.v', '-', '-', '-']
tokenized_frame_idx: ['-', 'Experiencer_focus', 'Experiencer_focus', '-', '-', '-']
tokenized_fe_idx: ['Experiencer', '-', '-', 'Content', 'Content', '-']

===============================
====Annotation (`annoID` = 4519)====
text: We were sitting there and I think they just went out of sequence, because we talked to the little boy afterward and we said, 'You OK with that?'
frameName: Opinion
frameID: 642
luName: think.v
luID: 23709
lu_idx: [(28, 32, 1)]
fe_idx: [(26, 26, 'Cognizer', 5228), (34, 63, 'Opinion', 5229)]
tokenized_text: We were sitting there and I think they just went out of sequence , because we talked to the little boy afterward and we said , ' You OK with that ? '
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', 'think.v', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', 'Opinion', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', 'Cognizer', '-', 'Opinion', 'Opinion', 'Opinion', 'Opinion', 'Opinion', 'Opinion', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 10780)====
text: Wir saßen da und ich glaube, sie vertauschten die Reihenfolge, weil wir hinterher fragten: 'War das okay für dich?'und er: 'Ja.
frameName: Certainty
frameID: 129
luName: glauben.v
luID: 30016
lu_idx: [(21, 26, 1577)]
fe_idx: [(29, 60, 'Content', 697), (63, 125, 'Explanation', 8228), (17, 19, 'Cognizer', 695)]
tokenized_text: Wir saßen da und ich glaube , sie vertauschten die Reihenfolge , weil wir hinterher fragten : ' War das okay für dich ?' und er : ' Ja .
tokenized_lu_idx: ['-', '-', '-', '-', '-', 'glauben.v', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', 'Certainty', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', 'Cognizer', '-', '-', 'Content', 'Content', 'Content', 'Content', '-', 'Explanation', 'Explanation', 'Explanation', 'Explanation', 'Explanation', 'Explanation', 'Explanation', 'Explanation', 'Explanation', 'Explanation', 'Explanation', 'Explanation', 'Explanation', 'Explanation', 'Explanation', 'Explanation', 'Explanation', '-']

===============================
====Annotation (`annoID` = 4396)====
text: The second is that it's put us in a place where we have no idea what's going to happen, in terms of the future.
frameName: Placing
frameID: 56
luName: put.v
luID: 14284
lu_idx: [(24, 26, 1)]
fe_idx: [(28, 29, 'Theme', 236), (19, 20, 'Cause', 1306), (31, 40, 'Goal', 239), (42, 46, 'Goal', 239)]
tokenized_text: The second is that it 's put us in a place where we have no idea what 's going to happen , in terms of the future .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', 'put.v', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', 'Placing', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', 'Cause', '-', '-', 'Theme', 'Goal', 'Goal', 'Goal', 'Goal', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 9159)====
text: Zweitens befinden wir uns an einem Punkt, an dem wir keine Ahnung haben, wie es in Zukunft weitergeht.
frameName: Being_located
frameID: 481
luName: sich an einem Punkt befinden.v
luID: 29368
lu_idx: [(35, 39, 1577), (26, 27, 1577), (29, 33, 1577), (9, 16, 1577)]
fe_idx: [(42, 100, 'Location', 7882), (26, 41, 'Location', 7882), (18, 20, 'Theme', 3914)]
tokenized_text: Zweitens befinden wir uns an einem Punkt , an dem wir keine Ahnung haben , wie es in Zukunft weitergeht .
tokenized_lu_idx: ['-', 'sich an einem Punkt befinden.v', '-', '-', 'sich an einem Punkt befinden.v', 'sich an einem Punkt befinden.v', 'sich an einem Punkt befinden.v', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', 'Being_located', '-', '-', 'Being_located', 'Being_located', 'Being_located', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', 'Theme', '-', 'Location', 'Location', 'Location', 'Location', 'Location', 'Location', 'Location', 'Location', 'Location', 'Location', 'Location', 'Location', 'Location', 'Location', 'Location', 'Location', '-']

===============================
====Annotation (`annoID` = 9761)====
text: I have an interest in education.
frameName: Possession
frameID: 107
luName: have.v
luID: 16047
lu_idx: [(2, 5, 1)]
fe_idx: [(7, 30, 'Possession', 463), (0, 0, 'Owner', 457)]
tokenized_text: I have an interest in education .
tokenized_lu_idx: ['-', 'have.v', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', 'Possession', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', 'Possession', 'Possession', 'Possession', 'Possession', '-']

====Annotation (`annoID` = 10373)====
text: Ich interessiere mich für Bildung.
frameName: Experiencer_focus
frameID: 42
luName: interessiere mich.v
luID: 29853
lu_idx: [(17, 20, 1577), (4, 15, 1577)]
fe_idx: [(22, 32, 'Content', 169), (0, 2, 'Experiencer', 168)]
tokenized_text: Ich interessiere mich für Bildung .
tokenized_lu_idx: ['-', 'interessiere mich.v', 'interessiere mich.v', '-', '-', '-']
tokenized_frame_idx: ['-', 'Experiencer_focus', 'Experiencer_focus', '-', '-', '-']
tokenized_fe_idx: ['Experiencer', '-', '-', 'Content', 'Content', '-']


===============================
====Annotation (`annoID` = 4397)====
text: The second is that it's put us in a place where we have no idea what's going to happen, in terms of the future.
frameName: Locale
frameID: 172
luName: place.n
luID: 17435
lu_idx: [(36, 40, 1)]
fe_idx: [(36, 40, 'Locale', 987)]
tokenized_text: The second is that it 's put us in a place where we have no idea what 's going to happen , in terms of the future .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'place.n', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Locale', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Locale', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 9159)====
text: Zweitens befinden wir uns an einem Punkt, an dem wir keine Ahnung haben, wie es in Zukunft weitergeht.
frameName: Being_located
frameID: 481
luName: sich an einem Punkt befinden.v
luID: 29368
lu_idx: [(35, 39, 1577), (26, 27, 1577), (29, 33, 1577), (9, 16, 1577)]
fe_idx: [(42, 100, 'Location', 7882), (26, 41, 'Location', 7882), (18, 20, 'Theme', 3914)]
tokenized_text: Zweitens befinden wir uns an einem Punkt , an dem wir keine Ahnung haben , wie es in Zukunft weitergeht .
tokenized_lu_idx: ['-', 'sich an einem Punkt befinden.v', '-', '-', 'sich an einem Punkt befinden.v', 'sich an einem Punkt befinden.v', 'sich an einem Punkt befinden.v', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', 'Being_located', '-', '-', 'Being_located', 'Being_located', 'Being_located', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', 'Theme', '-', 'Location', 'Location', 'Location', 'Location', 'Location', 'Location', 'Location', 'Location', 'Location', 'Location', 'Location', 'Location', 'Location', 'Location', 'Location', 'Location', '-']

===============================
====Annotation (`annoID` = 2507)====
text: What you have there is a person of extraordinary dedication who found a talent.
frameName: Locating
frameID: 458
luName: find.v
luID: 22270
lu_idx: [(64, 68, 1)]
fe_idx: [(70, 77, 'Sought_entity', 3534), (60, 62, 'Perceiver', 3533), (23, 58, 'Perceiver', 3533)]
tokenized_text: What you have there is a person of extraordinary dedication who found a talent .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'find.v', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Locating', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', 'Perceiver', 'Perceiver', 'Perceiver', 'Perceiver', 'Perceiver', 'Perceiver', '-', 'Sought_entity', 'Sought_entity', '-']

====Annotation (`annoID` = 9310)====
text: Sie ist eine Person mit außerordentlicher Hingabe, die ihr Talent gefunden hat.
frameName: Becoming_aware
frameID: 15
luName: finden.v
luID: 29518
lu_idx: [(66, 73, 1577)]
fe_idx: [(55, 58, 'Phenomenon', 62), (51, 53, 'Cognizer', 61), (59, 64, 'Phenomenon', 62)]
tokenized_text: Sie ist eine Person mit außerordentlicher Hingabe , die ihr Talent gefunden hat .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'finden.v', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Becoming_aware', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', 'Cognizer', 'Phenomenon', 'Phenomenon', '-', '-', '-']

===============================
====Annotation (`annoID` = 4271)====
text: And the third part of this is that we've all agreed, nonetheless, on the really extraordinary capacities that children have -- their capacities for innovation.
frameName: Stimulus_focus
frameID: 336
luName: extraordinary.a
luID: 27212
lu_idx: [(80, 92, 1)]
fe_idx: [(94, 103, 'Stimulus', 2400), (73, 78, 'Degree', 2402)]
tokenized_text: And the third part of this is that we 've all agreed , nonetheless , on the really extraordinary capacities that children have -- their capacities for innovation .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'extraordinary.a', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Stimulus_focus', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Degree', '-', 'Stimulus', '-', '-', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 9716)====
text: Und das dritte Thema ist, dass wir uns trotzdem alle einig sind, dass Kinder wirklich außergewöhnliche Fähigkeiten haben -- Fähigkeiten, neue Wege zu gehen.
frameName: Desirability
frameID: 326
luName: außergewöhnlich.a
luID: 29781
lu_idx: [(86, 101, 1577)]
fe_idx: [(103, 113, 'Evaluee', 2309), (77, 84, 'Degree', 2310)]
tokenized_text: Und das dritte Thema ist , dass wir uns trotzdem alle einig sind , dass Kinder wirklich außergewöhnliche Fähigkeiten haben -- Fähigkeiten , neue Wege zu gehen .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'außergewöhnlich.a', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Desirability', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Degree', '-', 'Evaluee', '-', '-', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 2561)====
text: And the girl said, 'They will, in a minute.'
frameName: Statement
frameID: 37
luName: say.v
luID: 13406
lu_idx: [(13, 16, 1)]
fe_idx: [(20, 41, 'Message', 154), (4, 11, 'Speaker', 152)]
tokenized_text: And the girl said , ' They will , in a minute . '
tokenized_lu_idx: ['-', '-', '-', 'say.v', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', 'Statement', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', 'Speaker', 'Speaker', '-', '-', '-', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', '-', '-']

====Annotation (`annoID` = 9347)====
text: Und das Mädchen antwortete: 'Gleich wissen sie es.'
frameName: Communication_response
frameID: 36
luName: antworten.v
luID: 29540
lu_idx: [(16, 25, 1577)]
fe_idx: [(4, 14, 'Speaker', 146), (29, 49, 'Message', 148)]
tokenized_text: Und das Mädchen antwortete : ' Gleich wissen sie es . '
tokenized_lu_idx: ['-', '-', '-', 'antworten.v', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', 'Communication_response', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', 'Speaker', 'Speaker', '-', '-', '-', 'Message', 'Message', 'Message', 'Message', 'Message', '-']

===============================
====Annotation (`annoID` = 2449)====
text: They come in bearing gifts, gold, frankincense and myrrh.
frameName: Arriving
frameID: 48
luName: come.v
luID: 13943
lu_idx: [(5, 8, 1)]
fe_idx: [(13, 55, 'Circumstances', 6875), (10, 11, 'Goal', 189), (0, 3, 'Theme', 186)]
tokenized_text: They come in bearing gifts , gold , frankincense and myrrh .
tokenized_lu_idx: ['-', 'come.v', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', 'Arriving', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['Theme', '-', 'Goal', 'Circumstances', 'Circumstances', 'Circumstances', 'Circumstances', 'Circumstances', 'Circumstances', 'Circumstances', 'Circumstances', '-']

====Annotation (`annoID` = 10713)====
text: Sie bringen Geschenke, Gold, Weihrauch und Myrrhe.
frameName: Giving
frameID: 127
luName: bringen.v
luID: 29949
lu_idx: [(4, 10, 1577)]
fe_idx: [(0, 2, 'Donor', 672), (43, 48, 'Depictive', 8192), (12, 20, 'Theme', 674), (29, 37, 'Depictive', 8192), (23, 26, 'Depictive', 8192)]
tokenized_text: Sie bringen Geschenke , Gold , Weihrauch und Myrrhe .
tokenized_lu_idx: ['-', 'bringen.v', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', 'Giving', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['Donor', '-', 'Theme', '-', 'Depictive', '-', 'Depictive', '-', 'Depictive', '-']

===============================
====Annotation (`annoID` = 9765)====
text: My contention is that creativity now is as important in education as literacy, and we should treat it with the same status.
frameName: Identicality
frameID: 511
luName: same.a
luID: 22793
lu_idx: [(111, 114, 1)]
fe_idx: [(116, 121, 'Type', 4094), (111, 121, 'Current_instance', 4095)]
tokenized_text: My contention is that creativity now is as important in education as literacy , and we should treat it with the same status .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'same.a', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Identicality', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Current_instance', 'Current_instance', '-']

====Annotation (`annoID` = 9321)====
text: Meine Überzeugung ist, dass Kreativität heute genauso wichtig für Bildung ist, wie Lesen und Schreiben, und wir sollten sie gleichwertig behandeln.
frameName: Evaluative_comparison
frameID: 325
luName: gleichwertig.a
luID: 29523
lu_idx: [(124, 135, 1577)]
fe_idx: [(120, 122, 'Profiled_item', 2256)]
tokenized_text: Meine Überzeugung ist , dass Kreativität heute genauso wichtig für Bildung ist , wie Lesen und Schreiben , und wir sollten sie gleichwertig behandeln .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'gleichwertig.a', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Evaluative_comparison', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Profiled_item', '-', '-', '-']

====Annotation (`annoID` = 4517)====
text: He didn't have to speak, but you know the bit where the three kings come in?
frameName: Familiarity
frameID: 714
luName: know.v
luID: 24084
lu_idx: [(33, 36, 1)]
fe_idx: [(38, 74, 'Entity', 5868), (29, 31, 'Cognizer', 5869)]
tokenized_text: He did n't have to speak , but you know the bit where the three kings come in ?
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', 'know.v', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', 'Familiarity', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', 'Cognizer', '-', 'Entity', 'Entity', 'Entity', 'Entity', 'Entity', 'Entity', 'Entity', 'Entity', '-']

====Annotation (`annoID` = 10775)====
text: Er musste nicht reden, aber wissen Sie noch, der Teil, wo die drei Könige kommen?
frameName: Remembering_information
frameID: 587
luName: wissen noch.v
luID: 30012
lu_idx: [(39, 42, 1577), (0, 0, 1577), (28, 33, 1577)]
fe_idx: [(45, 79, 'Mental_content', 4710), (35, 37, 'Cognizer', 4709)]
tokenized_text: Er musste nicht reden , aber wissen Sie noch , der Teil , wo die drei Könige kommen ?
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', 'wissen noch.v', '-', 'wissen noch.v', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', 'Remembering_information', '-', 'Remembering_information', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', 'Cognizer', '-', '-', 'Mental_content', 'Mental_content', 'Mental_content', 'Mental_content', 'Mental_content', 'Mental_content', 'Mental_content', 'Mental_content', '-']

===============================
====Annotation (`annoID` = 2489)====
text: We were sitting there and I think they just went out of sequence, because we talked to the little boy afterward and we said, 'You OK with that?'
frameName: Posture
frameID: 13
luName: sit.v
luID: 12743
lu_idx: [(8, 14, 1)]
fe_idx: [(16, 20, 'Location', 56), (0, 1, 'Agent', 55)]
tokenized_text: We were sitting there and I think they just went out of sequence , because we talked to the little boy afterward and we said , ' You OK with that ? '
tokenized_lu_idx: ['-', '-', 'sit.v', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', 'Posture', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['Agent', '-', '-', 'Location', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 10715)====
text: Wir saßen da und ich glaube, sie vertauschten die Reihenfolge, weil wir hinterher fragten: 'War das okay für dich?'und er: 'Ja.
frameName: Perception_experience
frameID: 64
luName: dasitzen.v
luID: 29951
lu_idx: [(4, 8, 1577)]
fe_idx: [(0, 2, 'Perceiver_passive', 287)]
tokenized_text: Wir saßen da und ich glaube , sie vertauschten die Reihenfolge , weil wir hinterher fragten : ' War das okay für dich ?' und er : ' Ja .
tokenized_lu_idx: ['-', 'dasitzen.v', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', 'Perception_experience', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['Perceiver_passive', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 2555)====
text: I heard a great story recently -- I love telling it -- of a little girl who was in a drawing lesson.
frameName: Statement
frameID: 37
luName: tell.v
luID: 13430
lu_idx: [(41, 47, 1)]
fe_idx: [(34, 34, 'Speaker', 152), (49, 50, 'Message', 154)]
tokenized_text: I heard a great story recently -- I love telling it -- of a little girl who was in a drawing lesson .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', 'tell.v', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', 'Statement', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', 'Speaker', '-', '-', 'Message', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 10794)====
text: Ich habe vor kurzem eine tolle Geschichte gehört -- ich erzähle sie zu gern -- über ein kleines Mädchen, die in Zeichnen saß.
frameName: Telling
frameID: 454
luName: erzählen.v
luID: 29759
lu_idx: [(56, 62, 1577)]
fe_idx: [(68, 74, 'Manner', 3506), (64, 66, 'Message', 3504), (52, 54, 'Speaker', 3502)]
tokenized_text: Ich habe vor kurzem eine tolle Geschichte gehört -- ich erzähle sie zu gern -- über ein kleines Mädchen , die in Zeichnen saß .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'erzählen.v', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Telling', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', 'Speaker', '-', 'Message', 'Manner', 'Manner', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 4276)====
text: I mean, Sirena last night was a marvel, wasn't she?
frameName: Stimulus_focus
frameID: 336
luName: marvel.n
luID: 27215
lu_idx: [(32, 37, 1)]
fe_idx: [(8, 13, 'Stimulus', 2400)]
tokenized_text: I mean , Sirena last night was a marvel , was n't she ?
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', 'marvel.n', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', 'Stimulus_focus', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', 'Stimulus', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 9304)====
text: Sirena gestern Abend war wunderbar, nicht wahr?
frameName: Desirability
frameID: 326
luName: wunderbar.a
luID: 29514
lu_idx: [(25, 33, 1577)]
fe_idx: [(0, 5, 'Evaluee', 2309), (7, 19, 'Circumstances', 2311)]
tokenized_text: Sirena gestern Abend war wunderbar , nicht wahr ?
tokenized_lu_idx: ['-', '-', '-', '-', 'wunderbar.a', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', 'Desirability', '-', '-', '-', '-']
tokenized_fe_idx: ['Evaluee', 'Circumstances', 'Circumstances', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 4057)====
text: And the girl said, 'I'm drawing a picture of God.'
frameName: Create_physical_artwork
frameID: 756
luName: draw.v
luID: 24326
lu_idx: [(24, 30, 1)]
fe_idx: [(21, 21, 'Creator', 6374), (32, 47, 'Representation', 6376)]
tokenized_text: And the girl said , ' I 'm drawing a picture of God . '
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', 'draw.v', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', 'Create_physical_artwork', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', 'Representation', 'Representation', 'Representation', 'Representation', '-', '-']

====Annotation (`annoID` = 9340)====
text: Und das Mädchen sagte: 'Ich zeichne ein Bild von Gott.'
frameName: Create_representation
frameID: 755
luName: zeichnen.v
luID: 29537
lu_idx: [(28, 34, 1577)]
fe_idx: [(36, 43, 'Representation', 6357), (45, 52, 'Represented', 6360), (24, 26, 'Creator', 6358)]
tokenized_text: Und das Mädchen sagte : ' Ich zeichne ein Bild von Gott . '
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', 'zeichnen.v', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', 'Create_representation', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', 'Creator', '-', 'Representation', 'Representation', 'Represented', 'Represented', '-', '-']

===============================
====Annotation (`annoID` = 4472)====
text: I heard a great story recently -- I love telling it -- of a little girl who was in a drawing lesson.
frameName: People
frameID: 278
luName: girl.n
luID: 19352
lu_idx: [(67, 70, 1)]
fe_idx: [(67, 70, 'Person', 1854), (72, 74, 'Person', 1854)]
tokenized_text: I heard a great story recently -- I love telling it -- of a little girl who was in a drawing lesson .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'girl.n', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'People', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Person', 'Person', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 9327)====
text: Ich habe vor kurzem eine tolle Geschichte gehört -- ich erzähle sie zu gern -- über ein kleines Mädchen, die in Zeichnen saß.
frameName: People_by_age
frameID: 490
luName: mädchen.n
luID: 29529
lu_idx: [(96, 102, 1577)]
fe_idx: [(105, 123, 'Descriptor', 3966), (-1, -1, 'Age', 3967), (-1, -1, 'Person', 3964), (88, 94, 'Persistent_characteristic', 3965)]
tokenized_text: Ich habe vor kurzem eine tolle Geschichte gehört -- ich erzähle sie zu gern -- über ein kleines Mädchen , die in Zeichnen saß .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'mädchen.n', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'People_by_age', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Persistent_characteristic', '-', '-', 'Descriptor', 'Descriptor', 'Descriptor', 'Descriptor', '-']

===============================
====Annotation (`annoID` = 2532)====
text: So I want to talk about education and I want to talk about creativity.
frameName: Statement
frameID: 37
luName: talk.v
luID: 13411
lu_idx: [(48, 51, 1)]
fe_idx: [(38, 38, 'Speaker', 152), (53, 68, 'Topic', 155)]
tokenized_text: So I want to talk about education and I want to talk about creativity .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'talk.v', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Statement', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', 'Speaker', '-', '-', '-', 'Topic', 'Topic', '-']

====Annotation (`annoID` = 9724)====
text: Ich möchte also über Bildung und Kreativität sprechen.
frameName: Speak_on_topic
frameID: 424
luName: sprechen.v
luID: 29788
lu_idx: [(45, 52, 1577)]
fe_idx: [(16, 43, 'Topic', 3125), (0, 2, 'Speaker', 3124)]
tokenized_text: Ich möchte also über Bildung und Kreativität sprechen .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', 'sprechen.v', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', 'Speak_on_topic', '-']
tokenized_fe_idx: ['Speaker', '-', '-', 'Topic', 'Topic', 'Topic', 'Topic', '-', '-']

===============================
====Annotation (`annoID` = 4411)====
text: And you're never asked back, curiously.
frameName: Locative_relation
frameID: 179
luName: back.avp
luID: 27281
lu_idx: [(23, 26, 1)]
fe_idx: [(4, 6, 'Figure', 1030), (-1, -1, 'Profiled_region', 11219)]
tokenized_text: And you 're never asked back , curiously .
tokenized_lu_idx: ['-', '-', '-', '-', '-', 'back.avp', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', 'Locative_relation', '-', '-', '-']
tokenized_fe_idx: ['-', 'Figure', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 9266)====
text: Auf jeden Fall nicht zweimal, seltsamerweise.
frameName: Frequency
frameID: 74
luName: zweimal.adv
luID: 29488
lu_idx: [(21, 27, 1577)]
fe_idx: [(-1, -1, 'Attribute', 6005)]
tokenized_text: Auf jeden Fall nicht zweimal , seltsamerweise .
tokenized_lu_idx: ['-', '-', '-', '-', 'zweimal.adv', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', 'Frequency', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 4224)====
text: Just seeing what she could do.
frameName: Intentionally_act
frameID: 178
luName: do.v
luID: 17683
lu_idx: [(27, 28, 1)]
fe_idx: [(17, 19, 'Agent', 1024), (12, 15, 'Act', 1023)]
tokenized_text: Just seeing what she could do .
tokenized_lu_idx: ['-', '-', '-', '-', '-', 'do.v', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', 'Intentionally_act', '-']
tokenized_fe_idx: ['-', '-', 'Act', 'Agent', '-', '-', '-']

====Annotation (`annoID` = 9097)====
text: Allein zu sehen, wozu sie in der Lage ist.
frameName: Capability
frameID: 496
luName: in der Lage sein.v
luID: 29340
lu_idx: [(38, 40, 1577), (33, 36, 1577), (29, 31, 1577), (26, 27, 1577)]
fe_idx: [(17, 20, 'Event', 4000), (22, 24, 'Entity', 3999)]
tokenized_text: Allein zu sehen , wozu sie in der Lage ist .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', 'in der Lage sein.v', 'in der Lage sein.v', 'in der Lage sein.v', 'in der Lage sein.v', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', 'Capability', 'Capability', 'Capability', 'Capability', '-']
tokenized_fe_idx: ['-', '-', '-', '-', 'Event', 'Entity', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 2423)====
text: But if you ask about their education, they pin you to the wall.
frameName: Attaching
frameID: 177
luName: pin.v
luID: 17634
lu_idx: [(43, 45, 1)]
fe_idx: [(47, 49, 'Item', 1021), (51, 61, 'Goal', 1485), (38, 41, 'Agent', 1020)]
tokenized_text: But if you ask about their education , they pin you to the wall .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', 'pin.v', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', 'Attaching', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', 'Agent', '-', 'Item', 'Goal', 'Goal', 'Goal', '-']

====Annotation (`annoID` = 10420)====
text: Fragen Sie sie nach ihrer Schulbildung, nageln sie Sie an die Wand.
frameName: Retaining
frameID: 1160
luName: an die Wand nageln.v
luID: 29369
lu_idx: [(40, 45, 1577)]
fe_idx: [(47, 49, 'Agent', 10819), (51, 53, 'Theme', 10820), (55, 65, 'Place', 10822)]
tokenized_text: Fragen Sie sie nach ihrer Schulbildung , nageln sie Sie an die Wand .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', 'an die Wand nageln.v', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', 'Retaining', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', 'Agent', 'Theme', 'Place', 'Place', 'Place', '-']

===============================
====Annotation (`annoID` = 2526)====
text: And yet we're meant to be educating them for it.
frameName: Purpose
frameID: 416
luName: mean.v
luID: 21664
lu_idx: [(14, 18, 1)]
fe_idx: [(20, 46, 'Goal', 3090), (-1, -1, 'Agent', 3089), (8, 9, 'Goal', 3090)]
tokenized_text: And yet we 're meant to be educating them for it .
tokenized_lu_idx: ['-', '-', '-', '-', 'mean.v', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', 'Purpose', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', 'Goal', '-', '-', 'Goal', 'Goal', 'Goal', 'Goal', 'Goal', 'Goal', '-']

====Annotation (`annoID` = 9297)====
text: Und trotzdem sollen wir sie dafür ausbilden.
frameName: Being_obligated
frameID: 361
luName: sollen.v
luID: 29511
lu_idx: [(13, 18, 1577)]
fe_idx: [(20, 22, 'Responsible_party', 2602), (24, 42, 'Duty', 2603)]
tokenized_text: Und trotzdem sollen wir sie dafür ausbilden .
tokenized_lu_idx: ['-', '-', 'sollen.v', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', 'Being_obligated', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', 'Responsible_party', 'Duty', 'Duty', 'Duty', '-']

===============================
====Annotation (`annoID` = 2540)====
text: There have been three themes running through the conference which are relevant to what I want to talk about.
frameName: Discussion
frameID: 28
luName: talk (to).v
luID: 13195
lu_idx: [(97, 100, 1)]
fe_idx: [(87, 87, 'Interlocutor_1', 109), (-1, -1, 'Interlocutor_2', 110), (102, 106, 'Topic', 112), (82, 85, 'Topic', 112)]
tokenized_text: There have been three themes running through the conference which are relevant to what I want to talk about .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'talk (to).v', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Discussion', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Topic', 'Interlocutor_1', '-', '-', '-', 'Topic', '-']

====Annotation (`annoID` = 9438)====
text: Es gab drei Leitmotive, die sich durch die Konferenz zogen, die wichtig sind für das, worüber ich sprechen will.
frameName: Text_creation
frameID: 253
luName: sprechen.v
luID: 29637
lu_idx: [(98, 105, 1577)]
fe_idx: [(94, 96, 'Author', 1684), (-1, -1, 'Text', 1686)]
tokenized_text: Es gab drei Leitmotive , die sich durch die Konferenz zogen , die wichtig sind für das , worüber ich sprechen will .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'sprechen.v', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Text_creation', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Author', '-', '-', '-']

===============================
====Annotation (`annoID` = 4421)====
text: But if you are, and you say to somebody, you know, they say, 'What do you do?'and you say you work in education, you can see the blood run from their face.
frameName: Substance
frameID: 609
luName: blood.n
luID: 27283
lu_idx: [(129, 133, 1)]
fe_idx: [(129, 133, 'Substance', 4968)]
tokenized_text: But if you are , and you say to somebody , you know , they say , ' What do you do ?' and you say you work in education , you can see the blood run from their face .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'blood.n', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Substance', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Substance', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 10378)====
text: Sind Sie aber eingeladen und reden mit jemandem, also wenn jemand fragt: 'Was machen Sie so?'und Sie: 'Ich arbeite im Bildungswesen', sieht man, wie den anderen das Blut aus dem Gesicht weicht.
frameName: Body_parts
frameID: 108
luName: das Blut.n
luID: 29858
lu_idx: [(165, 168, 1577), (161, 163, 1577)]
fe_idx: [(149, 159, 'Possessor', 472), (174, 184, 'Orientational_location', 522)]
tokenized_text: Sind Sie aber eingeladen und reden mit jemandem , also wenn jemand fragt : ' Was machen Sie so ?' und Sie : ' Ich arbeite im Bildungswesen ' , sieht man , wie den anderen das Blut aus dem Gesicht weicht .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'das Blut.n', 'das Blut.n', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Body_parts', 'Body_parts', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Possessor', 'Possessor', '-', '-', '-', 'Orientational_location', 'Orientational_location', '-', '-']

===============================
====Annotation (`annoID` = 2554)====
text: I heard a great story recently -- I love telling it -- of a little girl who was in a drawing lesson.
frameName: Hearsay
frameID: 31
luName: hear.v
luID: 13218
lu_idx: [(2, 6, 1)]
fe_idx: [(55, 98, 'Message', 123), (0, 0, 'Hearer', 122), (22, 29, 'Time', 9430), (8, 20, 'Message', 123)]
tokenized_text: I heard a great story recently -- I love telling it -- of a little girl who was in a drawing lesson .
tokenized_lu_idx: ['-', 'hear.v', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', 'Hearsay', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', 'Message', 'Message', 'Message', 'Time', '-', '-', '-', '-', '-', '-', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', '-']

====Annotation (`annoID` = 10784)====
text: Ich habe vor kurzem eine tolle Geschichte gehört -- ich erzähle sie zu gern -- über ein kleines Mädchen, die in Zeichnen saß.
frameName: Perception_experience
frameID: 64
luName: gehört haben.v
luID: 30020
lu_idx: [(42, 47, 1577), (0, 0, 1577), (4, 7, 1577)]
fe_idx: []
tokenized_text: Ich habe vor kurzem eine tolle Geschichte gehört -- ich erzähle sie zu gern -- über ein kleines Mädchen , die in Zeichnen saß .
tokenized_lu_idx: ['-', 'gehört haben.v', '-', '-', '-', '-', '-', 'gehört haben.v', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', 'Perception_experience', '-', '-', '-', '-', '-', 'Perception_experience', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 9668)====
text: He didn't have to speak, but you know the bit where the three kings come in?
frameName: Leadership
frameID: 67
luName: king.n
luID: 14768
lu_idx: [(62, 66, 1)]
fe_idx: [(62, 66, 'Leader', 303)]
tokenized_text: He did n't have to speak , but you know the bit where the three kings come in ?
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'king.n', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Leadership', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Leader', '-', '-', '-']

====Annotation (`annoID` = 10737)====
text: Er musste nicht reden, aber wissen Sie noch, der Teil, wo die drei Könige kommen?
frameName: People_by_jurisdiction
frameID: 506
luName: könig.n
luID: 29984
lu_idx: [(67, 72, 1577)]
fe_idx: [(67, 72, 'Person', 4061)]
tokenized_text: Er musste nicht reden , aber wissen Sie noch , der Teil , wo die drei Könige kommen ?
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'könig.n', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'People_by_jurisdiction', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Person', '-', '-']

===============================
====Annotation (`annoID` = 9760)====
text: The second is that it's put us in a place where we have no idea what's going to happen, in terms of the future.
frameName: Possession
frameID: 107
luName: have.v
luID: 16047
lu_idx: [(51, 54, 1)]
fe_idx: [(56, 62, 'Possession', 463), (64, 67, 'Possession', 463), (48, 49, 'Owner', 457)]
tokenized_text: The second is that it 's put us in a place where we have no idea what 's going to happen , in terms of the future .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'have.v', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Possession', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Owner', '-', 'Possession', 'Possession', 'Possession', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 9094)====
text: Zweitens befinden wir uns an einem Punkt, an dem wir keine Ahnung haben, wie es in Zukunft weitergeht.
frameName: Awareness
frameID: 14
luName: keine Ahnung haben.v
luID: 29337
lu_idx: [(59, 64, 1577), (66, 70, 1577), (53, 57, 1577)]
fe_idx: [(49, 51, 'Cognizer', 57), (73, 100, 'Topic', 60), (53, 57, 'Degree', 638)]
tokenized_text: Zweitens befinden wir uns an einem Punkt , an dem wir keine Ahnung haben , wie es in Zukunft weitergeht .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'keine Ahnung haben.v', 'keine Ahnung haben.v', 'keine Ahnung haben.v', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Awareness', 'Awareness', 'Awareness', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Cognizer', 'Degree', '-', '-', '-', 'Topic', 'Topic', 'Topic', 'Topic', 'Topic', '-']

===============================
====Annotation (`annoID` = 9662)====
text: And she's exceptional, but I think she's not, so to speak, exceptional in the whole of childhood.
frameName: Age
frameID: 489
luName: childhood.n
luID: 27284
lu_idx: [(87, 95, 1)]
fe_idx: [(-1, -1, 'Entity', 3957)]
tokenized_text: And she 's exceptional , but I think she 's not , so to speak , exceptional in the whole of childhood .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'childhood.n', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Age', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 10798)====
text: Sie ist außergewöhnlich, aber ich denke, sie ist nicht, sozusagen, außergewöhnlich in Bezug auf die Gesamtheit aller Kinder.
frameName: People_by_age
frameID: 490
luName: kind.n
luID: 29504
lu_idx: [(117, 122, 1577)]
fe_idx: []
tokenized_text: Sie ist außergewöhnlich , aber ich denke , sie ist nicht , sozusagen , außergewöhnlich in Bezug auf die Gesamtheit aller Kinder .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'kind.n', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'People_by_age', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 4404)====
text: No idea how this may play out.
frameName: Turning_out
frameID: 959
luName: play.v
luID: 27277
lu_idx: [(21, 24, 1)]
fe_idx: [(8, 10, 'State_of_affairs', 9175), (12, 15, 'State_of_affairs', 9175)]
tokenized_text: No idea how this may play out .
tokenized_lu_idx: ['-', '-', '-', '-', '-', 'play.v', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', 'Turning_out', '-', '-']
tokenized_fe_idx: ['-', '-', 'State_of_affairs', 'State_of_affairs', '-', '-', '-', '-']

====Annotation (`annoID` = 9691)====
text: Keine Ahnung, wie das enden wird.
frameName: Process_end
frameID: 208
luName: enden.v
luID: 29756
lu_idx: [(22, 26, 1577)]
fe_idx: [(18, 20, 'Process', 1404), (14, 16, 'Manner', 1411)]
tokenized_text: Keine Ahnung , wie das enden wird .
tokenized_lu_idx: ['-', '-', '-', '-', '-', 'enden.v', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', 'Process_end', '-', '-']
tokenized_fe_idx: ['-', '-', '-', 'Manner', 'Process', '-', '-', '-']

===============================
====Annotation (`annoID` = 2490)====
text: We were sitting there and I think they just went out of sequence, because we talked to the little boy afterward and we said, 'You OK with that?'
frameName: Motion
frameID: 3
luName: go.v
luID: 12554
lu_idx: [(44, 47, 1)]
fe_idx: [(49, 63, 'Manner', 2265), (34, 37, 'Theme', 11)]
tokenized_text: We were sitting there and I think they just went out of sequence , because we talked to the little boy afterward and we said , ' You OK with that ? '
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', 'go.v', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', 'Motion', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', 'Theme', '-', '-', 'Manner', 'Manner', 'Manner', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 10717)====
text: Wir saßen da und ich glaube, sie vertauschten die Reihenfolge, weil wir hinterher fragten: 'War das okay für dich?'und er: 'Ja.
frameName: Bungling
frameID: 241
luName: vertauschen.v
luID: 29953
lu_idx: [(33, 44, 1577)]
fe_idx: [(29, 31, 'Agent', 1564), (46, 60, 'Patient', 1565), (33, 44, 'Action', 1569)]
tokenized_text: Wir saßen da und ich glaube , sie vertauschten die Reihenfolge , weil wir hinterher fragten : ' War das okay für dich ?' und er : ' Ja .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', 'vertauschen.v', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', 'Bungling', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', 'Agent', 'Action', 'Patient', 'Patient', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
