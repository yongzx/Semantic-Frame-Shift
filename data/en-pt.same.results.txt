===============================
====Annotation (`annoID` = 2572)====
text: Picasso once said this, he said that all children are born artists.
frameName: Statement
frameID: 37
luName: say.v
luID: 13406
lu_idx: [(13, 16, 1)]
fe_idx: [(18, 21, 'Message', 154), (0, 6, 'Speaker', 152)]
tokenized_text: Picasso once said this , he said that all children are born artists .
tokenized_lu_idx: ['-', '-', 'say.v', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', 'Statement', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['Speaker', '-', '-', 'Message', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 2206)====
text: Picasso disse uma vez que todas as crianças nascem artistas.
frameName: Statement
frameID: 37
luName: dizer.v
luID: 26321
lu_idx: [(8, 12, 453)]
fe_idx: [(22, 58, 'Message', 154), (-1, -1, 'Medium', 956), (14, 20, 'Time', 3192), (0, 6, 'Speaker', 152)]
tokenized_text: Picasso disse uma vez que todas as crianças nascem artistas .
tokenized_lu_idx: ['-', 'dizer.v', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', 'Statement', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['Speaker', '-', 'Time', 'Time', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', '-']

===============================
====Annotation (`annoID` = 9904)====
text: I think you'd have to conclude the whole purpose of public education throughout the world is to produce university professors.
frameName: Opinion
frameID: 642
luName: think.v
luID: 23709
lu_idx: [(2, 6, 1)]
fe_idx: [(0, 0, 'Cognizer', 5228), (8, 29, 'Opinion', 5229)]
tokenized_text: I think you 'd have to conclude the whole purpose of public education throughout the world is to produce university professors .
tokenized_lu_idx: ['-', 'think.v', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', 'Opinion', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', 'Opinion', 'Opinion', 'Opinion', 'Opinion', 'Opinion', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 1882)====
text: Eu acho que a conclusão obrigatória seria, olhando para o resultado, que quem é bem sucedido, quem faz tudo o que deve, quem ganha as estrelinhas, quem são os vencedores, eu acho que a conclusão seria de que o objetivo da educação pública ao redor do mundo é produzir professores universitários.
frameName: Opinion
frameID: 642
luName: achar.v
luID: 26333
lu_idx: [(3, 6, 453)]
fe_idx: [(0, 1, 'Cognizer', 5228), (8, 168, 'Opinion', 5229)]
tokenized_text: Eu acho que a conclusão obrigatória seria , olhando para o resultado , que quem é bem sucedido , quem faz tudo o que deve , quem ganha as estrelinhas , quem são os vencedores , eu acho que a conclusão seria de que o objetivo da educação pública ao redor do mundo é produzir professores universitários .
tokenized_lu_idx: ['-', 'achar.v', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', 'Opinion', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['Cognizer', '-', 'Opinion', 'Opinion', 'Opinion', 'Opinion', 'Opinion', 'Opinion', 'Opinion', 'Opinion', 'Opinion', 'Opinion', 'Opinion', 'Opinion', 'Opinion', 'Opinion', 'Opinion', 'Opinion', 'Opinion', 'Opinion', 'Opinion', 'Opinion', 'Opinion', 'Opinion', 'Opinion', 'Opinion', 'Opinion', 'Opinion', 'Opinion', 'Opinion', 'Opinion', 'Opinion', 'Opinion', 'Opinion', 'Opinion', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 10156)====
text: We know three things about intelligence.
frameName: Topic
frameID: 343
luName: about.prep
luID: 20457
lu_idx: [(21, 25, 1)]
fe_idx: [(27, 38, 'Topic', 2452), (8, 19, 'Text', 2453)]
tokenized_text: We know three things about intelligence .
tokenized_lu_idx: ['-', '-', '-', '-', 'about.prep', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', 'Topic', '-', '-']
tokenized_fe_idx: ['-', '-', 'Text', 'Text', '-', 'Topic', '-']

====Annotation (`annoID` = 7302)====
text: Sabemos três coisas sobre inteligência.
frameName: Topic
frameID: 343
luName: sobre.prep
luID: 26435
lu_idx: [(20, 24, 453)]
fe_idx: [(26, 37, 'Topic', 2452), (-1, -1, 'Text', 2453)]
tokenized_text: Sabemos três coisas sobre inteligência .
tokenized_lu_idx: ['-', '-', '-', 'sobre.prep', '-', '-']
tokenized_frame_idx: ['-', '-', '-', 'Topic', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', 'Topic', '-']

===============================
====Annotation (`annoID` = 2517)====
text: If you think of it, children starting school this year will be retiring in 2065.
frameName: People_by_age
frameID: 490
luName: child.n
luID: 22624
lu_idx: [(20, 27, 1)]
fe_idx: [(20, 27, 'Person', 3964)]
tokenized_text: If you think of it , children starting school this year will be retiring in 2065 .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', 'child.n', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', 'People_by_age', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', 'Person', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 4353)====
text: Se formos pensar, as crianças entrando na escola esse ano estarão se aposentando em 2065.
frameName: People_by_age
frameID: 490
luName: criança.n
luID: 26312
lu_idx: [(21, 28, 453)]
fe_idx: [(30, 56, 'Descriptor', 3966), (-1, -1, 'Age', 3967), (21, 28, 'Person', 3964)]
tokenized_text: Se formos pensar , as crianças entrando na escola esse ano estarão se aposentando em 2065 .
tokenized_lu_idx: ['-', '-', '-', '-', '-', 'criança.n', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', 'People_by_age', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', 'Person', 'Descriptor', 'Descriptor', 'Descriptor', 'Descriptor', 'Descriptor', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 9626)====
text: Because you don't think of Shakespeare being a child, do you?
frameName: Awareness
frameID: 14
luName: think.v
luID: 12780
lu_idx: [(18, 22, 1)]
fe_idx: [(8, 10, 'Cognizer', 57), (24, 51, 'Content', 58)]
tokenized_text: Because you do n't think of Shakespeare being a child , do you ?
tokenized_lu_idx: ['-', '-', '-', '-', 'think.v', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', 'Awareness', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', 'Cognizer', '-', '-', '-', 'Content', 'Content', 'Content', 'Content', 'Content', '-', '-', '-', '-']

====Annotation (`annoID` = 1178)====
text: Porque você nunca pensou no Shakespeare criança, pensou?
frameName: Awareness
frameID: 14
luName: pensar.v
luID: 26304
lu_idx: [(18, 23, 453)]
fe_idx: [(7, 10, 'Cognizer', 57), (12, 16, 'Degree', 638), (25, 46, 'Content', 58)]
tokenized_text: Porque você nunca pensou no Shakespeare criança , pensou ?
tokenized_lu_idx: ['-', '-', '-', 'pensar.v', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', 'Awareness', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', 'Cognizer', 'Degree', '-', 'Content', 'Content', 'Content', '-', '-', '-']

===============================
====Annotation (`annoID` = 2534)====
text: So I want to talk about education and I want to talk about creativity.
frameName: Education_teaching
frameID: 101
luName: education.n
luID: 15868
lu_idx: [(24, 32, 1)]
fe_idx: []
tokenized_text: So I want to talk about education and I want to talk about creativity .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', 'education.n', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', 'Education_teaching', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 1496)====
text: Por isso eu quero falar sobre educação e quero falar sobre criatividade.
frameName: Education_teaching
frameID: 101
luName: educação.n
luID: 26479
lu_idx: [(30, 37, 453)]
fe_idx: [(-1, -1, 'Institution', 433), (-1, -1, 'Student', 432), (-1, -1, 'Fact', 4339), (-1, -1, 'Role', 4378), (-1, -1, 'Course', 4798), (-1, -1, 'Material', 4377), (-1, -1, 'Subject', 434), (-1, -1, 'Teacher', 431)]
tokenized_text: Por isso eu quero falar sobre educação e quero falar sobre criatividade .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', 'educação.n', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', 'Education_teaching', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 4528)====
text: If they don't know, they'll have a go.
frameName: Awareness
frameID: 14
luName: know.v
luID: 12771
lu_idx: [(14, 17, 1)]
fe_idx: [(-1, -1, 'Content', 58), (3, 6, 'Cognizer', 57)]
tokenized_text: If they do n't know , they 'll have a go .
tokenized_lu_idx: ['-', '-', '-', '-', 'know.v', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', 'Awareness', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', 'Cognizer', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 1216)====
text: Se elas não sabem, elas chutam.
frameName: Awareness
frameID: 14
luName: saber.v
luID: 26303
lu_idx: [(12, 16, 453)]
fe_idx: [(-1, -1, 'Content', 58), (3, 6, 'Cognizer', 57), (-1, -1, 'Topic', 60), (-1, -1, 'Expressor', 640)]
tokenized_text: Se elas não sabem , elas chutam .
tokenized_lu_idx: ['-', '-', '-', 'saber.v', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', 'Awareness', '-', '-', '-', '-']
tokenized_fe_idx: ['-', 'Cognizer', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 9824)====
text: And in pretty much every system too, there's a hierarchy within the arts.
frameName: System
frameID: 727
luName: system.n
luID: 24129
lu_idx: [(25, 30, 1)]
fe_idx: [(25, 30, 'Complex', 5996)]
tokenized_text: And in pretty much every system too , there 's a hierarchy within the arts .
tokenized_lu_idx: ['-', '-', '-', '-', '-', 'system.n', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', 'System', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', 'Complex', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 1395)====
text: E praticamente em qualquer sistema existe uma hierarquia dentre as artes.
frameName: System
frameID: 727
luName: sistema.n
luID: 26471
lu_idx: [(27, 33, 453)]
fe_idx: [(64, 71, 'Component_entities', 5995), (-1, -1, 'Function', 5997), (-1, -1, 'Complex', 5996), (-1, -1, 'Salient_entity', 6008)]
tokenized_text: E praticamente em qualquer sistema existe uma hierarquia dentre as artes .
tokenized_lu_idx: ['-', '-', '-', '-', 'sistema.n', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', 'System', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', 'Component_entities', 'Component_entities', '-']

===============================
====Annotation (`annoID` = 9989)====
text: Our education system is predicated on the idea of academic ability.
frameName: Awareness
frameID: 14
luName: idea.n
luID: 12788
lu_idx: [(42, 45, 1)]
fe_idx: [(47, 65, 'Content', 58), (-1, -1, 'Cognizer', 57)]
tokenized_text: Our education system is predicated on the idea of academic ability .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', 'idea.n', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', 'Awareness', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', 'Content', 'Content', 'Content', '-']

====Annotation (`annoID` = 6930)====
text: Nosso sistema educacional atual se baseia na idéia da habilidade acadêmica.
frameName: Awareness
frameID: 14
luName: ideia.n
luID: 26410
lu_idx: [(45, 49, 453)]
fe_idx: [(51, 73, 'Content', 58), (-1, -1, 'Cognizer', 57)]
tokenized_text: Nosso sistema educacional atual se baseia na idéia da habilidade acadêmica .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', 'ideia.n', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', 'Awareness', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', 'Content', 'Content', 'Content', '-']

===============================
====Annotation (`annoID` = 10169)====
text: We think in abstract terms, we think in movement.
frameName: Awareness
frameID: 14
luName: think.v
luID: 12780
lu_idx: [(3, 7, 1)]
fe_idx: [(-1, -1, 'Content', 58), (9, 25, 'Manner', 639), (0, 1, 'Cognizer', 57)]
tokenized_text: We think in abstract terms , we think in movement .
tokenized_lu_idx: ['-', 'think.v', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', 'Awareness', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['Cognizer', '-', 'Manner', 'Manner', 'Manner', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 1158)====
text: Pensamos em termo abstratos, pensamos em movimento.
frameName: Awareness
frameID: 14
luName: pensar.v
luID: 26304
lu_idx: [(0, 7, 453)]
fe_idx: [(-1, -1, 'Content', 58), (-1, -1, 'Topic', 60), (9, 26, 'Manner', 639), (-1, -1, 'Cognizer', 57)]
tokenized_text: Pensamos em termo abstratos , pensamos em movimento .
tokenized_lu_idx: ['pensar.v', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['Awareness', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', 'Manner', 'Manner', 'Manner', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 10150)====
text: And it indicates the whole structure of education is shifting beneath our feet.
frameName: Body_parts
frameID: 108
luName: foot.n
luID: 16088
lu_idx: [(74, 77, 1)]
fe_idx: [(70, 72, 'Possessor', 472), (74, 77, 'Body_part', 516)]
tokenized_text: And it indicates the whole structure of education is shifting beneath our feet .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'foot.n', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Body_parts', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Possessor', 'Body_part', '-']

====Annotation (`annoID` = 7361)====
text: E é um indicativo de que toda a estrutura educacional está mudando na frente do nosso nariz.
frameName: Body_parts
frameID: 108
luName: nariz.n
luID: 28485
lu_idx: [(86, 90, 453)]
fe_idx: [(-1, -1, 'Possessor', 472), (-1, -1, 'Body_part', 516)]
tokenized_text: E é um indicativo de que toda a estrutura educacional está mudando na frente do nosso nariz .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'nariz.n', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Body_parts', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 4254)====
text: So I have a big interest in education, and I think we all do.
frameName: Education_teaching
frameID: 101
luName: education.n
luID: 15868
lu_idx: [(28, 36, 1)]
fe_idx: [(-1, -1, 'Student', 432)]
tokenized_text: So I have a big interest in education , and I think we all do .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', 'education.n', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', 'Education_teaching', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 4338)====
text: Eu tenho um grande interesse em educação, e acho que todos temos.
frameName: Education_teaching
frameID: 101
luName: educação.n
luID: 26479
lu_idx: [(32, 39, 453)]
fe_idx: [(-1, -1, 'Teacher', 431), (-1, -1, 'Subject', 434), (-1, -1, 'Student', 432)]
tokenized_text: Eu tenho um grande interesse em educação , e acho que todos temos .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', 'educação.n', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', 'Education_teaching', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 2439)====
text: Because it's one of those things that goes deep with people, am I right?
frameName: Causation
frameID: 1
luName: because.c
luID: 12518
lu_idx: [(0, 6, 1)]
fe_idx: [(8, 58, 'Cause', 3), (-1, -1, 'Effect', 5)]
tokenized_text: Because it 's one of those things that goes deep with people , am I right ?
tokenized_lu_idx: ['because.c', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['Causation', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', 'Cause', 'Cause', 'Cause', 'Cause', 'Cause', 'Cause', 'Cause', 'Cause', 'Cause', 'Cause', 'Cause', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 2240)====
text: Porque é uma dessas coisas arraigadas nas pessoas, estou certo?Como religião, dinheiro e outras coisas.
frameName: Causation
frameID: 1
luName: porque.c
luID: 26364
lu_idx: [(0, 5, 453)]
fe_idx: [(7, 48, 'Cause', 3), (-1, -1, 'Effect', 5)]
tokenized_text: Porque é uma dessas coisas arraigadas nas pessoas , estou certo ? Como religião , dinheiro e outras coisas .
tokenized_lu_idx: ['porque.c', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['Causation', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', 'Cause', 'Cause', 'Cause', 'Cause', 'Cause', 'Cause', 'Cause', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 9988)====
text: Our education system is predicated on the idea of academic ability.
frameName: System
frameID: 727
luName: system.n
luID: 24129
lu_idx: [(14, 19, 1)]
fe_idx: [(0, 2, 'Possessor', 6007), (14, 19, 'Complex', 5996), (4, 12, 'Function', 5997)]
tokenized_text: Our education system is predicated on the idea of academic ability .
tokenized_lu_idx: ['-', '-', 'system.n', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', 'System', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['Possessor', 'Function', 'Complex', '-', '-', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 2383)====
text: Nosso sistema educacional atual se baseia na idéia da habilidade acadêmica.
frameName: System
frameID: 727
luName: sistema.n
luID: 26471
lu_idx: [(6, 12, 453)]
fe_idx: [(-1, -1, 'Complex', 5996), (14, 24, 'Function', 5997)]
tokenized_text: Nosso sistema educacional atual se baseia na idéia da habilidade acadêmica .
tokenized_lu_idx: ['-', 'sistema.n', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', 'System', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', 'Function', '-', '-', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 10014)====
text: So you were probably steered benignly away from things at school when you were a kid, things you liked, on the grounds that you would never get a job doing that.
frameName: Experiencer_focus
frameID: 42
luName: like.v
luID: 13807
lu_idx: [(97, 101, 1)]
fe_idx: [(86, 91, 'Content', 169), (93, 95, 'Experiencer', 168)]
tokenized_text: So you were probably steered benignly away from things at school when you were a kid , things you liked , on the grounds that you would never get a job doing that .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'like.v', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Experiencer_focus', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Content', 'Experiencer', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 6763)====
text: Então você era bondosamente afastado na escola quando era criança de certas coisas, coisas que gostava, com a premissa que você nunca iria conseguir um emprego fazendo aquilo.
frameName: Experiencer_focus
frameID: 42
luName: gostar.v
luID: 26602
lu_idx: [(95, 101, 453)]
fe_idx: []
tokenized_text: Então você era bondosamente afastado na escola quando era criança de certas coisas , coisas que gostava , com a premissa que você nunca iria conseguir um emprego fazendo aquilo .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'gostar.v', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Experiencer_focus', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 10163)====
text: We think about the world in all the ways that we experience it.
frameName: Perception_experience
frameID: 64
luName: experience.v
luID: 14696
lu_idx: [(49, 58, 1)]
fe_idx: []
tokenized_text: We think about the world in all the ways that we experience it .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'experience.v', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Perception_experience', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 7303)====
text: Pensamos a respeito do mundo de todas as formas que o vivenciamos.
frameName: Perception_experience
frameID: 64
luName: vivenciar.v
luID: 28465
lu_idx: [(54, 64, 453)]
fe_idx: [(52, 52, 'Phenomenon', 288), (-1, -1, 'Perceiver_passive', 287)]
tokenized_text: Pensamos a respeito do mundo de todas as formas que o vivenciamos .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'vivenciar.v', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Perception_experience', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Phenomenon', '-', '-']

===============================
====Annotation (`annoID` = 2604)====
text: Is that right?
frameName: Correctness
frameID: 668
luName: right.a
luID: 23839
lu_idx: [(8, 12, 1)]
fe_idx: [(3, 6, 'Information', 5488)]
tokenized_text: Is that right ?
tokenized_lu_idx: ['-', '-', 'right.a', '-']
tokenized_frame_idx: ['-', '-', 'Correctness', '-']
tokenized_fe_idx: ['-', 'Information', '-', '-']

====Annotation (`annoID` = 6901)====
text: Correto?
frameName: Correctness
frameID: 668
luName: correto.a
luID: 28314
lu_idx: [(0, 6, 453)]
fe_idx: [(-1, -1, 'Information', 5488), (-1, -1, 'Topic', 9163)]
tokenized_text: Correto ?
tokenized_lu_idx: ['correto.a', '-']
tokenized_frame_idx: ['Correctness', '-']
tokenized_fe_idx: ['-', '-']

===============================
====Annotation (`annoID` = 9598)====
text: What these things have in common is that kids will take a chance.
frameName: People_by_age
frameID: 490
luName: kid.n
luID: 22628
lu_idx: [(41, 44, 1)]
fe_idx: [(41, 44, 'Person', 3964)]
tokenized_text: What these things have in common is that kids will take a chance .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', 'kid.n', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', 'People_by_age', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', 'Person', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 1150)====
text: O que essas histórias tem em comum é que as crianças correm riscos.
frameName: People_by_age
frameID: 490
luName: criança.n
luID: 26312
lu_idx: [(44, 51, 453)]
fe_idx: [(-1, -1, 'Age', 3967), (-1, -1, 'Person', 3964)]
tokenized_text: O que essas histórias tem em comum é que as crianças correm riscos .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'criança.n', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'People_by_age', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 10086)====
text: And the consequence is that many highly-talented, brilliant, creative people think they're not, because the thing they were good at at school wasn't valued, or was actually stigmatized.
frameName: Causation
frameID: 1
luName: consequence.n
luID: 12532
lu_idx: [(8, 18, 1)]
fe_idx: [(-1, -1, 'Cause', 3), (23, 93, 'Effect', 5)]
tokenized_text: And the consequence is that many highly-talented , brilliant , creative people think they 're not , because the thing they were good at at school was n't valued , or was actually stigmatized .
tokenized_lu_idx: ['-', '-', 'consequence.n', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', 'Causation', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', 'Effect', 'Effect', 'Effect', 'Effect', 'Effect', 'Effect', 'Effect', 'Effect', 'Effect', 'Effect', 'Effect', 'Effect', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 7160)====
text: A consequência disso é que muitas pessoas altamente talentosas brilhantes e criativas, pensam que não são, porque aquilo que elas eram boas na escola não era valorizado, ou era até estigmatizado.
frameName: Causation
frameID: 1
luName: consequência.n
luID: 28417
lu_idx: [(2, 13, 453)]
fe_idx: [(15, 19, 'Cause', 3), (27, 105, 'Effect', 5), (23, 25, 'Effect', 5)]
tokenized_text: A consequência disso é que muitas pessoas altamente talentosas brilhantes e criativas , pensam que não são , porque aquilo que elas eram boas na escola não era valorizado , ou era até estigmatizado .
tokenized_lu_idx: ['-', 'consequência.n', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', 'Causation', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', 'Cause', '-', 'Effect', 'Effect', 'Effect', 'Effect', 'Effect', 'Effect', 'Effect', 'Effect', 'Effect', 'Effect', 'Effect', 'Effect', 'Effect', 'Effect', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 9622)====
text: So you can imagine what a seamless transition that was.
frameName: Awareness
frameID: 14
luName: imagine.v
luID: 12770
lu_idx: [(11, 17, 1)]
fe_idx: [(19, 53, 'Content', 58), (3, 5, 'Cognizer', 57)]
tokenized_text: So you can imagine what a seamless transition that was .
tokenized_lu_idx: ['-', '-', '-', 'imagine.v', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', 'Awareness', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', 'Cognizer', '-', '-', 'Content', 'Content', 'Content', 'Content', 'Content', 'Content', '-']

====Annotation (`annoID` = 1125)====
text: Vocês podem imaginar a mudança suave que foi.
frameName: Awareness
frameID: 14
luName: imaginar.v
luID: 26356
lu_idx: [(12, 19, 453)]
fe_idx: [(21, 43, 'Content', 58), (0, 4, 'Cognizer', 57)]
tokenized_text: Vocês podem imaginar a mudança suave que foi .
tokenized_lu_idx: ['-', '-', 'imaginar.v', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', 'Awareness', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['Cognizer', '-', '-', 'Content', 'Content', 'Content', 'Content', 'Content', '-']

===============================
====Annotation (`annoID` = 2597)====
text: And when they got out, he said to her mother, 'Just stand and watch her.'
frameName: Statement
frameID: 37
luName: say.v
luID: 13406
lu_idx: [(26, 29, 1)]
fe_idx: [(4, 20, 'Time', 3192), (23, 24, 'Speaker', 152), (47, 70, 'Message', 154), (31, 43, 'Addressee', 153)]
tokenized_text: And when they got out , he said to her mother , ' Just stand and watch her . '
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', 'say.v', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', 'Statement', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', 'Time', 'Time', 'Time', 'Time', '-', 'Speaker', '-', 'Addressee', 'Addressee', 'Addressee', '-', '-', 'Message', 'Message', 'Message', 'Message', 'Message', '-', '-']

====Annotation (`annoID` = 7257)====
text: E quando eles saíram da sala, ele disse para a mãe: 'Só a escute e a observe.'
frameName: Statement
frameID: 37
luName: dizer.v
luID: 26321
lu_idx: [(34, 38, 453)]
fe_idx: [(30, 32, 'Speaker', 152), (40, 49, 'Addressee', 153), (53, 75, 'Message', 154)]
tokenized_text: E quando eles saíram da sala , ele disse para a mãe : ' Só a escute e a observe . '
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', 'dizer.v', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', 'Statement', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', 'Speaker', '-', 'Addressee', 'Addressee', 'Addressee', '-', '-', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', '-', '-']

===============================
====Annotation (`annoID` = 9858)====
text: We all have bodies, don't we?
frameName: Body_parts
frameID: 108
luName: body.n
luID: 16075
lu_idx: [(12, 17, 1)]
fe_idx: [(12, 17, 'Body_part', 516), (0, 5, 'Possessor', 472)]
tokenized_text: We all have bodies , do n't we ?
tokenized_lu_idx: ['-', '-', '-', 'body.n', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', 'Body_parts', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['Possessor', 'Possessor', '-', 'Body_part', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 1582)====
text: Nós todos temos corpos, não temos?
frameName: Body_parts
frameID: 108
luName: corpo.n
luID: 26353
lu_idx: [(16, 21, 453)]
fe_idx: [(0, 2, 'Possessor', 472), (-1, -1, 'Body_part', 516)]
tokenized_text: Nós todos temos corpos , não temos ?
tokenized_lu_idx: ['-', '-', '-', 'corpo.n', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', 'Body_parts', '-', '-', '-', '-']
tokenized_fe_idx: ['Possessor', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 10093)====
text: In the next 30 years, according to UNESCO, more people worldwide will be graduating through education than since the beginning of history.
frameName: Attributed_information
frameID: 548
luName: according to.prep
luID: 23162
lu_idx: [(22, 30, 1), (32, 33, 1)]
fe_idx: [(0, 19, 'Proposition', 4432), (43, 136, 'Proposition', 4432), (35, 40, 'Speaker', 4433)]
tokenized_text: In the next 30 years , according to UNESCO , more people worldwide will be graduating through education than since the beginning of history .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', 'according to.prep', 'according to.prep', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', 'Attributed_information', 'Attributed_information', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['Proposition', 'Proposition', 'Proposition', 'Proposition', 'Proposition', '-', '-', '-', 'Speaker', '-', 'Proposition', 'Proposition', 'Proposition', 'Proposition', 'Proposition', 'Proposition', 'Proposition', 'Proposition', 'Proposition', 'Proposition', 'Proposition', 'Proposition', 'Proposition', 'Proposition', '-']

====Annotation (`annoID` = 7194)====
text: Nos próximos 30 anos, de acordo com a UNESCO, mais gente ao redor do mundo irá se formar através da educação do que desde o princípio da história.
frameName: Attributed_information
frameID: 548
luName: de acordo com.c
luID: 28432
lu_idx: [(22, 23, 453), (25, 30, 453), (32, 34, 453)]
fe_idx: [(36, 43, 'Speaker', 4433), (46, 144, 'Proposition', 4432)]
tokenized_text: Nos próximos 30 anos , de acordo com a UNESCO , mais gente ao redor do mundo irá se formar através da educação do que desde o princípio da história .
tokenized_lu_idx: ['-', '-', '-', '-', '-', 'de acordo com.c', 'de acordo com.c', 'de acordo com.c', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', 'Attributed_information', 'Attributed_information', 'Attributed_information', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', 'Speaker', 'Speaker', '-', 'Proposition', 'Proposition', 'Proposition', 'Proposition', 'Proposition', 'Proposition', 'Proposition', 'Proposition', 'Proposition', 'Proposition', 'Proposition', 'Proposition', 'Proposition', 'Proposition', 'Proposition', 'Proposition', 'Proposition', 'Proposition', 'Proposition', '-']

===============================
====Annotation (`annoID` = 5932)====
text: The problem is to remain an artist as we grow up.
frameName: Predicament
frameID: 274
luName: problem.n
luID: 19288
lu_idx: [(4, 10, 1)]
fe_idx: [(15, 33, 'Situation', 1826), (35, 47, 'Time', 1829)]
tokenized_text: The problem is to remain an artist as we grow up .
tokenized_lu_idx: ['-', 'problem.n', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', 'Predicament', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', 'Situation', 'Situation', 'Situation', 'Situation', 'Time', 'Time', 'Time', 'Time', '-']

====Annotation (`annoID` = 2213)====
text: O problema é permanecer artista enquanto crescemos.
frameName: Predicament
frameID: 274
luName: problema.n
luID: 26627
lu_idx: [(2, 9, 453)]
fe_idx: [(-1, -1, 'Experiencer', 1825), (11, 49, 'Situation', 1826)]
tokenized_text: O problema é permanecer artista enquanto crescemos .
tokenized_lu_idx: ['-', 'problema.n', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', 'Predicament', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', 'Situation', 'Situation', 'Situation', 'Situation', 'Situation', '-']

===============================
====Annotation (`annoID` = 2598)====
text: And they watched for a few minutes and he turned to her mother and said, 'Mrs.Lynne, Gillian isn't sick; she's a dancer.
frameName: Statement
frameID: 37
luName: say.v
luID: 13406
lu_idx: [(67, 70, 1)]
fe_idx: [(39, 40, 'Speaker', 152), (74, 118, 'Message', 154)]
tokenized_text: And they watched for a few minutes and he turned to her mother and said , ' Mrs.Lynne , Gillian is n't sick ; she 's a dancer .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'say.v', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Statement', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', 'Speaker', '-', '-', '-', '-', '-', '-', '-', '-', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', '-']

====Annotation (`annoID` = 7244)====
text: Eles observaram por alguns minutos e ele se virou para a mãe e disse: 'Sra.Lynne, a Gillian não está doente, ela é uma dançarina.Leve-a para uma escola de dança.'
frameName: Statement
frameID: 37
luName: dizer.v
luID: 26321
lu_idx: [(63, 67, 453)]
fe_idx: [(71, 160, 'Message', 154), (-1, -1, 'Speaker', 152)]
tokenized_text: Eles observaram por alguns minutos e ele se virou para a mãe e disse : ' Sra.Lynne , a Gillian não está doente , ela é uma dançarina.Leve-a para uma escola de dança . '
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'dizer.v', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Statement', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', '-']

===============================
====Annotation (`annoID` = 2170)====
text: One is the extraordinary evidence of human creativity in all of the presentations that we've had and in all of the people here.
frameName: Desirability
frameID: 326
luName: extraordinary.a
luID: 19989
lu_idx: [(11, 23, 1)]
fe_idx: [(25, 32, 'Evaluee', 2309)]
tokenized_text: One is the extraordinary evidence of human creativity in all of the presentations that we 've had and in all of the people here .
tokenized_lu_idx: ['-', '-', '-', 'extraordinary.a', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', 'Desirability', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', 'Evaluee', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 2343)====
text: O primeiro é a extraordinária evidência da criatividade humana em todas as apresentações que tivemos e em todas as pessoas presentes.
frameName: Desirability
frameID: 326
luName: extraordinário.a
luID: 26679
lu_idx: [(15, 28, 453)]
fe_idx: [(30, 38, 'Evaluee', 2309)]
tokenized_text: O primeiro é a extraordinária evidência da criatividade humana em todas as apresentações que tivemos e em todas as pessoas presentes .
tokenized_lu_idx: ['-', '-', '-', '-', 'extraordinário.a', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', 'Desirability', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', 'Evaluee', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 9725)====
text: And by the time they get to be adults, most kids have lost that capacity.
frameName: Losing
frameID: 963
luName: lose.v
luID: 25212
lu_idx: [(54, 57, 1)]
fe_idx: [(59, 71, 'Possession', 9197), (44, 47, 'Owner', 9196)]
tokenized_text: And by the time they get to be adults , most kids have lost that capacity .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'lose.v', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Losing', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Owner', '-', '-', 'Possession', 'Possession', '-']

====Annotation (`annoID` = 6802)====
text: E quando chegam a fase adulta, a maioria das crianças perdeu essa capacidade.
frameName: Losing
frameID: 963
luName: perder.v
luID: 26528
lu_idx: [(54, 59, 453)]
fe_idx: [(61, 75, 'Possession', 9197), (31, 52, 'Owner', 9196)]
tokenized_text: E quando chegam a fase adulta , a maioria das crianças perdeu essa capacidade .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'perder.v', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Losing', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', 'Owner', 'Owner', 'Owner', 'Owner', '-', 'Possession', 'Possession', '-']

===============================
====Annotation (`annoID` = 9632)====
text: My son didn't want to come.
frameName: Desiring
frameID: 338
luName: want.v
luID: 20296
lu_idx: [(14, 17, 1)]
fe_idx: [(19, 25, 'Event', 2469), (0, 5, 'Experiencer', 2467)]
tokenized_text: My son did n't want to come .
tokenized_lu_idx: ['-', '-', '-', '-', 'want.v', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', 'Desiring', '-', '-', '-']
tokenized_fe_idx: ['Experiencer', 'Experiencer', '-', '-', '-', 'Event', 'Event', '-']

====Annotation (`annoID` = 1253)====
text: Meu filho não queria vir.
frameName: Desiring
frameID: 338
luName: querer.v
luID: 26406
lu_idx: [(14, 19, 453)]
fe_idx: [(0, 8, 'Experiencer', 2467), (-1, -1, 'Focal_participant', 2472), (21, 23, 'Event', 2469), (-1, -1, 'Location_of_event', 2486)]
tokenized_text: Meu filho não queria vir .
tokenized_lu_idx: ['-', '-', '-', 'querer.v', '-', '-']
tokenized_frame_idx: ['-', '-', '-', 'Desiring', '-', '-']
tokenized_fe_idx: ['Experiencer', 'Experiencer', '-', '-', 'Event', '-']

===============================
====Annotation (`annoID` = 10159)====
text: We think about the world in all the ways that we experience it.
frameName: Political_locales
frameID: 175
luName: world.n
luID: 17538
lu_idx: [(19, 23, 1)]
fe_idx: [(19, 23, 'Locale', 1002)]
tokenized_text: We think about the world in all the ways that we experience it .
tokenized_lu_idx: ['-', '-', '-', '-', 'world.n', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', 'Political_locales', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', 'Locale', '-', '-', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 1155)====
text: Pensamos a respeito do mundo de todas as formas que o vivenciamos.
frameName: Political_locales
frameID: 175
luName: mundo.n
luID: 26327
lu_idx: [(23, 27, 453)]
fe_idx: [(-1, -1, 'Locale', 1002)]
tokenized_text: Pensamos a respeito do mundo de todas as formas que o vivenciamos .
tokenized_lu_idx: ['-', '-', '-', '-', 'mundo.n', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', 'Political_locales', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 10095)====
text: In the next 30 years, according to UNESCO, more people worldwide will be graduating through education than since the beginning of history.
frameName: Time_vector
frameID: 349
luName: since.adv
luID: 20536
lu_idx: [(107, 111, 1)]
fe_idx: [(113, 136, 'Landmark_event', 2501), (0, 105, 'Event', 3489)]
tokenized_text: In the next 30 years , according to UNESCO , more people worldwide will be graduating through education than since the beginning of history .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'since.adv', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Time_vector', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['Event', 'Event', 'Event', 'Event', 'Event', 'Event', 'Event', 'Event', 'Event', 'Event', 'Event', 'Event', 'Event', 'Event', 'Event', 'Event', 'Event', 'Event', 'Event', '-', 'Landmark_event', 'Landmark_event', 'Landmark_event', 'Landmark_event', '-']

====Annotation (`annoID` = 7191)====
text: Nos próximos 30 anos, de acordo com a UNESCO, mais gente ao redor do mundo irá se formar através da educação do que desde o princípio da história.
frameName: Time_vector
frameID: 349
luName: desde.prep
luID: 28429
lu_idx: [(116, 120, 453)]
fe_idx: [(122, 144, 'Landmark_event', 2501), (-1, -1, 'Distance', 2502), (-1, -1, 'Direction', 2503), (-1, -1, 'Event', 3489)]
tokenized_text: Nos próximos 30 anos , de acordo com a UNESCO , mais gente ao redor do mundo irá se formar através da educação do que desde o princípio da história .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'desde.prep', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Time_vector', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Landmark_event', 'Landmark_event', 'Landmark_event', 'Landmark_event', '-']

===============================
====Annotation (`annoID` = 9833)====
text: There isn't an education system on the planet that teaches dance every day to children the way we teach them mathematics.
frameName: Spatial_contact
frameID: 1188
luName: on.prep
luID: 26093
lu_idx: [(32, 33, 1)]
fe_idx: [(35, 44, 'Ground', 11082), (12, 30, 'Figure', 11083)]
tokenized_text: There is n't an education system on the planet that teaches dance every day to children the way we teach them mathematics .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', 'on.prep', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', 'Spatial_contact', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', 'Figure', 'Figure', 'Figure', '-', 'Ground', 'Ground', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 1359)====
text: Não existe um sistema educacional no planeta que ensina dança diariamente às crianças da mesma forma que ensina matemática.
frameName: Spatial_contact
frameID: 1188
luName: em.prep
luID: 26315
lu_idx: [(34, 35, 453)]
fe_idx: [(14, 32, 'Figure', 11083), (37, 43, 'Ground', 11082)]
tokenized_text: Não existe um sistema educacional no planeta que ensina dança diariamente às crianças da mesma forma que ensina matemática .
tokenized_lu_idx: ['-', '-', '-', '-', '-', 'em.prep', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', 'Spatial_contact', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', 'Figure', 'Figure', '-', 'Ground', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 9767)====
text: We were sitting there and I think they just went out of sequence, because we talked to the little boy afterward and we said, 'You OK with that?'
frameName: People_by_age
frameID: 490
luName: boy.n
luID: 22623
lu_idx: [(98, 100, 1)]
fe_idx: [(-1, -1, 'Age', 3967), (98, 100, 'Person', 3964)]
tokenized_text: We were sitting there and I think they just went out of sequence , because we talked to the little boy afterward and we said , ' You OK with that ? '
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'boy.n', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'People_by_age', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Person', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 6678)====
text: Estávamos lá sentados e eu acho que eles não seguiram a ordem porque nós conversamos com o garotinho depois e perguntamos: 'Tudo certo?'
frameName: People_by_age
frameID: 490
luName: garoto.n
luID: 26301
lu_idx: [(91, 99, 453)]
fe_idx: [(-1, -1, 'Person', 3964)]
tokenized_text: Estávamos lá sentados e eu acho que eles não seguiram a ordem porque nós conversamos com o garotinho depois e perguntamos : ' Tudo certo ? '
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'garoto.n', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'People_by_age', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 4062)====
text: And the teacher said, 'But nobody knows what God looks like.'
frameName: Education_teaching
frameID: 101
luName: teacher.n
luID: 15849
lu_idx: [(8, 14, 1)]
fe_idx: [(8, 14, 'Teacher', 431), (-1, -1, 'Subject', 434), (-1, -1, 'Student', 432)]
tokenized_text: And the teacher said , ' But nobody knows what God looks like . '
tokenized_lu_idx: ['-', '-', 'teacher.n', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', 'Education_teaching', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', 'Teacher', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 6554)====
text: E a professora disse: 'Mas ninguém conhece a aparência de Deus.'
frameName: Education_teaching
frameID: 101
luName: professor.n
luID: 26567
lu_idx: [(4, 13, 453)]
fe_idx: [(-1, -1, 'Teacher', 431), (-1, -1, 'Institution', 433), (-1, -1, 'Student', 432)]
tokenized_text: E a professora disse : ' Mas ninguém conhece a aparência de Deus . '
tokenized_lu_idx: ['-', '-', 'professor.n', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', 'Education_teaching', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 9844)====
text: I think math is very important, but so is dance.
frameName: Opinion
frameID: 642
luName: think.v
luID: 23709
lu_idx: [(2, 6, 1)]
fe_idx: [(8, 46, 'Opinion', 5229), (0, 0, 'Cognizer', 5228)]
tokenized_text: I think math is very important , but so is dance .
tokenized_lu_idx: ['-', 'think.v', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', 'Opinion', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', 'Opinion', 'Opinion', 'Opinion', 'Opinion', 'Opinion', 'Opinion', 'Opinion', 'Opinion', 'Opinion', '-']

====Annotation (`annoID` = 1540)====
text: Eu acho que matemática é importante, mas dança também.
frameName: Opinion
frameID: 642
luName: achar.v
luID: 26333
lu_idx: [(3, 6, 453)]
fe_idx: [(0, 1, 'Cognizer', 5228), (8, 52, 'Opinion', 5229)]
tokenized_text: Eu acho que matemática é importante , mas dança também .
tokenized_lu_idx: ['-', 'achar.v', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', 'Opinion', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['Cognizer', '-', 'Opinion', 'Opinion', 'Opinion', 'Opinion', 'Opinion', 'Opinion', 'Opinion', 'Opinion', '-']

===============================
====Annotation (`annoID` = 10201)====
text: If my wife is cooking a meal at home -- which is not often, thankfully.
frameName: Personal_relationship
frameID: 93
luName: wife.n
luID: 15541
lu_idx: [(6, 9, 1)]
fe_idx: [(3, 4, 'Partner_2', 404), (6, 9, 'Partner_1', 403)]
tokenized_text: If my wife is cooking a meal at home -- which is not often , thankfully .
tokenized_lu_idx: ['-', '-', 'wife.n', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', 'Personal_relationship', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', 'Partner_2', 'Partner_1', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 7388)====
text: Quando minha esposa está cozinhando, o que acontece pouco, ainda bem.
frameName: Personal_relationship
frameID: 93
luName: esposa.n
luID: 26462
lu_idx: [(13, 18, 453)]
fe_idx: [(-1, -1, 'Partner_1', 403), (-1, -1, 'Partner_2', 404)]
tokenized_text: Quando minha esposa está cozinhando , o que acontece pouco , ainda bem .
tokenized_lu_idx: ['-', '-', 'esposa.n', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', 'Personal_relationship', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 10297)====
text: She was eventually auditioned for the Royal Ballet School; she became a soloist; she had a wonderful career at the Royal Ballet.
frameName: Time_vector
frameID: 349
luName: eventually.adv
luID: 20550
lu_idx: [(8, 17, 1)]
fe_idx: [(0, 6, 'Event', 3489), (19, 56, 'Event', 3489)]
tokenized_text: She was eventually auditioned for the Royal Ballet School ; she became a soloist ; she had a wonderful career at the Royal Ballet .
tokenized_lu_idx: ['-', '-', 'eventually.adv', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', 'Time_vector', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['Event', 'Event', '-', 'Event', 'Event', 'Event', 'Event', 'Event', 'Event', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 2326)====
text: Ela eventualmente fez um teste para a Royal Ballet School, se tornou uma solista e teve uma carreira fantástica na Royal Ballet.
frameName: Time_vector
frameID: 349
luName: eventualmente.adv
luID: 26668
lu_idx: [(4, 16, 453)]
fe_idx: [(-1, -1, 'Distance', 2502), (18, 126, 'Landmark_event', 2501)]
tokenized_text: Ela eventualmente fez um teste para a Royal Ballet School , se tornou uma solista e teve uma carreira fantástica na Royal Ballet .
tokenized_lu_idx: ['-', 'eventualmente.adv', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', 'Time_vector', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', 'Landmark_event', 'Landmark_event', 'Landmark_event', 'Landmark_event', 'Landmark_event', 'Landmark_event', 'Landmark_event', 'Landmark_event', 'Landmark_event', 'Landmark_event', 'Landmark_event', 'Landmark_event', 'Landmark_event', 'Landmark_event', 'Landmark_event', 'Landmark_event', 'Landmark_event', 'Landmark_event', 'Landmark_event', 'Landmark_event', 'Landmark_event', '-']

===============================
====Annotation (`annoID` = 2533)====
text: So I want to talk about education and I want to talk about creativity.
frameName: Desiring
frameID: 338
luName: want.v
luID: 20296
lu_idx: [(5, 8, 1)]
fe_idx: [(10, 32, 'Event', 2469), (3, 3, 'Experiencer', 2467)]
tokenized_text: So I want to talk about education and I want to talk about creativity .
tokenized_lu_idx: ['-', '-', 'want.v', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', 'Desiring', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', 'Experiencer', '-', 'Event', 'Event', 'Event', 'Event', '-', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 1493)====
text: Por isso eu quero falar sobre educação e quero falar sobre criatividade.
frameName: Desiring
frameID: 338
luName: querer.v
luID: 26406
lu_idx: [(12, 16, 453)]
fe_idx: [(18, 37, 'Event', 2469), (9, 10, 'Experiencer', 2467)]
tokenized_text: Por isso eu quero falar sobre educação e quero falar sobre criatividade .
tokenized_lu_idx: ['-', '-', '-', 'querer.v', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', 'Desiring', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', 'Experiencer', '-', 'Event', 'Event', 'Event', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 10346)====
text: What TED celebrates is the gift of the human imagination.
frameName: Giving
frameID: 127
luName: gift.n
luID: 16573
lu_idx: [(27, 30, 1)]
fe_idx: [(32, 55, 'Theme', 674), (-1, -1, 'Donor', 672), (-1, -1, 'Theme', 674)]
tokenized_text: What TED celebrates is the gift of the human imagination .
tokenized_lu_idx: ['-', '-', '-', '-', '-', 'gift.n', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', 'Giving', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', 'Theme', 'Theme', 'Theme', 'Theme', '-']

====Annotation (`annoID` = 2296)====
text: O que a TED celebra é a dádiva da imaginação humana.
frameName: Giving
frameID: 127
luName: dádiva.n
luID: 26659
lu_idx: [(24, 29, 453)]
fe_idx: [(-1, -1, 'Recipient', 673), (31, 50, 'Donor', 672), (-1, -1, 'Theme', 674)]
tokenized_text: O que a TED celebra é a dádiva da imaginação humana .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', 'dádiva.n', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', 'Giving', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', 'Donor', 'Donor', 'Donor', '-']

===============================
====Annotation (`annoID` = 2536)====
text: I find this very interesting.
frameName: Regard
frameID: 640
luName: find.v
luID: 23699
lu_idx: [(2, 5, 1)]
fe_idx: [(7, 10, 'Evaluee', 5215), (12, 27, 'Judgment', 5221), (0, 0, 'Cognizer', 5214)]
tokenized_text: I find this very interesting .
tokenized_lu_idx: ['-', 'find.v', '-', '-', '-', '-']
tokenized_frame_idx: ['-', 'Regard', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', 'Evaluee', 'Judgment', 'Judgment', '-']

====Annotation (`annoID` = 4301)====
text: Eu acho isso muito interessante.
frameName: Regard
frameID: 640
luName: achar.v
luID: 27232
lu_idx: [(3, 6, 453)]
fe_idx: [(13, 30, 'Judgment', 5221), (0, 1, 'Cognizer', 5214), (8, 11, 'Evaluee', 5215)]
tokenized_text: Eu acho isso muito interessante .
tokenized_lu_idx: ['-', 'achar.v', '-', '-', '-', '-']
tokenized_frame_idx: ['-', 'Regard', '-', '-', '-', '-']
tokenized_fe_idx: ['Cognizer', '-', 'Evaluee', 'Judgment', 'Judgment', '-']

===============================
====Annotation (`annoID` = 9876)====
text: I think you'd have to conclude, if you look at the output, who really succeeds by this, who does everything that they should, who gets all the brownie points, who are the winners -- 
frameName: Opinion
frameID: 642
luName: think.v
luID: 23709
lu_idx: [(2, 6, 1)]
fe_idx: [(0, 0, 'Cognizer', 5228), (8, 29, 'Opinion', 5229)]
tokenized_text: I think you 'd have to conclude , if you look at the output , who really succeeds by this , who does everything that they should , who gets all the brownie points , who are the winners --
tokenized_lu_idx: ['-', 'think.v', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', 'Opinion', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', 'Opinion', 'Opinion', 'Opinion', 'Opinion', 'Opinion', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 1882)====
text: Eu acho que a conclusão obrigatória seria, olhando para o resultado, que quem é bem sucedido, quem faz tudo o que deve, quem ganha as estrelinhas, quem são os vencedores, eu acho que a conclusão seria de que o objetivo da educação pública ao redor do mundo é produzir professores universitários.
frameName: Opinion
frameID: 642
luName: achar.v
luID: 26333
lu_idx: [(3, 6, 453)]
fe_idx: [(0, 1, 'Cognizer', 5228), (8, 168, 'Opinion', 5229)]
tokenized_text: Eu acho que a conclusão obrigatória seria , olhando para o resultado , que quem é bem sucedido , quem faz tudo o que deve , quem ganha as estrelinhas , quem são os vencedores , eu acho que a conclusão seria de que o objetivo da educação pública ao redor do mundo é produzir professores universitários .
tokenized_lu_idx: ['-', 'achar.v', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', 'Opinion', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['Cognizer', '-', 'Opinion', 'Opinion', 'Opinion', 'Opinion', 'Opinion', 'Opinion', 'Opinion', 'Opinion', 'Opinion', 'Opinion', 'Opinion', 'Opinion', 'Opinion', 'Opinion', 'Opinion', 'Opinion', 'Opinion', 'Opinion', 'Opinion', 'Opinion', 'Opinion', 'Opinion', 'Opinion', 'Opinion', 'Opinion', 'Opinion', 'Opinion', 'Opinion', 'Opinion', 'Opinion', 'Opinion', 'Opinion', 'Opinion', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 2567)====
text: And he said, 'Yeah, why?Was that wrong?'
frameName: Statement
frameID: 37
luName: say.v
luID: 13406
lu_idx: [(7, 10, 1)]
fe_idx: [(14, 37, 'Message', 154), (4, 5, 'Speaker', 152)]
tokenized_text: And he said , ' Yeah , why ? Was that wrong ? '
tokenized_lu_idx: ['-', '-', 'say.v', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', 'Statement', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', 'Speaker', '-', '-', '-', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', '-', '-']

====Annotation (`annoID` = 6686)====
text: E ele disse: 'Claro!Por quê?Estava errado?'
frameName: Statement
frameID: 37
luName: dizer.v
luID: 26321
lu_idx: [(6, 10, 453)]
fe_idx: [(14, 40, 'Message', 154), (2, 4, 'Speaker', 152)]
tokenized_text: E ele disse : ' Claro ! Por quê ? Estava errado ? '
tokenized_lu_idx: ['-', '-', 'dizer.v', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', 'Statement', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', 'Speaker', '-', '-', '-', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', '-', '-']

===============================
====Annotation (`annoID` = 10323)====
text: There was a wonderful quote by Jonas Salk, who said, 'If all the insects were to disappear from the Earth, within 50 years all life on Earth would end.
frameName: Desirability
frameID: 326
luName: wonderful.a
luID: 19947
lu_idx: [(12, 20, 1)]
fe_idx: [(22, 40, 'Evaluee', 2309)]
tokenized_text: There was a wonderful quote by Jonas Salk , who said , ' If all the insects were to disappear from the Earth , within 50 years all life on Earth would end .
tokenized_lu_idx: ['-', '-', '-', 'wonderful.a', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', 'Desirability', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', 'Evaluee', 'Evaluee', 'Evaluee', 'Evaluee', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 2328)====
text: Existe uma frase maravilhosa de Jonas Salk, que diz: 'Se todos os insetos desaparecessem da terra, dentro de 50 anos, toda vida na Terra desapareceria.Se todos os humanos desaparecessem da Terra, dentro de 50 anos todas as formas de vida floresceriam.'
frameName: Desirability
frameID: 326
luName: maravilhoso.a
luID: 26670
lu_idx: [(17, 27, 453)]
fe_idx: [(11, 15, 'Evaluee', 2309)]
tokenized_text: Existe uma frase maravilhosa de Jonas Salk , que diz : ' Se todos os insetos desaparecessem da terra , dentro de 50 anos , toda vida na Terra desapareceria.Se todos os humanos desaparecessem da Terra , dentro de 50 anos todas as formas de vida floresceriam . '
tokenized_lu_idx: ['-', '-', '-', 'maravilhoso.a', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', 'Desirability', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', 'Evaluee', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 10112)====
text: When I was a student, if you had a degree, you had a job.
frameName: Possession
frameID: 107
luName: have.v
luID: 16047
lu_idx: [(29, 31, 1)]
fe_idx: [(33, 40, 'Possession', 463), (25, 27, 'Owner', 457)]
tokenized_text: When I was a student , if you had a degree , you had a job .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', 'have.v', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', 'Possession', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', 'Owner', '-', 'Possession', 'Possession', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 7297)====
text: Quando eu estudava, quem tinha um diploma, tinha um emprego.
frameName: Possession
frameID: 107
luName: ter.v
luID: 26331
lu_idx: [(25, 29, 453)]
fe_idx: [(20, 23, 'Owner', 457), (31, 40, 'Possession', 463)]
tokenized_text: Quando eu estudava , quem tinha um diploma , tinha um emprego .
tokenized_lu_idx: ['-', '-', '-', '-', '-', 'ter.v', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', 'Possession', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', 'Owner', '-', 'Possession', 'Possession', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 2422)====
text: But if you ask about their education, they pin you to the wall.
frameName: Questioning
frameID: 34
luName: ask.v
luID: 13314
lu_idx: [(11, 13, 1)]
fe_idx: [(7, 9, 'Speaker', 136), (15, 35, 'Topic', 139)]
tokenized_text: But if you ask about their education , they pin you to the wall .
tokenized_lu_idx: ['-', '-', '-', 'ask.v', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', 'Questioning', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', 'Speaker', '-', 'Topic', 'Topic', 'Topic', '-', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 2237)====
text: Mas se você perguntar sobre a educação deles, eles te põem contra a parede.
frameName: Questioning
frameID: 34
luName: perguntar.v
luID: 26573
lu_idx: [(12, 20, 453)]
fe_idx: [(7, 10, 'Speaker', 136), (22, 44, 'Addressee', 137), (22, 44, 'Message', 138)]
tokenized_text: Mas se você perguntar sobre a educação deles , eles te põem contra a parede .
tokenized_lu_idx: ['-', '-', '-', 'perguntar.v', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', 'Questioning', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', 'Speaker', '-', 'Message', 'Message', 'Message', 'Message', 'Message', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 10041)====
text: If you're at a dinner party, and you say you work in education -- 
frameName: Social_event
frameID: 114
luName: dinner-party.n
luID: 16206
lu_idx: [(15, 20, 1), (22, 26, 1)]
fe_idx: [(15, 26, 'Social_event', 546)]
tokenized_text: If you 're at a dinner party , and you say you work in education --
tokenized_lu_idx: ['-', '-', '-', '-', '-', 'dinner-party.n', 'dinner-party.n', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', 'Social_event', 'Social_event', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', 'Social_event', 'Social_event', '-', '-', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 2394)====
text: Se você estiver numa festa e disser que trabalha com educação...
frameName: Social_event
frameID: 114
luName: festa.n
luID: 26691
lu_idx: [(21, 25, 453)]
fe_idx: [(3, 6, 'Attendee', 552)]
tokenized_text: Se você estiver numa festa e disser que trabalha com educação ...
tokenized_lu_idx: ['-', '-', '-', '-', 'festa.n', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', 'Social_event', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', 'Attendee', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 10250)====
text: I saw a great t-shirt recently, which said, 'If a man speaks his mind in a forest, and no woman hears him, is he still wrong?'
frameName: Conditional_occurrence
frameID: 1192
luName: if.scon
luID: 26122
lu_idx: [(45, 46, 1)]
fe_idx: [(107, 123, 'Consequence', 11107), (48, 104, 'Profiled_possibility', 11106)]
tokenized_text: I saw a great t-shirt recently , which said , ' If a man speaks his mind in a forest , and no woman hears him , is he still wrong ? '
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'if.scon', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Conditional_occurrence', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Profiled_possibility', 'Profiled_possibility', 'Profiled_possibility', 'Profiled_possibility', 'Profiled_possibility', 'Profiled_possibility', 'Profiled_possibility', 'Profiled_possibility', 'Profiled_possibility', 'Profiled_possibility', 'Profiled_possibility', 'Profiled_possibility', 'Profiled_possibility', 'Profiled_possibility', '-', 'Consequence', 'Consequence', 'Consequence', 'Consequence', '-', '-']

====Annotation (`annoID` = 7627)====
text: Vi uma camiseta excelente esses dias que dizia: 'Se um homem fala o que pensa numa floresta, e nenhuma mulher escuta, ele continua errado?'
frameName: Conditional_occurrence
frameID: 1192
luName: se.c
luID: 26411
lu_idx: [(49, 50, 453)]
fe_idx: [(118, 136, 'Consequence', 11107), (52, 115, 'Profiled_possibility', 11106)]
tokenized_text: Vi uma camiseta excelente esses dias que dizia : ' Se um homem fala o que pensa numa floresta , e nenhuma mulher escuta , ele continua errado ? '
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'se.c', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Conditional_occurrence', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Profiled_possibility', 'Profiled_possibility', 'Profiled_possibility', 'Profiled_possibility', 'Profiled_possibility', 'Profiled_possibility', 'Profiled_possibility', 'Profiled_possibility', 'Profiled_possibility', 'Profiled_possibility', 'Profiled_possibility', 'Profiled_possibility', 'Profiled_possibility', '-', 'Consequence', 'Consequence', 'Consequence', '-', '-']

===============================
====Annotation (`annoID` = 4244)====
text: But if you ask about their education, they pin you to the wall.
frameName: Education_teaching
frameID: 101
luName: education.n
luID: 15868
lu_idx: [(27, 35, 1)]
fe_idx: [(21, 25, 'Student', 432)]
tokenized_text: But if you ask about their education , they pin you to the wall .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', 'education.n', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', 'Education_teaching', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', 'Student', '-', '-', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 2239)====
text: Mas se você perguntar sobre a educação deles, eles te põem contra a parede.
frameName: Education_teaching
frameID: 101
luName: educação.n
luID: 26479
lu_idx: [(30, 37, 453)]
fe_idx: [(-1, -1, 'Teacher', 431), (39, 43, 'Student', 432), (-1, -1, 'Subject', 434)]
tokenized_text: Mas se você perguntar sobre a educação deles , eles te põem contra a parede .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', 'educação.n', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', 'Education_teaching', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', 'Student', '-', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 10055)====
text: If you think of it, the whole system of public education around the world is a protracted process of university entrance.
frameName: Conditional_occurrence
frameID: 1192
luName: if.scon
luID: 26122
lu_idx: [(0, 1, 1)]
fe_idx: [(3, 17, 'Profiled_possibility', 11106), (20, 119, 'Consequence', 11107)]
tokenized_text: If you think of it , the whole system of public education around the world is a protracted process of university entrance .
tokenized_lu_idx: ['if.scon', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['Conditional_occurrence', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', 'Profiled_possibility', 'Profiled_possibility', 'Profiled_possibility', 'Profiled_possibility', '-', 'Consequence', 'Consequence', 'Consequence', 'Consequence', 'Consequence', 'Consequence', 'Consequence', 'Consequence', 'Consequence', 'Consequence', 'Consequence', 'Consequence', 'Consequence', 'Consequence', 'Consequence', 'Consequence', '-']

====Annotation (`annoID` = 1267)====
text: Se você for pensar, todo o sistema de educação pública ao redor do mundo é um extensão do processo de ingresso à universidade.
frameName: Conditional_occurrence
frameID: 1192
luName: se.c
luID: 26411
lu_idx: [(0, 1, 453)]
fe_idx: [(20, 124, 'Consequence', 11107), (3, 17, 'Profiled_possibility', 11106)]
tokenized_text: Se você for pensar , todo o sistema de educação pública ao redor do mundo é um extensão do processo de ingresso à universidade .
tokenized_lu_idx: ['se.c', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['Conditional_occurrence', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', 'Profiled_possibility', 'Profiled_possibility', 'Profiled_possibility', '-', 'Consequence', 'Consequence', 'Consequence', 'Consequence', 'Consequence', 'Consequence', 'Consequence', 'Consequence', 'Consequence', 'Consequence', 'Consequence', 'Consequence', 'Consequence', 'Consequence', 'Consequence', 'Consequence', 'Consequence', 'Consequence', 'Consequence', '-']

===============================
====Annotation (`annoID` = 10096)====
text: In the next 30 years, according to UNESCO, more people worldwide will be graduating through education than since the beginning of history.
frameName: Temporal_subregion
frameID: 652
luName: beginning.n
luID: 23757
lu_idx: [(117, 125, 1)]
fe_idx: [(117, 125, 'Subpart', 5333), (127, 136, 'Time_period', 5335)]
tokenized_text: In the next 30 years , according to UNESCO , more people worldwide will be graduating through education than since the beginning of history .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'beginning.n', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Temporal_subregion', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Subpart', 'Time_period', 'Time_period', '-']

====Annotation (`annoID` = 7193)====
text: Nos próximos 30 anos, de acordo com a UNESCO, mais gente ao redor do mundo irá se formar através da educação do que desde o princípio da história.
frameName: Temporal_subregion
frameID: 652
luName: princípio.n
luID: 28431
lu_idx: [(124, 132, 453)]
fe_idx: [(-1, -1, 'Time_period', 5335), (-1, -1, 'Subpart', 5333)]
tokenized_text: Nos próximos 30 anos , de acordo com a UNESCO , mais gente ao redor do mundo irá se formar através da educação do que desde o princípio da história .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'princípio.n', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Temporal_subregion', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 10080)====
text: And the second is academic ability, which has really come to dominate our view of intelligence, because the universities designed the system in their image.
frameName: Dominate_situation
frameID: 801
luName: dominate.v
luID: 24508
lu_idx: [(61, 68, 1)]
fe_idx: [(18, 33, 'Agent', 7293), (36, 40, 'Agent', 7293), (70, 93, 'Situation', 7294)]
tokenized_text: And the second is academic ability , which has really come to dominate our view of intelligence , because the universities designed the system in their image .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'dominate.v', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Dominate_situation', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', 'Agent', 'Agent', '-', 'Agent', '-', '-', '-', '-', '-', 'Situation', 'Situation', 'Situation', 'Situation', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 1161)====
text: A segunda é a aptidão acadêmica, que veio a dominar nossa visão de inteligência, porque as universidades planejaram o sistema à sua própria imagem.
frameName: Dominate_situation
frameID: 801
luName: dominar.v
luID: 26379
lu_idx: [(44, 50, 453)]
fe_idx: [(33, 35, 'Agent', 7293), (52, 78, 'Situation', 7294), (14, 30, 'Agent', 7293)]
tokenized_text: A segunda é a aptidão acadêmica , que veio a dominar nossa visão de inteligência , porque as universidades planejaram o sistema à sua própria imagem .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'dominar.v', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Dominate_situation', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', 'Agent', 'Agent', '-', 'Agent', '-', '-', '-', 'Situation', 'Situation', 'Situation', 'Situation', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 9987)====
text: Our education system is predicated on the idea of academic ability.
frameName: Education_teaching
frameID: 101
luName: education.n
luID: 15868
lu_idx: [(4, 12, 1)]
fe_idx: [(-1, -1, 'Teacher', 431), (-1, -1, 'Material', 4377)]
tokenized_text: Our education system is predicated on the idea of academic ability .
tokenized_lu_idx: ['-', 'education.n', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', 'Education_teaching', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 2384)====
text: Nosso sistema educacional atual se baseia na idéia da habilidade acadêmica.
frameName: Education_teaching
frameID: 101
luName: educacional.a
luID: 26492
lu_idx: [(14, 24, 453)]
fe_idx: [(-1, -1, 'Institution', 433), (-1, -1, 'Student', 432), (-1, -1, 'Fact', 4339), (6, 12, 'Course', 4798), (-1, -1, 'Material', 4377), (-1, -1, 'Subject', 434), (-1, -1, 'Teacher', 431)]
tokenized_text: Nosso sistema educacional atual se baseia na idéia da habilidade acadêmica .
tokenized_lu_idx: ['-', '-', 'educacional.a', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', 'Education_teaching', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', 'Course', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 2525)====
text: Nobody has a clue, despite all the expertise that's been on parade for the past four days, what the world will look like in five years' time.
frameName: Concessive
frameID: 952
luName: despite.prep
luID: 25173
lu_idx: [(19, 25, 1)]
fe_idx: [(27, 88, 'Conceded_state_of_affairs', 9102), (91, 139, 'Main_assertion', 9104), (0, 16, 'Main_assertion', 9104)]
tokenized_text: Nobody has a clue , despite all the expertise that 's been on parade for the past four days , what the world will look like in five years' time .
tokenized_lu_idx: ['-', '-', '-', '-', '-', 'despite.prep', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', 'Concessive', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['Main_assertion', 'Main_assertion', 'Main_assertion', 'Main_assertion', '-', '-', 'Conceded_state_of_affairs', 'Conceded_state_of_affairs', 'Conceded_state_of_affairs', 'Conceded_state_of_affairs', 'Conceded_state_of_affairs', 'Conceded_state_of_affairs', 'Conceded_state_of_affairs', 'Conceded_state_of_affairs', 'Conceded_state_of_affairs', 'Conceded_state_of_affairs', 'Conceded_state_of_affairs', 'Conceded_state_of_affairs', 'Conceded_state_of_affairs', '-', 'Main_assertion', 'Main_assertion', 'Main_assertion', 'Main_assertion', 'Main_assertion', 'Main_assertion', 'Main_assertion', 'Main_assertion', 'Main_assertion', 'Main_assertion', '-']

====Annotation (`annoID` = 4361)====
text: Ninguém tem noção, apesar de todo conhecimento que vimos nos últimos quatro dias, de como o mundo vai estar em cinco anos.
frameName: Concessive
frameID: 952
luName: apesar de.c
luID: 27266
lu_idx: [(19, 27, 453)]
fe_idx: [(0, 16, 'Main_assertion', 9104), (29, 79, 'Conceded_state_of_affairs', 9102), (82, 120, 'Main_assertion', 9104)]
tokenized_text: Ninguém tem noção , apesar de todo conhecimento que vimos nos últimos quatro dias , de como o mundo vai estar em cinco anos .
tokenized_lu_idx: ['-', '-', '-', '-', 'apesar de.c', 'apesar de.c', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', 'Concessive', 'Concessive', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['Main_assertion', 'Main_assertion', 'Main_assertion', '-', '-', '-', 'Conceded_state_of_affairs', 'Conceded_state_of_affairs', 'Conceded_state_of_affairs', 'Conceded_state_of_affairs', 'Conceded_state_of_affairs', 'Conceded_state_of_affairs', 'Conceded_state_of_affairs', 'Conceded_state_of_affairs', '-', 'Main_assertion', 'Main_assertion', 'Main_assertion', 'Main_assertion', 'Main_assertion', 'Main_assertion', 'Main_assertion', 'Main_assertion', 'Main_assertion', '-']

===============================
====Annotation (`annoID` = 2532)====
text: So I want to talk about education and I want to talk about creativity.
frameName: Statement
frameID: 37
luName: talk.v
luID: 13411
lu_idx: [(48, 51, 1)]
fe_idx: [(38, 38, 'Speaker', 152), (53, 68, 'Topic', 155)]
tokenized_text: So I want to talk about education and I want to talk about creativity .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'talk.v', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Statement', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', 'Speaker', '-', '-', '-', 'Topic', 'Topic', '-']

====Annotation (`annoID` = 1499)====
text: Por isso eu quero falar sobre educação e quero falar sobre criatividade.
frameName: Statement
frameID: 37
luName: falar.v
luID: 26299
lu_idx: [(47, 51, 453)]
fe_idx: [(-1, -1, 'Speaker', 152), (-1, -1, 'Medium', 956), (53, 70, 'Topic', 155), (-1, -1, 'Message', 154)]
tokenized_text: Por isso eu quero falar sobre educação e quero falar sobre criatividade .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', 'falar.v', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', 'Statement', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Topic', 'Topic', '-']

===============================
====Annotation (`annoID` = 10153)====
text: We know three things about intelligence.
frameName: Awareness
frameID: 14
luName: know.v
luID: 12771
lu_idx: [(3, 6, 1)]
fe_idx: [(21, 38, 'Topic', 60), (8, 19, 'Content', 58), (0, 1, 'Cognizer', 57)]
tokenized_text: We know three things about intelligence .
tokenized_lu_idx: ['-', 'know.v', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', 'Awareness', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['Cognizer', '-', 'Content', 'Content', 'Topic', 'Topic', '-']

====Annotation (`annoID` = 1030)====
text: Sabemos três coisas sobre inteligência.
frameName: Awareness
frameID: 14
luName: saber.v
luID: 26303
lu_idx: [(0, 6, 453)]
fe_idx: [(20, 37, 'Topic', 60), (-1, -1, 'Cognizer', 57), (8, 18, 'Content', 58)]
tokenized_text: Sabemos três coisas sobre inteligência .
tokenized_lu_idx: ['saber.v', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['Awareness', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', 'Content', 'Content', 'Topic', 'Topic', '-']

===============================
====Annotation (`annoID` = 2522)====
text: If you think of it, children starting school this year will be retiring in 2065.
frameName: Conditional_occurrence
frameID: 1192
luName: if.scon
luID: 26122
lu_idx: [(0, 1, 1)]
fe_idx: [(20, 78, 'Consequence', 11107), (3, 17, 'Profiled_possibility', 11106)]
tokenized_text: If you think of it , children starting school this year will be retiring in 2065 .
tokenized_lu_idx: ['if.scon', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['Conditional_occurrence', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', 'Profiled_possibility', 'Profiled_possibility', 'Profiled_possibility', 'Profiled_possibility', '-', 'Consequence', 'Consequence', 'Consequence', 'Consequence', 'Consequence', 'Consequence', 'Consequence', 'Consequence', 'Consequence', 'Consequence', '-']

====Annotation (`annoID` = 4351)====
text: Se formos pensar, as crianças entrando na escola esse ano estarão se aposentando em 2065.
frameName: Conditional_occurrence
frameID: 1192
luName: se.c
luID: 26411
lu_idx: [(0, 1, 453)]
fe_idx: [(3, 15, 'Profiled_possibility', 11106), (18, 87, 'Consequence', 11107)]
tokenized_text: Se formos pensar , as crianças entrando na escola esse ano estarão se aposentando em 2065 .
tokenized_lu_idx: ['se.c', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['Conditional_occurrence', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', 'Profiled_possibility', 'Profiled_possibility', '-', 'Consequence', 'Consequence', 'Consequence', 'Consequence', 'Consequence', 'Consequence', 'Consequence', 'Consequence', 'Consequence', 'Consequence', 'Consequence', 'Consequence', '-']

===============================
====Annotation (`annoID` = 10134)====
text: But now kids with degrees are often heading home to carry on playing video games, because you need an MA where the previous job required a BA, and now you need a PhD for the other.
frameName: Competition
frameID: 217
luName: play.v
luID: 18317
lu_idx: [(61, 67, 1)]
fe_idx: [(69, 79, 'Competition', 1428), (-1, -1, 'Participants', 1427)]
tokenized_text: But now kids with degrees are often heading home to carry on playing video games , because you need an MA where the previous job required a BA , and now you need a PhD for the other .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'play.v', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Competition', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Competition', 'Competition', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 7669)====
text: Mas agora garotos com diplomas estão voltando para casa para jogar video game porque pedem mestrado para o trabalho que necessitava bacharelado, e doutorado para o trabalho que necessitava mestrado.
frameName: Competition
frameID: 217
luName: jogar.v
luID: 28604
lu_idx: [(61, 65, 453)]
fe_idx: [(67, 76, 'Competition', 1428), (-1, -1, 'Participants', 1427)]
tokenized_text: Mas agora garotos com diplomas estão voltando para casa para jogar video game porque pedem mestrado para o trabalho que necessitava bacharelado , e doutorado para o trabalho que necessitava mestrado .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'jogar.v', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Competition', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Competition', 'Competition', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 4226)====
text: Actually, what I find is everybody has an interest in education.
frameName: Becoming_aware
frameID: 15
luName: find.v
luID: 12791
lu_idx: [(17, 20, 1)]
fe_idx: [(10, 13, 'Phenomenon', 62), (15, 15, 'Cognizer', 61)]
tokenized_text: Actually , what I find is everybody has an interest in education .
tokenized_lu_idx: ['-', '-', '-', '-', 'find.v', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', 'Becoming_aware', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', 'Phenomenon', 'Cognizer', '-', '-', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 2358)====
text: Na verdade, eu descobri que todo mundo se interessa por educação.
frameName: Becoming_aware
frameID: 15
luName: descobrir.v
luID: 26685
lu_idx: [(15, 22, 453)]
fe_idx: [(12, 13, 'Cognizer', 61), (24, 63, 'Phenomenon', 62)]
tokenized_text: Na verdade , eu descobri que todo mundo se interessa por educação .
tokenized_lu_idx: ['-', '-', '-', '-', 'descobrir.v', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', 'Becoming_aware', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', 'Cognizer', '-', 'Phenomenon', 'Phenomenon', 'Phenomenon', 'Phenomenon', 'Phenomenon', 'Phenomenon', 'Phenomenon', '-']

===============================
====Annotation (`annoID` = 9728)====
text: We stigmatize mistakes.
frameName: Judgment
frameID: 23
luName: stigmatize.v
luID: 12992
lu_idx: [(3, 12, 1)]
fe_idx: [(0, 1, 'Cognizer', 89), (14, 21, 'Evaluee', 90)]
tokenized_text: We stigmatize mistakes .
tokenized_lu_idx: ['-', 'stigmatize.v', '-', '-']
tokenized_frame_idx: ['-', 'Judgment', '-', '-']
tokenized_fe_idx: ['Cognizer', '-', 'Evaluee', '-']

====Annotation (`annoID` = 2187)====
text: Nós estigmatizamos os erros.
frameName: Judgment
frameID: 23
luName: estigmatizar.v
luID: 26619
lu_idx: [(4, 17, 453)]
fe_idx: [(19, 26, 'Evaluee', 90), (0, 2, 'Cognizer', 89)]
tokenized_text: Nós estigmatizamos os erros .
tokenized_lu_idx: ['-', 'estigmatizar.v', '-', '-', '-']
tokenized_frame_idx: ['-', 'Judgment', '-', '-', '-']
tokenized_fe_idx: ['Cognizer', '-', 'Evaluee', 'Evaluee', '-']

===============================
====Annotation (`annoID` = 2535)====
text: So I want to talk about education and I want to talk about creativity.
frameName: Desiring
frameID: 338
luName: want.v
luID: 20296
lu_idx: [(40, 43, 1)]
fe_idx: [(45, 68, 'Event', 2469), (38, 38, 'Experiencer', 2467)]
tokenized_text: So I want to talk about education and I want to talk about creativity .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', 'want.v', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', 'Desiring', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', 'Experiencer', '-', 'Event', 'Event', 'Event', 'Event', '-']

====Annotation (`annoID` = 1498)====
text: Por isso eu quero falar sobre educação e quero falar sobre criatividade.
frameName: Desiring
frameID: 338
luName: querer.v
luID: 26406
lu_idx: [(41, 45, 453)]
fe_idx: [(47, 70, 'Event', 2469), (-1, -1, 'Experiencer', 2467), (-1, -1, 'Focal_participant', 2472), (-1, -1, 'Location_of_event', 2486)]
tokenized_text: Por isso eu quero falar sobre educação e quero falar sobre criatividade .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', 'querer.v', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', 'Desiring', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', 'Event', 'Event', 'Event', '-']

===============================
====Annotation (`annoID` = 9813)====
text: What you have there is a person of extraordinary dedication who found a talent.
frameName: Capability
frameID: 496
luName: talent.n
luID: 27219
lu_idx: [(72, 77, 1)]
fe_idx: [(-1, -1, 'Entity', 3999), (-1, -1, 'Event', 4000)]
tokenized_text: What you have there is a person of extraordinary dedication who found a talent .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'talent.n', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Capability', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 1483)====
text: O que vemos ali é uma pessoa de extrema dedicação que achou seu talento.
frameName: Capability
frameID: 496
luName: talento.n
luID: 26558
lu_idx: [(64, 70, 453)]
fe_idx: [(22, 48, 'Entity', 3999), (-1, -1, 'Event', 4000)]
tokenized_text: O que vemos ali é uma pessoa de extrema dedicação que achou seu talento .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'talento.n', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Capability', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', 'Entity', 'Entity', 'Entity', 'Entity', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 10129)====
text: But now kids with degrees are often heading home to carry on playing video games, because you need an MA where the previous job required a BA, and now you need a PhD for the other.
frameName: Concessive
frameID: 952
luName: but.c
luID: 25179
lu_idx: [(0, 2, 1)]
fe_idx: [(4, 79, 'Conceded_state_of_affairs', 9102), (-1, -1, 'Main_assertion', 9104)]
tokenized_text: But now kids with degrees are often heading home to carry on playing video games , because you need an MA where the previous job required a BA , and now you need a PhD for the other .
tokenized_lu_idx: ['but.c', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['Concessive', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', 'Conceded_state_of_affairs', 'Conceded_state_of_affairs', 'Conceded_state_of_affairs', 'Conceded_state_of_affairs', 'Conceded_state_of_affairs', 'Conceded_state_of_affairs', 'Conceded_state_of_affairs', 'Conceded_state_of_affairs', 'Conceded_state_of_affairs', 'Conceded_state_of_affairs', 'Conceded_state_of_affairs', 'Conceded_state_of_affairs', 'Conceded_state_of_affairs', 'Conceded_state_of_affairs', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 7650)====
text: Mas agora garotos com diplomas estão voltando para casa para jogar video game porque pedem mestrado para o trabalho que necessitava bacharelado, e doutorado para o trabalho que necessitava mestrado.
frameName: Concessive
frameID: 952
luName: mas.c
luID: 26438
lu_idx: [(0, 2, 453)]
fe_idx: [(4, 196, 'Conceded_state_of_affairs', 9102), (-1, -1, 'Main_assertion', 9104)]
tokenized_text: Mas agora garotos com diplomas estão voltando para casa para jogar video game porque pedem mestrado para o trabalho que necessitava bacharelado , e doutorado para o trabalho que necessitava mestrado .
tokenized_lu_idx: ['mas.c', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['Concessive', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', 'Conceded_state_of_affairs', 'Conceded_state_of_affairs', 'Conceded_state_of_affairs', 'Conceded_state_of_affairs', 'Conceded_state_of_affairs', 'Conceded_state_of_affairs', 'Conceded_state_of_affairs', 'Conceded_state_of_affairs', 'Conceded_state_of_affairs', 'Conceded_state_of_affairs', 'Conceded_state_of_affairs', 'Conceded_state_of_affairs', 'Conceded_state_of_affairs', 'Conceded_state_of_affairs', 'Conceded_state_of_affairs', 'Conceded_state_of_affairs', 'Conceded_state_of_affairs', 'Conceded_state_of_affairs', 'Conceded_state_of_affairs', 'Conceded_state_of_affairs', 'Conceded_state_of_affairs', 'Conceded_state_of_affairs', 'Conceded_state_of_affairs', 'Conceded_state_of_affairs', 'Conceded_state_of_affairs', 'Conceded_state_of_affairs', 'Conceded_state_of_affairs', 'Conceded_state_of_affairs', 'Conceded_state_of_affairs', 'Conceded_state_of_affairs', '-']

===============================
====Annotation (`annoID` = 2560)====
text: And the teacher said, 'But nobody knows what God looks like.'
frameName: Statement
frameID: 37
luName: say.v
luID: 13406
lu_idx: [(16, 19, 1)]
fe_idx: [(23, 58, 'Message', 154), (4, 14, 'Speaker', 152)]
tokenized_text: And the teacher said , ' But nobody knows what God looks like . '
tokenized_lu_idx: ['-', '-', '-', 'say.v', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', 'Statement', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', 'Speaker', 'Speaker', '-', '-', '-', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', '-', '-']

====Annotation (`annoID` = 6555)====
text: E a professora disse: 'Mas ninguém conhece a aparência de Deus.'
frameName: Statement
frameID: 37
luName: dizer.v
luID: 26321
lu_idx: [(15, 19, 453)]
fe_idx: [(23, 61, 'Message', 154), (2, 13, 'Speaker', 152)]
tokenized_text: E a professora disse : ' Mas ninguém conhece a aparência de Deus . '
tokenized_lu_idx: ['-', '-', '-', 'dizer.v', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', 'Statement', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', 'Speaker', 'Speaker', '-', '-', '-', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', '-', '-']

===============================
====Annotation (`annoID` = 10257)====
text: And the third thing about intelligence is, it's distinct.
frameName: Ordinal_numbers
frameID: 547
luName: third.a
luID: 23150
lu_idx: [(8, 12, 1)]
fe_idx: [(14, 18, 'Type', 4427), (14, 18, 'Item', 4430), (8, 13, 'Item', 4430)]
tokenized_text: And the third thing about intelligence is , it 's distinct .
tokenized_lu_idx: ['-', '-', 'third.a', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', 'Ordinal_numbers', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', 'Item', 'Item', '-', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 7468)====
text: O terceiro ponto sobre a inteligência é que é distinta.
frameName: Ordinal_numbers
frameID: 547
luName: terceiro.a
luID: 26324
lu_idx: [(2, 9, 453)]
fe_idx: [(38, 53, 'Basis_of_order', 4429), (-1, -1, 'Type', 4427), (17, 36, 'Comparison_set', 4431), (-1, -1, 'Starting_point', 4428), (11, 15, 'Item', 4430)]
tokenized_text: O terceiro ponto sobre a inteligência é que é distinta .
tokenized_lu_idx: ['-', 'terceiro.a', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', 'Ordinal_numbers', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', 'Item', 'Comparison_set', 'Comparison_set', 'Comparison_set', 'Basis_of_order', 'Basis_of_order', 'Basis_of_order', 'Basis_of_order', '-']

===============================
====Annotation (`annoID` = 4192)====
text: We walked in this room and it was full of people like me.
frameName: Similarity
frameID: 403
luName: like.prep
luID: 21544
lu_idx: [(49, 52, 1)]
fe_idx: [(54, 55, 'Entity_2', 3052), (42, 47, 'Entity_1', 3051)]
tokenized_text: We walked in this room and it was full of people like me .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'like.prep', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Similarity', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Entity_1', '-', 'Entity_2', '-']

====Annotation (`annoID` = 7417)====
text: Entramos numa sala cheia de pessoas como eu.
frameName: Similarity
frameID: 403
luName: como.c
luID: 27253
lu_idx: [(36, 39, 453)]
fe_idx: [(41, 42, 'Entity_2', 3052), (-1, -1, 'Dimension', 3053), (-1, -1, 'Differentiating_fact', 8178), (28, 34, 'Entity_1', 3051)]
tokenized_text: Entramos numa sala cheia de pessoas como eu .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', 'como.c', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', 'Similarity', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', 'Entity_1', '-', 'Entity_2', '-']

===============================
====Annotation (`annoID` = 2161)====
text: I believe our only hope for the future is to adopt a new conception of human ecology, one in which we start to reconstitute our conception of the richness of human capacity.
frameName: Activity_start
frameID: 134
luName: start.v
luID: 16704
lu_idx: [(102, 106, 1)]
fe_idx: [(99, 100, 'Agent', 1781), (108, 171, 'Activity', 1391)]
tokenized_text: I believe our only hope for the future is to adopt a new conception of human ecology , one in which we start to reconstitute our conception of the richness of human capacity .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'start.v', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Activity_start', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Agent', '-', 'Activity', 'Activity', 'Activity', 'Activity', 'Activity', 'Activity', 'Activity', 'Activity', 'Activity', 'Activity', '-']

====Annotation (`annoID` = 6846)====
text: Eu acredito que nossa única esperança para o futuro é a adoção de uma nova concepção de ecologia humana, uma em que começamos a reconstituir nossa concepção da riqueza da capacidade humana.
frameName: Activity_start
frameID: 134
luName: começar.v
luID: 26586
lu_idx: [(116, 124, 453)]
fe_idx: [(126, 187, 'Activity', 1391), (-1, -1, 'Agent', 1781)]
tokenized_text: Eu acredito que nossa única esperança para o futuro é a adoção de uma nova concepção de ecologia humana , uma em que começamos a reconstituir nossa concepção da riqueza da capacidade humana .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'começar.v', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Activity_start', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Activity', 'Activity', 'Activity', 'Activity', 'Activity', 'Activity', 'Activity', 'Activity', 'Activity', '-']

===============================
====Annotation (`annoID` = 2431)====
text: If you're at a dinner party, and you say you work in education -- 
frameName: Conditional_occurrence
frameID: 1192
luName: if.scon
luID: 26122
lu_idx: [(0, 1, 1)]
fe_idx: [(3, 61, 'Profiled_possibility', 11106), (-1, -1, 'Consequence', 11107)]
tokenized_text: If you 're at a dinner party , and you say you work in education --
tokenized_lu_idx: ['if.scon', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['Conditional_occurrence', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', 'Profiled_possibility', 'Profiled_possibility', 'Profiled_possibility', 'Profiled_possibility', 'Profiled_possibility', 'Profiled_possibility', 'Profiled_possibility', 'Profiled_possibility', 'Profiled_possibility', 'Profiled_possibility', 'Profiled_possibility', 'Profiled_possibility', 'Profiled_possibility', 'Profiled_possibility', '-']

====Annotation (`annoID` = 2393)====
text: Se você estiver numa festa e disser que trabalha com educação...
frameName: Conditional_occurrence
frameID: 1192
luName: se.c
luID: 26411
lu_idx: [(0, 1, 453)]
fe_idx: [(-1, -1, 'Consequence', 11107), (3, 60, 'Profiled_possibility', 11106)]
tokenized_text: Se você estiver numa festa e disser que trabalha com educação ...
tokenized_lu_idx: ['se.c', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['Conditional_occurrence', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', 'Profiled_possibility', 'Profiled_possibility', 'Profiled_possibility', 'Profiled_possibility', 'Profiled_possibility', 'Profiled_possibility', 'Profiled_possibility', 'Profiled_possibility', 'Profiled_possibility', 'Profiled_possibility', '-']

===============================
====Annotation (`annoID` = 9772)====
text: And the third boy said, 'Frank sent this.'
frameName: People_by_age
frameID: 490
luName: boy.n
luID: 22623
lu_idx: [(14, 16, 1)]
fe_idx: [(14, 16, 'Person', 3964), (-1, -1, 'Age', 3967)]
tokenized_text: And the third boy said , ' Frank sent this . '
tokenized_lu_idx: ['-', '-', '-', 'boy.n', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', 'People_by_age', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', 'Person', '-', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 1143)====
text: E o terceiro garoto disse: 'O Frank mandou isso.'
frameName: People_by_age
frameID: 490
luName: garoto.n
luID: 26301
lu_idx: [(13, 18, 453)]
fe_idx: [(-1, -1, 'Age', 3967), (-1, -1, 'Person', 3964)]
tokenized_text: E o terceiro garoto disse : ' O Frank mandou isso . '
tokenized_lu_idx: ['-', '-', '-', 'garoto.n', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', 'People_by_age', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 2569)====
text: And the second boy said, 'I bring you myrrh.'
frameName: Statement
frameID: 37
luName: say.v
luID: 13406
lu_idx: [(19, 22, 1)]
fe_idx: [(4, 17, 'Speaker', 152), (26, 42, 'Message', 154)]
tokenized_text: And the second boy said , ' I bring you myrrh . '
tokenized_lu_idx: ['-', '-', '-', '-', 'say.v', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', 'Statement', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', 'Speaker', 'Speaker', 'Speaker', '-', '-', '-', 'Message', 'Message', 'Message', 'Message', '-', '-']

====Annotation (`annoID` = 1140)====
text: O segundo garoto disse: 'Eu trago mirra.'
frameName: Statement
frameID: 37
luName: dizer.v
luID: 26321
lu_idx: [(17, 21, 453)]
fe_idx: [(25, 38, 'Message', 154), (0, 15, 'Speaker', 152), (-1, -1, 'Topic', 155), (-1, -1, 'Medium', 956)]
tokenized_text: O segundo garoto disse : ' Eu trago mirra . '
tokenized_lu_idx: ['-', '-', '-', 'dizer.v', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', 'Statement', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['Speaker', 'Speaker', 'Speaker', '-', '-', '-', 'Message', 'Message', 'Message', '-', '-']

===============================
====Annotation (`annoID` = 9566)====
text: I never thought of it.
frameName: Negation
frameID: 1186
luName: never.adv
luID: 26067
lu_idx: [(2, 6, 1)]
fe_idx: [(0, 0, 'Negated_proposition', 11073), (8, 20, 'Negated_proposition', 11073)]
tokenized_text: I never thought of it .
tokenized_lu_idx: ['-', 'never.adv', '-', '-', '-', '-']
tokenized_frame_idx: ['-', 'Negation', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', 'Negated_proposition', 'Negated_proposition', 'Negated_proposition', '-']

====Annotation (`annoID` = 1184)====
text: Eu nunca tinha pensado.
frameName: Negation
frameID: 1186
luName: nunca.adv
luID: 26363
lu_idx: [(3, 7, 453)]
fe_idx: [(9, 21, 'Negated_proposition', 11073), (0, 1, 'Negated_proposition', 11073)]
tokenized_text: Eu nunca tinha pensado .
tokenized_lu_idx: ['-', 'nunca.adv', '-', '-', '-']
tokenized_frame_idx: ['-', 'Negation', '-', '-', '-']
tokenized_fe_idx: ['Negated_proposition', '-', 'Negated_proposition', 'Negated_proposition', '-']

===============================
====Annotation (`annoID` = 9997)====
text: Around the world, there were no public systems of education, really, before the 19th century.
frameName: System
frameID: 727
luName: system.n
luID: 24129
lu_idx: [(39, 45, 1)]
fe_idx: [(39, 45, 'Complex', 5996), (32, 37, 'Descriptor', 6006), (47, 58, 'Function', 5997)]
tokenized_text: Around the world , there were no public systems of education , really , before the 19th century .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', 'system.n', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', 'System', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', 'Descriptor', 'Complex', 'Function', 'Function', '-', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 2380)====
text: O sistema foi concebido, e no mundo todo, não existiam sistemas públicos de educação antes do Séc.XIX.
frameName: System
frameID: 727
luName: sistema.n
luID: 26471
lu_idx: [(55, 62, 453)]
fe_idx: [(64, 83, 'Component_entities', 5995), (-1, -1, 'Complex', 5996)]
tokenized_text: O sistema foi concebido , e no mundo todo , não existiam sistemas públicos de educação antes do Séc.XIX .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'sistema.n', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'System', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Component_entities', 'Component_entities', 'Component_entities', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 9835)====
text: There isn't an education system on the planet that teaches dance every day to children the way we teach them mathematics.
frameName: Frequency
frameID: 74
luName: every.prep
luID: 15092
lu_idx: [(65, 69, 1)]
fe_idx: [(12, 63, 'Event', 326), (75, 119, 'Event', 326), (71, 73, 'Time_span', 3284), (65, 73, 'Rate', 6003)]
tokenized_text: There is n't an education system on the planet that teaches dance every day to children the way we teach them mathematics .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'every.prep', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Frequency', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', 'Event', 'Event', 'Event', 'Event', 'Event', 'Event', 'Event', 'Event', 'Event', 'Rate', 'Rate', 'Event', 'Event', 'Event', 'Event', 'Event', 'Event', 'Event', 'Event', '-']

====Annotation (`annoID` = 1323)====
text: Não existe um sistema educacional no planeta que ensina dança diariamente às crianças da mesma forma que ensina matemática.
frameName: Frequency
frameID: 74
luName: diariamente.adv
luID: 26474
lu_idx: [(62, 72, 453)]
fe_idx: [(74, 84, 'Salient_entity', 6004), (-1, -1, 'Attribute', 6005), (49, 60, 'Event', 326), (-1, -1, 'Rate', 6003), (-1, -1, 'Time_span', 3284)]
tokenized_text: Não existe um sistema educacional no planeta que ensina dança diariamente às crianças da mesma forma que ensina matemática .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'diariamente.adv', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Frequency', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', 'Event', 'Event', '-', 'Salient_entity', 'Salient_entity', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 9596)====
text: And the third boy said, 'Frank sent this.'
frameName: Ordinal_numbers
frameID: 547
luName: third.a
luID: 23150
lu_idx: [(8, 12, 1)]
fe_idx: [(14, 16, 'Type', 4427), (8, 16, 'Item', 4430)]
tokenized_text: And the third boy said , ' Frank sent this . '
tokenized_lu_idx: ['-', '-', 'third.a', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', 'Ordinal_numbers', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', 'Item', 'Item', '-', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 1142)====
text: E o terceiro garoto disse: 'O Frank mandou isso.'
frameName: Ordinal_numbers
frameID: 547
luName: terceiro.a
luID: 26324
lu_idx: [(4, 11, 453)]
fe_idx: [(-1, -1, 'Comparison_set', 4431), (-1, -1, 'Type', 4427), (13, 18, 'Item', 4430)]
tokenized_text: E o terceiro garoto disse : ' O Frank mandou isso . '
tokenized_lu_idx: ['-', '-', 'terceiro.a', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', 'Ordinal_numbers', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', 'Item', '-', '-', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 10012)====
text: So you were probably steered benignly away from things at school when you were a kid, things you liked, on the grounds that you would never get a job doing that.
frameName: Temporal_collocation
frameID: 838
luName: when.adv
luID: 24707
lu_idx: [(65, 68, 1)]
fe_idx: [(70, 83, 'Landmark_period', 8243), (3, 63, 'Trajector_event', 8244)]
tokenized_text: So you were probably steered benignly away from things at school when you were a kid , things you liked , on the grounds that you would never get a job doing that .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'when.adv', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Temporal_collocation', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', 'Trajector_event', 'Trajector_event', 'Trajector_event', 'Trajector_event', 'Trajector_event', 'Trajector_event', 'Trajector_event', 'Trajector_event', 'Trajector_event', 'Trajector_event', '-', 'Landmark_period', 'Landmark_period', 'Landmark_period', 'Landmark_period', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 6726)====
text: Então você era bondosamente afastado na escola quando era criança de certas coisas, coisas que gostava, com a premissa que você nunca iria conseguir um emprego fazendo aquilo.
frameName: Temporal_collocation
frameID: 838
luName: quando.c
luID: 26491
lu_idx: [(47, 52, 453)]
fe_idx: []
tokenized_text: Então você era bondosamente afastado na escola quando era criança de certas coisas , coisas que gostava , com a premissa que você nunca iria conseguir um emprego fazendo aquilo .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', 'quando.c', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', 'Temporal_collocation', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 10084)====
text: If you think of it, the whole system of public education around the world is a protracted process of university entrance.
frameName: Process
frameID: 209
luName: process.n
luID: 18138
lu_idx: [(90, 96, 1)]
fe_idx: [(79, 88, 'Manner', 1342), (98, 119, 'Process', 1339)]
tokenized_text: If you think of it , the whole system of public education around the world is a protracted process of university entrance .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'process.n', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Process', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Manner', '-', 'Process', 'Process', 'Process', '-']

====Annotation (`annoID` = 6942)====
text: Se você for pensar, todo o sistema de educação pública ao redor do mundo é um extensão do processo de ingresso à universidade.
frameName: Process
frameID: 209
luName: processo.n
luID: 28332
lu_idx: [(90, 97, 453)]
fe_idx: [(99, 124, 'Result', 1343), (-1, -1, 'Process', 1339)]
tokenized_text: Se você for pensar , todo o sistema de educação pública ao redor do mundo é um extensão do processo de ingresso à universidade .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'processo.n', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Process', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Result', 'Result', 'Result', 'Result', '-']

===============================
====Annotation (`annoID` = 9633)====
text: He didn't want to come to Los Angeles.
frameName: Desiring
frameID: 338
luName: want.v
luID: 20296
lu_idx: [(10, 13, 1)]
fe_idx: [(15, 36, 'Event', 2469), (0, 1, 'Experiencer', 2467)]
tokenized_text: He did n't want to come to Los Angeles .
tokenized_lu_idx: ['-', '-', '-', 'want.v', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', 'Desiring', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['Experiencer', '-', '-', '-', 'Event', 'Event', 'Event', 'Event', 'Event', '-']

====Annotation (`annoID` = 1259)====
text: Ele não queria vir para Los Angeles.
frameName: Desiring
frameID: 338
luName: querer.v
luID: 26406
lu_idx: [(8, 13, 453)]
fe_idx: [(-1, -1, 'Focal_participant', 2472), (19, 34, 'Location_of_event', 2486), (15, 17, 'Event', 2469), (0, 2, 'Experiencer', 2467)]
tokenized_text: Ele não queria vir para Los Angeles .
tokenized_lu_idx: ['-', '-', 'querer.v', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', 'Desiring', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['Experiencer', '-', '-', 'Event', 'Location_of_event', 'Location_of_event', 'Location_of_event', '-']

===============================
====Annotation (`annoID` = 2412)====
text: Actually, we lived in a place called Snitterfield, just outside Stratford, which is where Shakespeare's father was born.
frameName: Residence
frameID: 100
luName: live.v
luID: 15831
lu_idx: [(13, 17, 1)]
fe_idx: [(19, 118, 'Location', 426), (10, 11, 'Resident', 425)]
tokenized_text: Actually , we lived in a place called Snitterfield , just outside Stratford , which is where Shakespeare 's father was born .
tokenized_lu_idx: ['-', '-', '-', 'live.v', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', 'Residence', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', 'Resident', '-', 'Location', 'Location', 'Location', 'Location', 'Location', 'Location', 'Location', 'Location', 'Location', 'Location', 'Location', 'Location', 'Location', 'Location', 'Location', 'Location', 'Location', 'Location', '-']

====Annotation (`annoID` = 1076)====
text: Na verdade, nós moramos numa cidade chamada Snitterfield, na periferia de Stratford, que foi onde o pai do Shakespeare nasceu.
frameName: Residence
frameID: 100
luName: morar.v
luID: 26347
lu_idx: [(16, 22, 453)]
fe_idx: [(24, 82, 'Location', 426), (12, 14, 'Resident', 425)]
tokenized_text: Na verdade , nós moramos numa cidade chamada Snitterfield , na periferia de Stratford , que foi onde o pai do Shakespeare nasceu .
tokenized_lu_idx: ['-', '-', '-', '-', 'morar.v', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', 'Residence', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', 'Resident', '-', 'Location', 'Location', 'Location', 'Location', 'Location', 'Location', 'Location', 'Location', 'Location', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 10152)====
text: We need to radically rethink our view of intelligence.
frameName: Opinion
frameID: 642
luName: view.n
luID: 23707
lu_idx: [(33, 36, 1)]
fe_idx: [(38, 52, 'Topic', 5231), (29, 31, 'Cognizer', 5228), (33, 36, 'Opinion', 5229)]
tokenized_text: We need to radically rethink our view of intelligence .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', 'view.n', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', 'Opinion', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', 'Cognizer', 'Opinion', 'Topic', 'Topic', '-']

====Annotation (`annoID` = 7287)====
text: Precisamos repensar radicalmente nossa visão de inteligência.
frameName: Opinion
frameID: 642
luName: visão.n
luID: 26380
lu_idx: [(39, 43, 453)]
fe_idx: [(-1, -1, 'Opinion', 5229), (33, 37, 'Cognizer', 5228), (45, 59, 'Topic', 5231)]
tokenized_text: Precisamos repensar radicalmente nossa visão de inteligência .
tokenized_lu_idx: ['-', '-', '-', '-', 'visão.n', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', 'Opinion', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', 'Cognizer', '-', 'Topic', 'Topic', '-']

===============================
====Annotation (`annoID` = 4473)====
text: What these things have in common is that kids will take a chance.
frameName: Commonality
frameID: 1108
luName: in common.a
luID: 25742
lu_idx: [(23, 31, 1)]
fe_idx: [(36, 63, 'Commonality', 10292), (5, 16, 'Entities', 10290)]
tokenized_text: What these things have in common is that kids will take a chance .
tokenized_lu_idx: ['-', '-', '-', '-', 'in common.a', 'in common.a', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', 'Commonality', 'Commonality', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', 'Entities', 'Entities', '-', '-', '-', '-', 'Commonality', 'Commonality', 'Commonality', 'Commonality', 'Commonality', 'Commonality', '-']

====Annotation (`annoID` = 1149)====
text: O que essas histórias tem em comum é que as crianças correm riscos.
frameName: Commonality
frameID: 1108
luName: comum.a
luID: 26402
lu_idx: [(29, 33, 453)]
fe_idx: [(-1, -1, 'Commonality', 10292), (-1, -1, 'Entities', 10290)]
tokenized_text: O que essas histórias tem em comum é que as crianças correm riscos .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', 'comum.a', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', 'Commonality', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 9625)====
text: Because you don't think of Shakespeare being a child, do you?
frameName: Causation
frameID: 1
luName: because.c
luID: 12518
lu_idx: [(0, 6, 1)]
fe_idx: [(8, 51, 'Cause', 3), (-1, -1, 'Effect', 5)]
tokenized_text: Because you do n't think of Shakespeare being a child , do you ?
tokenized_lu_idx: ['because.c', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['Causation', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', 'Cause', 'Cause', 'Cause', 'Cause', 'Cause', 'Cause', 'Cause', 'Cause', 'Cause', '-', '-', '-', '-']

====Annotation (`annoID` = 1176)====
text: Porque você nunca pensou no Shakespeare criança, pensou?
frameName: Causation
frameID: 1
luName: porque.c
luID: 26364
lu_idx: [(0, 5, 453)]
fe_idx: [(7, 46, 'Cause', 3), (-1, -1, 'Effect', 5)]
tokenized_text: Porque você nunca pensou no Shakespeare criança , pensou ?
tokenized_lu_idx: ['porque.c', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['Causation', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', 'Cause', 'Cause', 'Cause', 'Cause', 'Cause', 'Cause', '-', '-', '-']

===============================
====Annotation (`annoID` = 9940)====
text: But James got the part of Joseph, which we were thrilled about.
frameName: Concessive
frameID: 952
luName: but.c
luID: 25179
lu_idx: [(0, 2, 1)]
fe_idx: [(4, 31, 'Conceded_state_of_affairs', 9102), (34, 38, 'Conceded_state_of_affairs', 9102)]
tokenized_text: But James got the part of Joseph , which we were thrilled about .
tokenized_lu_idx: ['but.c', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['Concessive', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', 'Conceded_state_of_affairs', 'Conceded_state_of_affairs', 'Conceded_state_of_affairs', 'Conceded_state_of_affairs', 'Conceded_state_of_affairs', 'Conceded_state_of_affairs', '-', 'Conceded_state_of_affairs', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 6600)====
text: Mas o James ganhou o papel de José, o que nos deixou empolgados.
frameName: Concessive
frameID: 952
luName: mas.c
luID: 26438
lu_idx: [(0, 2, 453)]
fe_idx: [(4, 33, 'Conceded_state_of_affairs', 9102), (-1, -1, 'Main_assertion', 9104)]
tokenized_text: Mas o James ganhou o papel de José , o que nos deixou empolgados .
tokenized_lu_idx: ['mas.c', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['Concessive', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', 'Conceded_state_of_affairs', 'Conceded_state_of_affairs', 'Conceded_state_of_affairs', 'Conceded_state_of_affairs', 'Conceded_state_of_affairs', 'Conceded_state_of_affairs', 'Conceded_state_of_affairs', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 2420)====
text: So you can imagine what a seamless transition that was.
frameName: Capability
frameID: 496
luName: can.v
luID: 22693
lu_idx: [(7, 9, 1)]
fe_idx: [(3, 5, 'Entity', 3999), (11, 53, 'Event', 4000)]
tokenized_text: So you can imagine what a seamless transition that was .
tokenized_lu_idx: ['-', '-', 'can.v', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', 'Capability', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', 'Entity', '-', 'Event', 'Event', 'Event', 'Event', 'Event', 'Event', 'Event', '-']

====Annotation (`annoID` = 1124)====
text: Vocês podem imaginar a mudança suave que foi.
frameName: Capability
frameID: 496
luName: poder.v
luID: 26355
lu_idx: [(6, 10, 453)]
fe_idx: [(12, 43, 'Event', 4000), (0, 4, 'Entity', 3999)]
tokenized_text: Vocês podem imaginar a mudança suave que foi .
tokenized_lu_idx: ['-', 'poder.v', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', 'Capability', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['Entity', '-', 'Event', 'Event', 'Event', 'Event', 'Event', 'Event', '-']

===============================
====Annotation (`annoID` = 10281)====
text: And the school, in the '30s, wrote to her parents and said, 'We think Gillian has a learning disorder.'
frameName: Kinship
frameID: 95
luName: parent.n
luID: 15703
lu_idx: [(42, 48, 1)]
fe_idx: [(38, 40, 'Ego', 414), (42, 48, 'Alter', 413)]
tokenized_text: And the school , in the ' 30s , wrote to her parents and said , ' We think Gillian has a learning disorder . '
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'parent.n', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Kinship', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Ego', 'Alter', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 7550)====
text: E a escola, nos anos 30, escreveu para os pais dizendo: 'Achamos que a Gillian tem dificuldade de aprendizado.'
frameName: Kinship
frameID: 95
luName: pai.n
luID: 26361
lu_idx: [(42, 45, 453)]
fe_idx: [(-1, -1, 'Ego', 414), (-1, -1, 'Alter', 413)]
tokenized_text: E a escola , nos anos 30 , escreveu para os pais dizendo : ' Achamos que a Gillian tem dificuldade de aprendizado . '
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'pai.n', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Kinship', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 10109)====
text: When I was a student, if you had a degree, you had a job.
frameName: Temporal_collocation
frameID: 838
luName: when.adv
luID: 24707
lu_idx: [(0, 3, 1)]
fe_idx: [(22, 40, 'Event_description', 8186), (5, 19, 'Landmark_period', 8243), (43, 55, 'Trajector_event', 8244)]
tokenized_text: When I was a student , if you had a degree , you had a job .
tokenized_lu_idx: ['when.adv', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['Temporal_collocation', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', 'Landmark_period', 'Landmark_period', 'Landmark_period', 'Landmark_period', '-', 'Event_description', 'Event_description', 'Event_description', 'Event_description', 'Event_description', '-', 'Trajector_event', 'Trajector_event', 'Trajector_event', 'Trajector_event', '-']

====Annotation (`annoID` = 7296)====
text: Quando eu estudava, quem tinha um diploma, tinha um emprego.
frameName: Temporal_collocation
frameID: 838
luName: quando.c
luID: 26491
lu_idx: [(0, 5, 453)]
fe_idx: [(7, 17, 'Landmark_event', 7736), (20, 58, 'Trajector_event', 8244)]
tokenized_text: Quando eu estudava , quem tinha um diploma , tinha um emprego .
tokenized_lu_idx: ['quando.c', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['Temporal_collocation', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', 'Landmark_event', 'Landmark_event', '-', 'Trajector_event', 'Trajector_event', 'Trajector_event', 'Trajector_event', 'Trajector_event', 'Trajector_event', 'Trajector_event', 'Trajector_event', '-']

===============================
====Annotation (`annoID` = 4266)====
text: So the unpredictability, I think, is extraordinary.
frameName: Expectation
frameID: 21
luName: unpredictability.n
luID: 27211
lu_idx: [(7, 22, 1)]
fe_idx: [(-1, -1, 'Topic', 6699), (-1, -1, 'Cognizer', 83)]
tokenized_text: So the unpredictability , I think , is extraordinary .
tokenized_lu_idx: ['-', '-', 'unpredictability.n', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', 'Expectation', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 4377)====
text: A imprevisibilidade, pra mim, é extraordinária.
frameName: Expectation
frameID: 21
luName: imprevisibilidade.n
luID: 27274
lu_idx: [(2, 18, 453)]
fe_idx: [(-1, -1, 'Phenomenon', 84), (-1, -1, 'Cognizer', 83)]
tokenized_text: A imprevisibilidade , pra mim , é extraordinária .
tokenized_lu_idx: ['-', 'imprevisibilidade.n', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', 'Expectation', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 2476)====
text: And the minute they left the room, she was on her feet, moving to the music.
frameName: Departing
frameID: 51
luName: leave.v
luID: 14039
lu_idx: [(20, 23, 1)]
fe_idx: [(25, 32, 'Source', 207), (15, 18, 'Theme', 206)]
tokenized_text: And the minute they left the room , she was on her feet , moving to the music .
tokenized_lu_idx: ['-', '-', '-', '-', 'leave.v', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', 'Departing', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', 'Theme', '-', 'Source', 'Source', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 7251)====
text: E assim que eles deixaram a sala, ela disse, ela estava de pé, se movendo com a música.
frameName: Departing
frameID: 51
luName: deixar.v
luID: 26488
lu_idx: [(17, 24, 453)]
fe_idx: [(26, 31, 'Source', 207), (12, 15, 'Theme', 206)]
tokenized_text: E assim que eles deixaram a sala , ela disse , ela estava de pé , se movendo com a música .
tokenized_lu_idx: ['-', '-', '-', '-', 'deixar.v', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', 'Departing', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', 'Theme', '-', 'Source', 'Source', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 9860)====
text: Truthfully, what happens is, as children grow up, we start to educate them progressively from the waist up.
frameName: Event
frameID: 168
luName: happen.v
luID: 17170
lu_idx: [(17, 23, 1)]
fe_idx: [(50, 105, 'Event', 903)]
tokenized_text: Truthfully , what happens is , as children grow up , we start to educate them progressively from the waist up .
tokenized_lu_idx: ['-', '-', '-', 'happen.v', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', 'Event', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Event', 'Event', 'Event', 'Event', 'Event', 'Event', 'Event', 'Event', 'Event', 'Event', '-']

====Annotation (`annoID` = 1585)====
text: Sério, o que acontece é que à medida que as crianças crescem, nós começamos a educá-las progressivamente da cintura para cima.
frameName: Event
frameID: 168
luName: acontecer.v
luID: 26335
lu_idx: [(13, 20, 453)]
fe_idx: [(-1, -1, 'Place', 904), (28, 59, 'Time', 906), (7, 11, 'Event', 903), (66, 124, 'Event', 903)]
tokenized_text: Sério , o que acontece é que à medida que as crianças crescem , nós começamos a educá-las progressivamente da cintura para cima .
tokenized_lu_idx: ['-', '-', '-', '-', 'acontecer.v', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', 'Event', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', 'Event', 'Event', '-', '-', '-', 'Time', 'Time', 'Time', 'Time', 'Time', 'Time', '-', '-', 'Event', 'Event', 'Event', 'Event', 'Event', 'Event', 'Event', 'Event', '-']

===============================
====Annotation (`annoID` = 10349)====
text: And the only way we'll do it is by seeing our creative capacities for the richness they are and seeing our children for the hope that they are.
frameName: Sole_instance
frameID: 327
luName: only.a
luID: 20012
lu_idx: [(8, 11, 1)]
fe_idx: [(4, 27, 'Item', 2747), (13, 27, 'Type', 2748)]
tokenized_text: And the only way we 'll do it is by seeing our creative capacities for the richness they are and seeing our children for the hope that they are .
tokenized_lu_idx: ['-', '-', 'only.a', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', 'Sole_instance', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', 'Item', 'Item', 'Type', 'Type', 'Type', 'Type', 'Type', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 6814)====
text: E a única maneira de fazer isso é encarando nossa capacidade criativa pela riqueza que ela representa e nossas crianças pela esperança que elas representam.
frameName: Sole_instance
frameID: 327
luName: único.a
luID: 26651
lu_idx: [(4, 8, 453)]
fe_idx: [(10, 16, 'Type', 2748), (34, 154, 'Item', 2747)]
tokenized_text: E a única maneira de fazer isso é encarando nossa capacidade criativa pela riqueza que ela representa e nossas crianças pela esperança que elas representam .
tokenized_lu_idx: ['-', '-', 'único.a', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', 'Sole_instance', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', 'Type', '-', '-', '-', '-', 'Item', 'Item', 'Item', 'Item', 'Item', 'Item', 'Item', 'Item', 'Item', 'Item', 'Item', 'Item', 'Item', 'Item', 'Item', 'Item', 'Item', '-']

===============================
====Annotation (`annoID` = 9634)====
text: He loved it, but he had a girlfriend in England.
frameName: Experiencer_focus
frameID: 42
luName: love.v
luID: 13809
lu_idx: [(3, 7, 1)]
fe_idx: [(0, 1, 'Experiencer', 168), (9, 10, 'Content', 169)]
tokenized_text: He loved it , but he had a girlfriend in England .
tokenized_lu_idx: ['-', 'love.v', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', 'Experiencer_focus', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['Experiencer', '-', 'Content', '-', '-', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 1287)====
text: Ele adorava, mas tinha uma namorada na Inglaterra.
frameName: Experiencer_focus
frameID: 42
luName: adorar.v
luID: 26437
lu_idx: [(4, 10, 453)]
fe_idx: [(-1, -1, 'Topic', 2511), (-1, -1, 'Content', 169), (0, 2, 'Experiencer', 168), (-1, -1, 'Event', 2552)]
tokenized_text: Ele adorava , mas tinha uma namorada na Inglaterra .
tokenized_lu_idx: ['-', 'adorar.v', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', 'Experiencer_focus', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['Experiencer', '-', '-', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 10247)====
text: I saw a great t-shirt recently, which said, 'If a man speaks his mind in a forest, and no woman hears him, is he still wrong?'
frameName: Desirability
frameID: 326
luName: great.a
luID: 19972
lu_idx: [(8, 12, 1)]
fe_idx: [(14, 20, 'Evaluee', 2309)]
tokenized_text: I saw a great t-shirt recently , which said , ' If a man speaks his mind in a forest , and no woman hears him , is he still wrong ? '
tokenized_lu_idx: ['-', '-', '-', 'great.a', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', 'Desirability', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', 'Evaluee', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 7624)====
text: Vi uma camiseta excelente esses dias que dizia: 'Se um homem fala o que pensa numa floresta, e nenhuma mulher escuta, ele continua errado?'
frameName: Desirability
frameID: 326
luName: excelente.a
luID: 26546
lu_idx: [(16, 24, 453)]
fe_idx: [(3, 14, 'Evaluee', 2309)]
tokenized_text: Vi uma camiseta excelente esses dias que dizia : ' Se um homem fala o que pensa numa floresta , e nenhuma mulher escuta , ele continua errado ? '
tokenized_lu_idx: ['-', '-', '-', 'excelente.a', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', 'Desirability', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', 'Evaluee', 'Evaluee', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 10319)====
text: We have to rethink the fundamental principles on which we're educating our children.
frameName: Importance
frameID: 376
luName: fundamental.a
luID: 21025
lu_idx: [(23, 33, 1)]
fe_idx: [(35, 44, 'Factor', 2835)]
tokenized_text: We have to rethink the fundamental principles on which we 're educating our children .
tokenized_lu_idx: ['-', '-', '-', '-', '-', 'fundamental.a', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', 'Importance', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', 'Factor', '-', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 2331)====
text: Temos que repensar os princípios fundamentais que baseamos a educação de nossas crianças.
frameName: Importance
frameID: 376
luName: fundamental.a
luID: 26672
lu_idx: [(33, 44, 453)]
fe_idx: [(-1, -1, 'Interested_party', 2853), (22, 31, 'Factor', 2835)]
tokenized_text: Temos que repensar os princípios fundamentais que baseamos a educação de nossas crianças .
tokenized_lu_idx: ['-', '-', '-', '-', '-', 'fundamental.a', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', 'Importance', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', 'Factor', '-', '-', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 9957)====
text: They look upon their body as a form of transport for their heads.
frameName: Body_parts
frameID: 108
luName: head.n
luID: 16094
lu_idx: [(59, 63, 1)]
fe_idx: [(53, 57, 'Possessor', 472), (59, 63, 'Body_part', 516)]
tokenized_text: They look upon their body as a form of transport for their heads .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'head.n', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Body_parts', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Possessor', 'Body_part', '-']

====Annotation (`annoID` = 2371)====
text: Eles vêem o próprio corpo como uma forma de transporte para a cabeça.
frameName: Body_parts
frameID: 108
luName: cabeça.n
luID: 26316
lu_idx: [(62, 67, 453)]
fe_idx: [(0, 3, 'Possessor', 472), (-1, -1, 'Body_part', 516)]
tokenized_text: Eles vêem o próprio corpo como uma forma de transporte para a cabeça .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'cabeça.n', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Body_parts', '-']
tokenized_fe_idx: ['Possessor', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 4194)====
text: We walked in this room and it was full of people like me.
frameName: People
frameID: 278
luName: people.n
luID: 19342
lu_idx: [(42, 47, 1)]
fe_idx: [(42, 47, 'Person', 1854)]
tokenized_text: We walked in this room and it was full of people like me .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'people.n', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'People', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Person', '-', '-', '-']

====Annotation (`annoID` = 7416)====
text: Entramos numa sala cheia de pessoas como eu.
frameName: People
frameID: 278
luName: pessoa.n
luID: 26555
lu_idx: [(28, 34, 453)]
fe_idx: [(-1, -1, 'Person', 1854)]
tokenized_text: Entramos numa sala cheia de pessoas como eu .
tokenized_lu_idx: ['-', '-', '-', '-', '-', 'pessoa.n', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', 'People', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 2519)====
text: If you think of it, children starting school this year will be retiring in 2065.
frameName: Calendric_unit
frameID: 206
luName: year.n
luID: 18087
lu_idx: [(50, 53, 1)]
fe_idx: [(50, 53, 'Unit', 7052), (45, 48, 'Landmark_period', 11406)]
tokenized_text: If you think of it , children starting school this year will be retiring in 2065 .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'year.n', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Calendric_unit', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', 'Landmark_period', 'Unit', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 4356)====
text: Se formos pensar, as crianças entrando na escola esse ano estarão se aposentando em 2065.
frameName: Calendric_unit
frameID: 206
luName: ano.n
luID: 26349
lu_idx: [(54, 56, 453)]
fe_idx: [(-1, -1, 'Unit', 7052), (49, 52, 'Relative_time', 1318)]
tokenized_text: Se formos pensar , as crianças entrando na escola esse ano estarão se aposentando em 2065 .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'ano.n', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Calendric_unit', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', 'Relative_time', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 9843)====
text: I think this is rather important.
frameName: Importance
frameID: 376
luName: important.a
luID: 21016
lu_idx: [(23, 31, 1)]
fe_idx: [(-1, -1, 'Undertaking', 2837), (8, 11, 'Factor', 2835), (16, 21, 'Degree', 2836)]
tokenized_text: I think this is rather important .
tokenized_lu_idx: ['-', '-', '-', '-', '-', 'important.a', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', 'Importance', '-']
tokenized_fe_idx: ['-', '-', 'Factor', '-', 'Degree', '-', '-']

====Annotation (`annoID` = 1539)====
text: Eu acho bastante importante.
frameName: Importance
frameID: 376
luName: importante.a
luID: 26551
lu_idx: [(17, 26, 453)]
fe_idx: [(-1, -1, 'Undertaking', 2837), (-1, -1, 'Interested_party', 2853), (-1, -1, 'Field', 2854), (-1, -1, 'Factor', 2835), (8, 15, 'Degree', 2836)]
tokenized_text: Eu acho bastante importante .
tokenized_lu_idx: ['-', '-', '-', 'importante.a', '-']
tokenized_frame_idx: ['-', '-', '-', 'Importance', '-']
tokenized_fe_idx: ['-', '-', 'Degree', '-', '-']

===============================
====Annotation (`annoID` = 4416)====
text: I find this very interesting.
frameName: Degree
frameID: 882
luName: very.adv
luID: 24909
lu_idx: [(12, 15, 1)]
fe_idx: [(17, 27, 'Gradable_attribute', 8257)]
tokenized_text: I find this very interesting .
tokenized_lu_idx: ['-', '-', '-', 'very.adv', '-', '-']
tokenized_frame_idx: ['-', '-', '-', 'Degree', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', 'Gradable_attribute', '-']

====Annotation (`annoID` = 4302)====
text: Eu acho isso muito interessante.
frameName: Degree
frameID: 882
luName: muito.adv
luID: 27233
lu_idx: [(13, 17, 453)]
fe_idx: [(19, 30, 'Gradable_attribute', 8257)]
tokenized_text: Eu acho isso muito interessante .
tokenized_lu_idx: ['-', '-', '-', 'muito.adv', '-', '-']
tokenized_frame_idx: ['-', '-', '-', 'Degree', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', 'Gradable_attribute', '-']

===============================
====Annotation (`annoID` = 10260)====
text: And the third thing about intelligence is, it's distinct.
frameName: Topic
frameID: 343
luName: about.prep
luID: 20457
lu_idx: [(20, 24, 1)]
fe_idx: [(26, 37, 'Topic', 2452), (4, 18, 'Text', 2453)]
tokenized_text: And the third thing about intelligence is , it 's distinct .
tokenized_lu_idx: ['-', '-', '-', '-', 'about.prep', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', 'Topic', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', 'Text', 'Text', 'Text', '-', 'Topic', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 7469)====
text: O terceiro ponto sobre a inteligência é que é distinta.
frameName: Topic
frameID: 343
luName: sobre.prep
luID: 26435
lu_idx: [(17, 21, 453)]
fe_idx: [(23, 36, 'Topic', 2452), (-1, -1, 'Communicator', 2454), (-1, -1, 'Text', 2453)]
tokenized_text: O terceiro ponto sobre a inteligência é que é distinta .
tokenized_lu_idx: ['-', '-', '-', 'sobre.prep', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', 'Topic', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', 'Topic', 'Topic', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 2465)====
text: They look upon their body as a form of transport for their heads.
frameName: Bringing
frameID: 216
luName: transport.n
luID: 18309
lu_idx: [(39, 47, 1)]
fe_idx: [(49, 63, 'Theme', 1419)]
tokenized_text: They look upon their body as a form of transport for their heads .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', 'transport.n', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', 'Bringing', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Theme', 'Theme', 'Theme', '-']

====Annotation (`annoID` = 6888)====
text: Eles vêem o próprio corpo como uma forma de transporte para a cabeça.
frameName: Bringing
frameID: 216
luName: transporte.n
luID: 28306
lu_idx: [(44, 53, 453)]
fe_idx: [(-1, -1, 'Area', 1421), (10, 24, 'Carrier', 3500), (55, 67, 'Theme', 1419)]
tokenized_text: Eles vêem o próprio corpo como uma forma de transporte para a cabeça .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', 'transporte.n', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', 'Bringing', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', 'Carrier', 'Carrier', 'Carrier', '-', '-', '-', '-', '-', 'Theme', 'Theme', 'Theme', '-']

===============================
====Annotation (`annoID` = 9991)====
text: And there's a reason.
frameName: Existence
frameID: 437
luName: there be.v
luID: 21981
lu_idx: [(4, 10, 1)]
fe_idx: [(12, 19, 'Entity', 3193)]
tokenized_text: And there 's a reason .
tokenized_lu_idx: ['-', 'there be.v', 'there be.v', '-', '-', '-']
tokenized_frame_idx: ['-', 'Existence', 'Existence', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', 'Entity', 'Entity', '-']

====Annotation (`annoID` = 1097)====
text: E existe uma razão para isso.
frameName: Existence
frameID: 437
luName: existir.v
luID: 26289
lu_idx: [(2, 7, 453)]
fe_idx: [(9, 17, 'Entity', 3193), (19, 27, 'Inherent_purpose', 3196)]
tokenized_text: E existe uma razão para isso .
tokenized_lu_idx: ['-', 'existir.v', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', 'Existence', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', 'Entity', 'Entity', 'Inherent_purpose', 'Inherent_purpose', '-']

===============================
====Annotation (`annoID` = 8839)====
text: Anyway, Gillian and I had lunch one day and I said, 'How did you get to be a dancer?'
frameName: Calendric_unit
frameID: 206
luName: one day.n
luID: 18122
lu_idx: [(32, 34, 1), (36, 38, 1)]
fe_idx: [(32, 38, 'Unit', 7052)]
tokenized_text: Anyway , Gillian and I had lunch one day and I said , ' How did you get to be a dancer ? '
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', 'one day.n', 'one day.n', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', 'Calendric_unit', 'Calendric_unit', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', 'Unit', 'Unit', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 7533)====
text: Gillian e eu almoçamos um dia e eu perguntei: 'Gillian, como você se tornou dançarina?'
frameName: Calendric_unit
frameID: 206
luName: dia.n
luID: 27270
lu_idx: [(26, 28, 453)]
fe_idx: [(-1, -1, 'Unit', 7052), (23, 24, 'Relative_time', 1318)]
tokenized_text: Gillian e eu almoçamos um dia e eu perguntei : ' Gillian , como você se tornou dançarina ? '
tokenized_lu_idx: ['-', '-', '-', '-', '-', 'dia.n', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', 'Calendric_unit', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', 'Relative_time', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 10060)====
text: If you think of it, the whole system of public education around the world is a protracted process of university entrance.
frameName: Political_locales
frameID: 175
luName: world.n
luID: 17538
lu_idx: [(68, 72, 1)]
fe_idx: [(68, 72, 'Locale', 1002)]
tokenized_text: If you think of it , the whole system of public education around the world is a protracted process of university entrance .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'world.n', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Political_locales', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Locale', '-', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 1332)====
text: Se você for pensar, todo o sistema de educação pública ao redor do mundo é um extensão do processo de ingresso à universidade.
frameName: Political_locales
frameID: 175
luName: mundo.n
luID: 26327
lu_idx: [(67, 71, 453)]
fe_idx: [(-1, -1, 'Locale', 1002)]
tokenized_text: Se você for pensar , todo o sistema de educação pública ao redor do mundo é um extensão do processo de ingresso à universidade .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'mundo.n', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Political_locales', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 10154)====
text: We know three things about intelligence.
frameName: Cardinal_numbers
frameID: 196
luName: three.num
luID: 17845
lu_idx: [(8, 12, 1)]
fe_idx: [(8, 12, 'Number', 2715), (14, 19, 'Entity', 2716)]
tokenized_text: We know three things about intelligence .
tokenized_lu_idx: ['-', '-', 'three.num', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', 'Cardinal_numbers', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', 'Number', 'Entity', '-', '-', '-']

====Annotation (`annoID` = 1153)====
text: Sabemos três coisas sobre inteligência.
frameName: Cardinal_numbers
frameID: 196
luName: três.num
luID: 26311
lu_idx: [(8, 11, 453)]
fe_idx: [(-1, -1, 'Number', 2715), (13, 18, 'Entity', 2716)]
tokenized_text: Sabemos três coisas sobre inteligência .
tokenized_lu_idx: ['-', 'três.num', '-', '-', '-', '-']
tokenized_frame_idx: ['-', 'Cardinal_numbers', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', 'Entity', '-', '-', '-']

===============================
====Annotation (`annoID` = 9581)====
text: When my son was four in England -- 
frameName: Temporal_collocation
frameID: 838
luName: when.adv
luID: 24707
lu_idx: [(0, 3, 1)]
fe_idx: [(5, 30, 'Landmark_period', 8243)]
tokenized_text: When my son was four in England --
tokenized_lu_idx: ['when.adv', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['Temporal_collocation', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', 'Landmark_period', 'Landmark_period', 'Landmark_period', 'Landmark_period', 'Landmark_period', 'Landmark_period', '-']

====Annotation (`annoID` = 6568)====
text: Quando meu filho tinha quatro anos na Inglaterra...
frameName: Temporal_collocation
frameID: 838
luName: quando.c
luID: 26491
lu_idx: [(0, 5, 453)]
fe_idx: [(7, 47, 'Landmark_period', 8243), (-1, -1, 'Trajector_event', 8244)]
tokenized_text: Quando meu filho tinha quatro anos na Inglaterra ...
tokenized_lu_idx: ['quando.c', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['Temporal_collocation', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', 'Landmark_period', 'Landmark_period', 'Landmark_period', 'Landmark_period', 'Landmark_period', 'Landmark_period', 'Landmark_period', '-']

===============================
====Annotation (`annoID` = 4521)====
text: I lived in Stratford-on-Avon until about five years ago.
frameName: Time_vector
frameID: 349
luName: ago.idio
luID: 20535
lu_idx: [(52, 54, 1)]
fe_idx: [(-1, -1, 'Landmark_event', 2501), (35, 50, 'Distance', 2502)]
tokenized_text: I lived in Stratford-on-Avon until about five years ago .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', 'ago.idio', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', 'Time_vector', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', 'Distance', 'Distance', 'Distance', '-', '-']

====Annotation (`annoID` = 2245)====
text: Eu morei em Stratford-on-Avon até cinco anos atrás.
frameName: Time_vector
frameID: 349
luName: atrás.adv
luID: 26634
lu_idx: [(45, 49, 453)]
fe_idx: [(30, 43, 'Distance', 2502), (-1, -1, 'Landmark_event', 2501), (0, 28, 'Event', 3489)]
tokenized_text: Eu morei em Stratford-on-Avon até cinco anos atrás .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', 'atrás.adv', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', 'Time_vector', '-']
tokenized_fe_idx: ['Event', 'Event', 'Event', 'Event', 'Distance', 'Distance', 'Distance', '-', '-']

===============================
====Annotation (`annoID` = 10064)====
text: And the second is academic ability, which has really come to dominate our view of intelligence, because the universities designed the system in their image.
frameName: System
frameID: 727
luName: system.n
luID: 24129
lu_idx: [(134, 139, 1)]
fe_idx: [(134, 139, 'Complex', 5996)]
tokenized_text: And the second is academic ability , which has really come to dominate our view of intelligence , because the universities designed the system in their image .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'system.n', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'System', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Complex', '-', '-', '-', '-']

====Annotation (`annoID` = 1315)====
text: A segunda é a aptidão acadêmica, que veio a dominar nossa visão de inteligência, porque as universidades planejaram o sistema à sua própria imagem.
frameName: System
frameID: 727
luName: sistema.n
luID: 26471
lu_idx: [(118, 124, 453)]
fe_idx: [(-1, -1, 'Function', 5997), (-1, -1, 'Complex', 5996), (-1, -1, 'Salient_entity', 6008), (-1, -1, 'Component_entities', 5995)]
tokenized_text: A segunda é a aptidão acadêmica , que veio a dominar nossa visão de inteligência , porque as universidades planejaram o sistema à sua própria imagem .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'sistema.n', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'System', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 8835)====
text: People who had to move to think.'
frameName: People
frameID: 278
luName: people.n
luID: 19342
lu_idx: [(0, 5, 1)]
fe_idx: [(0, 5, 'Person', 1854)]
tokenized_text: People who had to move to think . '
tokenized_lu_idx: ['people.n', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['People', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['Person', '-', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 6985)====
text: Pessoas que precisavam se mexer para pensar.
frameName: People
frameID: 278
luName: pessoa.n
luID: 26555
lu_idx: [(0, 6, 453)]
fe_idx: [(-1, -1, 'Person', 1854)]
tokenized_text: Pessoas que precisavam se mexer para pensar .
tokenized_lu_idx: ['pessoa.n', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['People', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 4519)====
text: We were sitting there and I think they just went out of sequence, because we talked to the little boy afterward and we said, 'You OK with that?'
frameName: Opinion
frameID: 642
luName: think.v
luID: 23709
lu_idx: [(28, 32, 1)]
fe_idx: [(26, 26, 'Cognizer', 5228), (34, 63, 'Opinion', 5229)]
tokenized_text: We were sitting there and I think they just went out of sequence , because we talked to the little boy afterward and we said , ' You OK with that ? '
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', 'think.v', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', 'Opinion', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', 'Cognizer', '-', 'Opinion', 'Opinion', 'Opinion', 'Opinion', 'Opinion', 'Opinion', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 6671)====
text: Estávamos lá sentados e eu acho que eles não seguiram a ordem porque nós conversamos com o garotinho depois e perguntamos: 'Tudo certo?'
frameName: Opinion
frameID: 642
luName: achar.v
luID: 26333
lu_idx: [(27, 30, 453)]
fe_idx: [(24, 25, 'Cognizer', 5228), (32, 34, 'Opinion', 5229), (36, 60, 'Opinion', 5229)]
tokenized_text: Estávamos lá sentados e eu acho que eles não seguiram a ordem porque nós conversamos com o garotinho depois e perguntamos : ' Tudo certo ? '
tokenized_lu_idx: ['-', '-', '-', '-', '-', 'achar.v', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', 'Opinion', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', 'Cognizer', '-', 'Opinion', 'Opinion', 'Opinion', 'Opinion', 'Opinion', 'Opinion', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 10124)====
text: And I didn't want one, frankly.
frameName: Desiring
frameID: 338
luName: want.v
luID: 20296
lu_idx: [(13, 16, 1)]
fe_idx: [(18, 20, 'Focal_participant', 2472), (4, 4, 'Experiencer', 2467)]
tokenized_text: And I did n't want one , frankly .
tokenized_lu_idx: ['-', '-', '-', '-', 'want.v', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', 'Desiring', '-', '-', '-', '-']
tokenized_fe_idx: ['-', 'Experiencer', '-', '-', '-', 'Focal_participant', '-', '-', '-']

====Annotation (`annoID` = 6958)====
text: E eu não queria, francamente.
frameName: Desiring
frameID: 338
luName: querer.v
luID: 26406
lu_idx: [(9, 14, 453)]
fe_idx: [(-1, -1, 'Event', 2469), (2, 3, 'Experiencer', 2467)]
tokenized_text: E eu não queria , francamente .
tokenized_lu_idx: ['-', '-', '-', 'querer.v', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', 'Desiring', '-', '-', '-']
tokenized_fe_idx: ['-', 'Experiencer', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 9861)====
text: Truthfully, what happens is, as children grow up, we start to educate them progressively from the waist up.
frameName: Temporal_collocation
frameID: 838
luName: as.adv
luID: 24724
lu_idx: [(29, 30, 1)]
fe_idx: [(50, 105, 'Trajector_event', 8244), (32, 44, 'Landmark_period', 8243)]
tokenized_text: Truthfully , what happens is , as children grow up , we start to educate them progressively from the waist up .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', 'as.adv', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', 'Temporal_collocation', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', 'Landmark_period', 'Landmark_period', '-', '-', 'Trajector_event', 'Trajector_event', 'Trajector_event', 'Trajector_event', 'Trajector_event', 'Trajector_event', 'Trajector_event', 'Trajector_event', 'Trajector_event', 'Trajector_event', '-']

====Annotation (`annoID` = 6868)====
text: Sério, o que acontece é que à medida que as crianças crescem, nós começamos a educá-las progressivamente da cintura para cima.
frameName: Temporal_collocation
frameID: 838
luName: à medida que.scon
luID: 28300
lu_idx: [(28, 28, 453), (30, 35, 453), (37, 39, 453)]
fe_idx: [(41, 59, 'Landmark_event', 7736), (62, 124, 'Trajector_event', 8244)]
tokenized_text: Sério , o que acontece é que à medida que as crianças crescem , nós começamos a educá-las progressivamente da cintura para cima .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', 'à medida que.scon', 'à medida que.scon', 'à medida que.scon', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', 'Temporal_collocation', 'Temporal_collocation', 'Temporal_collocation', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Landmark_event', 'Landmark_event', 'Landmark_event', '-', 'Trajector_event', 'Trajector_event', 'Trajector_event', 'Trajector_event', 'Trajector_event', 'Trajector_event', 'Trajector_event', 'Trajector_event', 'Trajector_event', '-']

===============================
====Annotation (`annoID` = 2561)====
text: And the girl said, 'They will, in a minute.'
frameName: Statement
frameID: 37
luName: say.v
luID: 13406
lu_idx: [(13, 16, 1)]
fe_idx: [(20, 41, 'Message', 154), (4, 11, 'Speaker', 152)]
tokenized_text: And the girl said , ' They will , in a minute . '
tokenized_lu_idx: ['-', '-', '-', 'say.v', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', 'Statement', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', 'Speaker', 'Speaker', '-', '-', '-', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', '-', '-']

====Annotation (`annoID` = 6564)====
text: E a menina disse: 'Vão conhecer num minuto.'
frameName: Statement
frameID: 37
luName: dizer.v
luID: 26321
lu_idx: [(11, 15, 453)]
fe_idx: [(2, 9, 'Speaker', 152), (19, 41, 'Message', 154)]
tokenized_text: E a menina disse : ' Vão conhecer num minuto . '
tokenized_lu_idx: ['-', '-', '-', 'dizer.v', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', 'Statement', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', 'Speaker', 'Speaker', '-', '-', '-', 'Message', 'Message', 'Message', 'Message', '-', '-']

===============================
====Annotation (`annoID` = 2612)====
text: And slightly to one side.
frameName: Part_orientational
frameID: 131
luName: side.n
luID: 16643
lu_idx: [(20, 23, 1)]
fe_idx: [(20, 23, 'Part', 705)]
tokenized_text: And slightly to one side .
tokenized_lu_idx: ['-', '-', '-', '-', 'side.n', '-']
tokenized_frame_idx: ['-', '-', '-', '-', 'Part_orientational', '-']
tokenized_fe_idx: ['-', '-', '-', '-', 'Part', '-']

====Annotation (`annoID` = 6872)====
text: E levemente para um lado.
frameName: Part_orientational
frameID: 131
luName: lado.n
luID: 26455
lu_idx: [(20, 23, 453)]
fe_idx: [(-1, -1, 'Whole', 707), (-1, -1, 'Part', 705)]
tokenized_text: E levemente para um lado .
tokenized_lu_idx: ['-', '-', '-', '-', 'lado.n', '-']
tokenized_frame_idx: ['-', '-', '-', '-', 'Part_orientational', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 10057)====
text: If you think of it, the whole system of public education around the world is a protracted process of university entrance.
frameName: System
frameID: 727
luName: system.n
luID: 24129
lu_idx: [(30, 35, 1)]
fe_idx: [(77, 119, 'Complex', 5996), (57, 72, 'Descriptor', 6006), (37, 55, 'Function', 5997)]
tokenized_text: If you think of it , the whole system of public education around the world is a protracted process of university entrance .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', 'system.n', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', 'System', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', 'Function', 'Function', 'Function', 'Descriptor', 'Descriptor', 'Descriptor', '-', 'Complex', 'Complex', 'Complex', 'Complex', 'Complex', 'Complex', '-']

====Annotation (`annoID` = 1319)====
text: Se você for pensar, todo o sistema de educação pública ao redor do mundo é um extensão do processo de ingresso à universidade.
frameName: System
frameID: 727
luName: sistema.n
luID: 26471
lu_idx: [(27, 33, 453)]
fe_idx: [(-1, -1, 'Complex', 5996), (35, 53, 'Function', 5997), (20, 23, 'Component_entities', 5995)]
tokenized_text: Se você for pensar , todo o sistema de educação pública ao redor do mundo é um extensão do processo de ingresso à universidade .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', 'sistema.n', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', 'System', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', 'Component_entities', '-', '-', 'Function', 'Function', 'Function', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 2603)====
text: There was a wonderful quote by Jonas Salk, who said, 'If all the insects were to disappear from the Earth, within 50 years all life on Earth would end.
frameName: Statement
frameID: 37
luName: say.v
luID: 13406
lu_idx: [(47, 50, 1)]
fe_idx: [(54, 149, 'Message', 154), (31, 40, 'Speaker', 152), (43, 45, 'Speaker', 152)]
tokenized_text: There was a wonderful quote by Jonas Salk , who said , ' If all the insects were to disappear from the Earth , within 50 years all life on Earth would end .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'say.v', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Statement', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', 'Speaker', 'Speaker', '-', 'Speaker', '-', '-', '-', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', '-']

====Annotation (`annoID` = 2298)====
text: Existe uma frase maravilhosa de Jonas Salk, que diz: 'Se todos os insetos desaparecessem da terra, dentro de 50 anos, toda vida na Terra desapareceria.Se todos os humanos desaparecessem da Terra, dentro de 50 anos todas as formas de vida floresceriam.'
frameName: Statement
frameID: 37
luName: dizer.v
luID: 26321
lu_idx: [(48, 50, 453)]
fe_idx: [(44, 46, 'Speaker', 152), (54, 249, 'Message', 154), (7, 41, 'Speaker', 152)]
tokenized_text: Existe uma frase maravilhosa de Jonas Salk , que diz : ' Se todos os insetos desaparecessem da terra , dentro de 50 anos , toda vida na Terra desapareceria.Se todos os humanos desaparecessem da Terra , dentro de 50 anos todas as formas de vida floresceriam . '
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', 'dizer.v', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', 'Statement', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', 'Speaker', 'Speaker', 'Speaker', 'Speaker', 'Speaker', 'Speaker', '-', 'Speaker', '-', '-', '-', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', '-', '-']

===============================
====Annotation (`annoID` = 9831)====
text: There isn't an education system on the planet that teaches dance every day to children the way we teach them mathematics.
frameName: Existence
frameID: 437
luName: there be.v
luID: 21981
lu_idx: [(6, 8, 1), (1, 4, 1)]
fe_idx: [(46, 49, 'Entity', 3193), (12, 44, 'Entity', 3193)]
tokenized_text: There is n't an education system on the planet that teaches dance every day to children the way we teach them mathematics .
tokenized_lu_idx: ['-', 'there be.v', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', 'Existence', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', 'Entity', 'Entity', 'Entity', 'Entity', 'Entity', 'Entity', 'Entity', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 1297)====
text: Não existe um sistema educacional no planeta que ensina dança diariamente às crianças da mesma forma que ensina matemática.
frameName: Existence
frameID: 437
luName: existir.v
luID: 26289
lu_idx: [(4, 9, 453)]
fe_idx: [(11, 32, 'Entity', 3193), (34, 43, 'Place', 4362)]
tokenized_text: Não existe um sistema educacional no planeta que ensina dança diariamente às crianças da mesma forma que ensina matemática .
tokenized_lu_idx: ['-', 'existir.v', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', 'Existence', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', 'Entity', 'Entity', 'Entity', 'Place', 'Place', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 9595)====
text: And the second boy said, 'I bring you myrrh.'
frameName: Ordinal_numbers
frameID: 547
luName: second.a
luID: 23149
lu_idx: [(8, 13, 1)]
fe_idx: [(8, 17, 'Item', 4430), (15, 17, 'Type', 4427)]
tokenized_text: And the second boy said , ' I bring you myrrh . '
tokenized_lu_idx: ['-', '-', 'second.a', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', 'Ordinal_numbers', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', 'Item', 'Type', '-', '-', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 1138)====
text: O segundo garoto disse: 'Eu trago mirra.'
frameName: Ordinal_numbers
frameID: 547
luName: segundo.a
luID: 26323
lu_idx: [(2, 8, 453)]
fe_idx: [(10, 15, 'Item', 4430), (-1, -1, 'Comparison_set', 4431), (-1, -1, 'Type', 4427)]
tokenized_text: O segundo garoto disse : ' Eu trago mirra . '
tokenized_lu_idx: ['-', 'segundo.a', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', 'Ordinal_numbers', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', 'Item', '-', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 10243)====
text: Remember that old chestnut?
frameName: Memory
frameID: 124
luName: remember.v
luID: 16479
lu_idx: [(0, 7, 1)]
fe_idx: [(-1, -1, 'Cognizer', 609), (9, 25, 'Content', 610)]
tokenized_text: Remember that old chestnut ?
tokenized_lu_idx: ['remember.v', '-', '-', '-', '-']
tokenized_frame_idx: ['Memory', '-', '-', '-', '-']
tokenized_fe_idx: ['-', 'Content', 'Content', 'Content', '-']

====Annotation (`annoID` = 6967)====
text: Lembram dessa piada velha?
frameName: Memory
frameID: 124
luName: lembrar.v
luID: 28182
lu_idx: [(0, 6, 453)]
fe_idx: [(8, 24, 'Content', 610), (-1, -1, 'Cognizer', 609)]
tokenized_text: Lembram dessa piada velha ?
tokenized_lu_idx: ['lembrar.v', '-', '-', '-', '-']
tokenized_frame_idx: ['Memory', '-', '-', '-', '-']
tokenized_fe_idx: ['-', 'Content', 'Content', 'Content', '-']

===============================
====Annotation (`annoID` = 9842)====
text: I think this is rather important.
frameName: Opinion
frameID: 642
luName: think.v
luID: 23709
lu_idx: [(2, 6, 1)]
fe_idx: [(0, 0, 'Cognizer', 5228), (8, 31, 'Opinion', 5229)]
tokenized_text: I think this is rather important .
tokenized_lu_idx: ['-', 'think.v', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', 'Opinion', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', 'Opinion', 'Opinion', 'Opinion', 'Opinion', '-']

====Annotation (`annoID` = 1327)====
text: Eu acho bastante importante.
frameName: Opinion
frameID: 642
luName: achar.v
luID: 26333
lu_idx: [(3, 6, 453)]
fe_idx: [(0, 1, 'Cognizer', 5228), (8, 26, 'Opinion', 5229)]
tokenized_text: Eu acho bastante importante .
tokenized_lu_idx: ['-', 'achar.v', '-', '-', '-']
tokenized_frame_idx: ['-', 'Opinion', '-', '-', '-']
tokenized_fe_idx: ['Cognizer', '-', 'Opinion', 'Opinion', '-']

===============================
====Annotation (`annoID` = 2516)====
text: If you think of it, children starting school this year will be retiring in 2065.
frameName: Cogitation
frameID: 17
luName: think.v
luID: 12862
lu_idx: [(7, 11, 1)]
fe_idx: [(13, 17, 'Topic', 71), (3, 5, 'Cognizer', 70)]
tokenized_text: If you think of it , children starting school this year will be retiring in 2065 .
tokenized_lu_idx: ['-', '-', 'think.v', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', 'Cogitation', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', 'Cognizer', '-', 'Topic', 'Topic', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 4352)====
text: Se formos pensar, as crianças entrando na escola esse ano estarão se aposentando em 2065.
frameName: Cogitation
frameID: 17
luName: pensar.v
luID: 27246
lu_idx: [(10, 15, 453)]
fe_idx: [(-1, -1, 'Topic', 71), (-1, -1, 'Cognizer', 70)]
tokenized_text: Se formos pensar , as crianças entrando na escola esse ano estarão se aposentando em 2065 .
tokenized_lu_idx: ['-', '-', 'pensar.v', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', 'Cogitation', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 9866)====
text: And then we focus on their heads.
frameName: Body_parts
frameID: 108
luName: head.n
luID: 16094
lu_idx: [(27, 31, 1)]
fe_idx: [(21, 25, 'Possessor', 472), (27, 31, 'Body_part', 516)]
tokenized_text: And then we focus on their heads .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', 'head.n', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', 'Body_parts', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', 'Possessor', 'Body_part', '-']

====Annotation (`annoID` = 1868)====
text: E depois nos focamos na cabeça.
frameName: Body_parts
frameID: 108
luName: cabeça.n
luID: 26316
lu_idx: [(24, 29, 453)]
fe_idx: [(-1, -1, 'Possessor', 472), (-1, -1, 'Body_part', 516)]
tokenized_text: E depois nos focamos na cabeça .
tokenized_lu_idx: ['-', '-', '-', '-', '-', 'cabeça.n', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', 'Body_parts', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 8834)====
text: People who couldn't sit still.
frameName: People
frameID: 278
luName: people.n
luID: 19342
lu_idx: [(0, 5, 1)]
fe_idx: [(0, 5, 'Person', 1854)]
tokenized_text: People who could n't sit still .
tokenized_lu_idx: ['people.n', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['People', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['Person', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 6990)====
text: Pessoas que não conseguiam ficar paradas.
frameName: People
frameID: 278
luName: pessoa.n
luID: 26555
lu_idx: [(0, 6, 453)]
fe_idx: [(-1, -1, 'Person', 1854)]
tokenized_text: Pessoas que não conseguiam ficar paradas .
tokenized_lu_idx: ['pessoa.n', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['People', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 8803)====
text: People weren't aware they could have that.
frameName: Awareness
frameID: 14
luName: aware.a
luID: 12761
lu_idx: [(15, 19, 1)]
fe_idx: [(0, 5, 'Cognizer', 57), (21, 40, 'Content', 58)]
tokenized_text: People were n't aware they could have that .
tokenized_lu_idx: ['-', '-', '-', 'aware.a', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', 'Awareness', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['Cognizer', '-', '-', '-', 'Content', 'Content', 'Content', 'Content', '-']

====Annotation (`annoID` = 7425)====
text: As pessoas não sabiam que podiam ter aquilo.
frameName: Awareness
frameID: 14
luName: saber.v
luID: 26303
lu_idx: [(15, 20, 453)]
fe_idx: [(0, 9, 'Cognizer', 57), (22, 42, 'Content', 58)]
tokenized_text: As pessoas não sabiam que podiam ter aquilo .
tokenized_lu_idx: ['-', '-', '-', 'saber.v', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', 'Awareness', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['Cognizer', 'Cognizer', '-', '-', 'Content', 'Content', 'Content', 'Content', '-']

===============================
====Annotation (`annoID` = 10328)====
text: There was a wonderful quote by Jonas Salk, who said, 'If all the insects were to disappear from the Earth, within 50 years all life on Earth would end.
frameName: Temporal_collocation
frameID: 838
luName: within.prep
luID: 24713
lu_idx: [(107, 112, 1)]
fe_idx: [(114, 121, 'Landmark_period', 8243), (123, 149, 'Trajector_event', 8244)]
tokenized_text: There was a wonderful quote by Jonas Salk , who said , ' If all the insects were to disappear from the Earth , within 50 years all life on Earth would end .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'within.prep', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Temporal_collocation', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Landmark_period', 'Landmark_period', 'Trajector_event', 'Trajector_event', 'Trajector_event', 'Trajector_event', 'Trajector_event', 'Trajector_event', '-']

====Annotation (`annoID` = 7356)====
text: Existe uma frase maravilhosa de Jonas Salk, que diz: 'Se todos os insetos desaparecessem da terra, dentro de 50 anos, toda vida na Terra desapareceria.Se todos os humanos desaparecessem da Terra, dentro de 50 anos todas as formas de vida floresceriam.'
frameName: Temporal_collocation
frameID: 838
luName: dentro de.prep
luID: 28478
lu_idx: [(203, 204, 453), (196, 201, 453)]
fe_idx: [(206, 212, 'Landmark_period', 8243), (214, 249, 'Trajector_event', 8244)]
tokenized_text: Existe uma frase maravilhosa de Jonas Salk , que diz : ' Se todos os insetos desaparecessem da terra , dentro de 50 anos , toda vida na Terra desapareceria.Se todos os humanos desaparecessem da Terra , dentro de 50 anos todas as formas de vida floresceriam . '
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'dentro de.prep', 'dentro de.prep', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Temporal_collocation', 'Temporal_collocation', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Landmark_period', 'Landmark_period', 'Trajector_event', 'Trajector_event', 'Trajector_event', 'Trajector_event', 'Trajector_event', 'Trajector_event', '-', '-']

===============================
====Annotation (`annoID` = 10062)====
text: And the second is academic ability, which has really come to dominate our view of intelligence, because the universities designed the system in their image.
frameName: Causation
frameID: 1
luName: because.c
luID: 12518
lu_idx: [(96, 102, 1)]
fe_idx: [(104, 154, 'Cause', 3), (36, 93, 'Effect', 5)]
tokenized_text: And the second is academic ability , which has really come to dominate our view of intelligence , because the universities designed the system in their image .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'because.c', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Causation', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', 'Effect', 'Effect', 'Effect', 'Effect', 'Effect', 'Effect', 'Effect', 'Effect', 'Effect', 'Effect', '-', '-', 'Cause', 'Cause', 'Cause', 'Cause', 'Cause', 'Cause', 'Cause', 'Cause', '-']

====Annotation (`annoID` = 1164)====
text: A segunda é a aptidão acadêmica, que veio a dominar nossa visão de inteligência, porque as universidades planejaram o sistema à sua própria imagem.
frameName: Causation
frameID: 1
luName: porque.c
luID: 26364
lu_idx: [(81, 86, 453)]
fe_idx: [(88, 145, 'Cause', 3), (33, 78, 'Effect', 5)]
tokenized_text: A segunda é a aptidão acadêmica , que veio a dominar nossa visão de inteligência , porque as universidades planejaram o sistema à sua própria imagem .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'porque.c', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Causation', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', 'Effect', 'Effect', 'Effect', 'Effect', 'Effect', 'Effect', 'Effect', 'Effect', '-', '-', 'Cause', 'Cause', 'Cause', 'Cause', 'Cause', 'Cause', 'Cause', 'Cause', 'Cause', '-']

===============================
====Annotation (`annoID` = 9635)====
text: He loved it, but he had a girlfriend in England.
frameName: Concessive
frameID: 952
luName: but.c
luID: 25179
lu_idx: [(13, 15, 1)]
fe_idx: [(0, 10, 'Main_assertion', 9104), (17, 46, 'Conceded_state_of_affairs', 9102)]
tokenized_text: He loved it , but he had a girlfriend in England .
tokenized_lu_idx: ['-', '-', '-', '-', 'but.c', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', 'Concessive', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['Main_assertion', 'Main_assertion', 'Main_assertion', '-', '-', 'Conceded_state_of_affairs', 'Conceded_state_of_affairs', 'Conceded_state_of_affairs', 'Conceded_state_of_affairs', 'Conceded_state_of_affairs', 'Conceded_state_of_affairs', '-']

====Annotation (`annoID` = 1288)====
text: Ele adorava, mas tinha uma namorada na Inglaterra.
frameName: Concessive
frameID: 952
luName: mas.c
luID: 26438
lu_idx: [(13, 15, 453)]
fe_idx: [(-1, -1, 'Topic', 9103), (0, 10, 'Main_assertion', 9104), (17, 48, 'Conceded_state_of_affairs', 9102)]
tokenized_text: Ele adorava , mas tinha uma namorada na Inglaterra .
tokenized_lu_idx: ['-', '-', '-', 'mas.c', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', 'Concessive', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['Main_assertion', 'Main_assertion', '-', '-', 'Conceded_state_of_affairs', 'Conceded_state_of_affairs', 'Conceded_state_of_affairs', 'Conceded_state_of_affairs', 'Conceded_state_of_affairs', '-']

===============================
====Annotation (`annoID` = 9867)====
text: And slightly to one side.
frameName: Goal
frameID: 569
luName: to.prep
luID: 23266
lu_idx: [(13, 14, 1)]
fe_idx: [(16, 23, 'Landmark', 4547)]
tokenized_text: And slightly to one side .
tokenized_lu_idx: ['-', '-', 'to.prep', '-', '-', '-']
tokenized_frame_idx: ['-', '-', 'Goal', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', 'Landmark', 'Landmark', '-']

====Annotation (`annoID` = 2253)====
text: E levemente para um lado.
frameName: Goal
frameID: 569
luName: para.prep
luID: 26354
lu_idx: [(12, 15, 453)]
fe_idx: [(-1, -1, 'Trajector', 4549), (-1, -1, 'Profiled_region', 4548), (17, 23, 'Landmark', 4547), (-1, -1, 'Landmark', 4547)]
tokenized_text: E levemente para um lado .
tokenized_lu_idx: ['-', '-', 'para.prep', '-', '-', '-']
tokenized_frame_idx: ['-', '-', 'Goal', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', 'Landmark', 'Landmark', '-']

===============================
====Annotation (`annoID` = 9927)====
text: They're just a form of life, another form of life.
frameName: Type
frameID: 117
luName: form.n
luID: 16259
lu_idx: [(37, 40, 1)]
fe_idx: [(42, 48, 'Category', 594)]
tokenized_text: They 're just a form of life , another form of life .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', 'form.n', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', 'Type', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Category', 'Category', '-']

====Annotation (`annoID` = 6862)====
text: É só uma forma de vida, outra forma de vida.
frameName: Type
frameID: 117
luName: de.prep
luID: 28267
lu_idx: [(36, 37, 453)]
fe_idx: [(39, 42, 'Category', 594), (30, 34, 'Subtype', 593)]
tokenized_text: É só uma forma de vida , outra forma de vida .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', 'de.prep', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', 'Type', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', 'Subtype', '-', 'Category', '-']

===============================
====Annotation (`annoID` = 10114)====
text: When I was a student, if you had a degree, you had a job.
frameName: Possession
frameID: 107
luName: have.v
luID: 16047
lu_idx: [(47, 49, 1)]
fe_idx: [(51, 55, 'Possession', 463), (43, 45, 'Owner', 457)]
tokenized_text: When I was a student , if you had a degree , you had a job .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'have.v', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Possession', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Owner', '-', 'Possession', 'Possession', '-']

====Annotation (`annoID` = 7300)====
text: Quando eu estudava, quem tinha um diploma, tinha um emprego.
frameName: Possession
frameID: 107
luName: ter.v
luID: 26331
lu_idx: [(43, 47, 453)]
fe_idx: [(49, 58, 'Possession', 463), (20, 40, 'Owner', 457)]
tokenized_text: Quando eu estudava , quem tinha um diploma , tinha um emprego .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', 'ter.v', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', 'Possession', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', 'Owner', 'Owner', 'Owner', 'Owner', '-', '-', 'Possession', 'Possession', '-']

===============================
====Annotation (`annoID` = 9814)====
text: So I want to talk about education and I want to talk about creativity.
frameName: Topic
frameID: 343
luName: about.prep
luID: 20457
lu_idx: [(18, 22, 1)]
fe_idx: [(3, 3, 'Communicator', 2454), (-1, -1, 'Text', 2453), (24, 32, 'Topic', 2452)]
tokenized_text: So I want to talk about education and I want to talk about creativity .
tokenized_lu_idx: ['-', '-', '-', '-', '-', 'about.prep', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', 'Topic', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', 'Communicator', '-', '-', '-', '-', 'Topic', '-', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 1495)====
text: Por isso eu quero falar sobre educação e quero falar sobre criatividade.
frameName: Topic
frameID: 343
luName: sobre.prep
luID: 26435
lu_idx: [(24, 28, 453)]
fe_idx: [(30, 37, 'Topic', 2452)]
tokenized_text: Por isso eu quero falar sobre educação e quero falar sobre criatividade .
tokenized_lu_idx: ['-', '-', '-', '-', '-', 'sobre.prep', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', 'Topic', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', 'Topic', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 8800)====
text: I think now they'd say she had ADHD.
frameName: Opinion
frameID: 642
luName: think.v
luID: 23709
lu_idx: [(2, 6, 1)]
fe_idx: [(8, 34, 'Opinion', 5229), (0, 0, 'Cognizer', 5228)]
tokenized_text: I think now they 'd say she had ADHD .
tokenized_lu_idx: ['-', 'think.v', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', 'Opinion', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', 'Opinion', 'Opinion', 'Opinion', 'Opinion', 'Opinion', 'Opinion', 'Opinion', '-']

====Annotation (`annoID` = 7398)====
text: Eu acho que hoje diriam que ela tinha TDAH.
frameName: Opinion
frameID: 642
luName: achar.v
luID: 26333
lu_idx: [(3, 6, 453)]
fe_idx: [(0, 1, 'Cognizer', 5228), (8, 41, 'Opinion', 5229)]
tokenized_text: Eu acho que hoje diriam que ela tinha TDAH .
tokenized_lu_idx: ['-', 'achar.v', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', 'Opinion', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['Cognizer', '-', 'Opinion', 'Opinion', 'Opinion', 'Opinion', 'Opinion', 'Opinion', 'Opinion', '-']

===============================
====Annotation (`annoID` = 9985)====
text: Waiting until it ends so they can go home and write a paper about it.
frameName: Topic
frameID: 343
luName: about.prep
luID: 20457
lu_idx: [(60, 64, 1)]
fe_idx: [(66, 67, 'Topic', 2452), (52, 58, 'Text', 2453)]
tokenized_text: Waiting until it ends so they can go home and write a paper about it .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'about.prep', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Topic', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Text', 'Text', '-', 'Topic', '-']

====Annotation (`annoID` = 6717)====
text: Só esperando que o evento acabe e eles possam escrever um artigo a respeito.
frameName: Topic
frameID: 343
luName: a respeito de.prep
luID: 28232
lu_idx: [(67, 74, 453), (65, 65, 453)]
fe_idx: [(34, 37, 'Communicator', 2454), (55, 63, 'Text', 2453), (17, 24, 'Topic', 2452)]
tokenized_text: Só esperando que o evento acabe e eles possam escrever um artigo a respeito .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'a respeito de.prep', 'a respeito de.prep', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Topic', 'Topic', '-']
tokenized_fe_idx: ['-', '-', '-', 'Topic', 'Topic', '-', '-', 'Communicator', '-', '-', 'Text', 'Text', '-', '-', '-']

===============================
====Annotation (`annoID` = 9789)====
text: He loved it, but he had a girlfriend in England.
frameName: Personal_relationship
frameID: 93
luName: girlfriend.n
luID: 15556
lu_idx: [(26, 35, 1)]
fe_idx: [(26, 35, 'Partner_2', 404), (17, 18, 'Partner_1', 403)]
tokenized_text: He loved it , but he had a girlfriend in England .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', 'girlfriend.n', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', 'Personal_relationship', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', 'Partner_1', '-', '-', 'Partner_2', '-', '-', '-']

====Annotation (`annoID` = 1336)====
text: Ele adorava, mas tinha uma namorada na Inglaterra.
frameName: Personal_relationship
frameID: 93
luName: namorado.n
luID: 26439
lu_idx: [(27, 34, 453)]
fe_idx: [(-1, -1, 'Partner_2', 404), (0, 2, 'Partner_1', 403)]
tokenized_text: Ele adorava , mas tinha uma namorada na Inglaterra .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', 'namorado.n', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', 'Personal_relationship', '-', '-', '-']
tokenized_fe_idx: ['Partner_1', '-', '-', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 8825)====
text: She eventually graduated from the Royal Ballet School, founded the Gillian Lynne Dance Company, met Andrew Lloyd Webber.
frameName: Activity_finish
frameID: 149
luName: graduate.v
luID: 16997
lu_idx: [(15, 23, 1)]
fe_idx: [(0, 2, 'Agent', 1813), (25, 52, 'Activity', 1814)]
tokenized_text: She eventually graduated from the Royal Ballet School , founded the Gillian Lynne Dance Company , met Andrew Lloyd Webber .
tokenized_lu_idx: ['-', '-', 'graduate.v', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', 'Activity_finish', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['Agent', '-', '-', 'Activity', 'Activity', 'Activity', 'Activity', 'Activity', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 2319)====
text: Ela eventualmente se formou na Royal Ballet School, fundou sua própria empresa, a Companhia de Dança Gillian Lynne, e conheceu Andrew Lloyd Weber.
frameName: Activity_finish
frameID: 149
luName: formar.v
luID: 26666
lu_idx: [(21, 26, 453)]
fe_idx: [(-1, -1, 'Activity', 1814), (0, 2, 'Agent', 1813), (28, 49, 'Place', 1513)]
tokenized_text: Ela eventualmente se formou na Royal Ballet School , fundou sua própria empresa , a Companhia de Dança Gillian Lynne , e conheceu Andrew Lloyd Weber .
tokenized_lu_idx: ['-', '-', '-', 'formar.v', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', 'Activity_finish', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['Agent', '-', '-', '-', 'Place', 'Place', 'Place', 'Place', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 9984)====
text: Waiting until it ends so they can go home and write a paper about it.
frameName: Text_creation
frameID: 253
luName: write.v
luID: 18965
lu_idx: [(46, 50, 1)]
fe_idx: [(52, 58, 'Text', 1686), (25, 28, 'Author', 1684)]
tokenized_text: Waiting until it ends so they can go home and write a paper about it .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'write.v', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Text_creation', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', 'Author', '-', '-', '-', '-', '-', 'Text', 'Text', '-', '-', '-']

====Annotation (`annoID` = 6711)====
text: Só esperando que o evento acabe e eles possam escrever um artigo a respeito.
frameName: Text_creation
frameID: 253
luName: escrever.v
luID: 28228
lu_idx: [(46, 53, 453)]
fe_idx: [(34, 37, 'Author', 1684), (55, 63, 'Text', 1686)]
tokenized_text: Só esperando que o evento acabe e eles possam escrever um artigo a respeito .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', 'escrever.v', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', 'Text_creation', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', 'Author', '-', '-', 'Text', 'Text', '-', '-', '-']

===============================
====Annotation (`annoID` = 4209)====
text: And when they got out, he said to her mother, 'Just stand and watch her.'
frameName: Kinship
frameID: 95
luName: mother.n
luID: 15671
lu_idx: [(38, 43, 1)]
fe_idx: [(34, 36, 'Ego', 414), (38, 43, 'Alter', 413)]
tokenized_text: And when they got out , he said to her mother , ' Just stand and watch her . '
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'mother.n', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Kinship', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', 'Ego', 'Alter', '-', '-', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 7484)====
text: E quando eles saíram da sala, ele disse para a mãe: 'Só a escute e a observe.'
frameName: Kinship
frameID: 95
luName: mãe.n
luID: 28537
lu_idx: [(47, 49, 453)]
fe_idx: [(-1, -1, 'Ego', 414), (-1, -1, 'Alter', 413)]
tokenized_text: E quando eles saíram da sala , ele disse para a mãe : ' Só a escute e a observe . '
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'mãe.n', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Kinship', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 9925)====
text: They're just a form of life, another form of life.
frameName: Type
frameID: 117
luName: form.n
luID: 16259
lu_idx: [(15, 18, 1)]
fe_idx: [(20, 26, 'Category', 594)]
tokenized_text: They 're just a form of life , another form of life .
tokenized_lu_idx: ['-', '-', '-', '-', 'form.n', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', 'Type', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', 'Category', 'Category', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 6861)====
text: É só uma forma de vida, outra forma de vida.
frameName: Type
frameID: 117
luName: de.prep
luID: 28267
lu_idx: [(15, 16, 453)]
fe_idx: [(9, 13, 'Subtype', 593), (18, 21, 'Category', 594)]
tokenized_text: É só uma forma de vida , outra forma de vida .
tokenized_lu_idx: ['-', '-', '-', '-', 'de.prep', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', 'Type', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', 'Subtype', '-', 'Category', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 2518)====
text: If you think of it, children starting school this year will be retiring in 2065.
frameName: Activity_start
frameID: 134
luName: start.v
luID: 16704
lu_idx: [(29, 36, 1)]
fe_idx: [(38, 43, 'Activity', 1391), (45, 53, 'Time', 736), (20, 27, 'Agent', 1781)]
tokenized_text: If you think of it , children starting school this year will be retiring in 2065 .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', 'start.v', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', 'Activity_start', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', 'Agent', '-', 'Activity', 'Time', 'Time', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 4354)====
text: Se formos pensar, as crianças entrando na escola esse ano estarão se aposentando em 2065.
frameName: Activity_start
frameID: 134
luName: entrar.v
luID: 27263
lu_idx: [(30, 37, 453)]
fe_idx: [(18, 28, 'Agent', 1781), (39, 47, 'Activity', 1391), (49, 56, 'Time', 736)]
tokenized_text: Se formos pensar , as crianças entrando na escola esse ano estarão se aposentando em 2065 .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', 'entrar.v', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', 'Activity_start', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', 'Agent', 'Agent', '-', 'Activity', 'Activity', 'Time', 'Time', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 2574)====
text: Anyway, we moved from Stratford to Los Angeles, and I just want to say a word about the transition.
frameName: Statement
frameID: 37
luName: say.v
luID: 13406
lu_idx: [(67, 69, 1)]
fe_idx: [(52, 52, 'Speaker', 152), (71, 76, 'Message', 154), (78, 97, 'Topic', 155)]
tokenized_text: Anyway , we moved from Stratford to Los Angeles , and I just want to say a word about the transition .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'say.v', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Statement', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Speaker', '-', '-', '-', '-', 'Message', 'Message', 'Topic', 'Topic', 'Topic', '-']

====Annotation (`annoID` = 1283)====
text: Enfim, nos mudamos de Stratford para Los Angeles, e eu só quero dizer uma coisa sobre essa transição.
frameName: Statement
frameID: 37
luName: dizer.v
luID: 26321
lu_idx: [(64, 68, 453)]
fe_idx: [(80, 99, 'Topic', 155), (52, 53, 'Speaker', 152), (70, 78, 'Message', 154)]
tokenized_text: Enfim , nos mudamos de Stratford para Los Angeles , e eu só quero dizer uma coisa sobre essa transição .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'dizer.v', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Statement', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Speaker', '-', '-', '-', 'Message', 'Message', 'Topic', 'Topic', 'Topic', '-']

===============================
====Annotation (`annoID` = 10126)====
text: But now kids with degrees are often heading home to carry on playing video games, because you need an MA where the previous job required a BA, and now you need a PhD for the other.
frameName: Temporal_collocation
frameID: 838
luName: now.adv
luID: 24703
lu_idx: [(4, 6, 1)]
fe_idx: [(4, 6, 'Landmark_period', 8243), (8, 79, 'Trajector_event', 8244)]
tokenized_text: But now kids with degrees are often heading home to carry on playing video games , because you need an MA where the previous job required a BA , and now you need a PhD for the other .
tokenized_lu_idx: ['-', 'now.adv', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', 'Temporal_collocation', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', 'Landmark_period', 'Trajector_event', 'Trajector_event', 'Trajector_event', 'Trajector_event', 'Trajector_event', 'Trajector_event', 'Trajector_event', 'Trajector_event', 'Trajector_event', 'Trajector_event', 'Trajector_event', 'Trajector_event', 'Trajector_event', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 7661)====
text: Mas agora garotos com diplomas estão voltando para casa para jogar video game porque pedem mestrado para o trabalho que necessitava bacharelado, e doutorado para o trabalho que necessitava mestrado.
frameName: Temporal_collocation
frameID: 838
luName: agora.adv
luID: 26370
lu_idx: [(4, 8, 453)]
fe_idx: [(10, 196, 'Landmark_event', 7736), (-1, -1, 'Trajector_event', 8244)]
tokenized_text: Mas agora garotos com diplomas estão voltando para casa para jogar video game porque pedem mestrado para o trabalho que necessitava bacharelado , e doutorado para o trabalho que necessitava mestrado .
tokenized_lu_idx: ['-', 'agora.adv', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', 'Temporal_collocation', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', 'Landmark_event', 'Landmark_event', 'Landmark_event', 'Landmark_event', 'Landmark_event', 'Landmark_event', 'Landmark_event', 'Landmark_event', 'Landmark_event', 'Landmark_event', 'Landmark_event', 'Landmark_event', 'Landmark_event', 'Landmark_event', 'Landmark_event', 'Landmark_event', 'Landmark_event', 'Landmark_event', 'Landmark_event', 'Landmark_event', 'Landmark_event', 'Landmark_event', 'Landmark_event', 'Landmark_event', 'Landmark_event', 'Landmark_event', 'Landmark_event', 'Landmark_event', 'Landmark_event', '-']

===============================
====Annotation (`annoID` = 10151)====
text: We need to radically rethink our view of intelligence.
frameName: Needing
frameID: 627
luName: need.v
luID: 23603
lu_idx: [(3, 6, 1)]
fe_idx: [(0, 1, 'Cognizer', 5111), (8, 52, 'Requirement', 5112)]
tokenized_text: We need to radically rethink our view of intelligence .
tokenized_lu_idx: ['-', 'need.v', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', 'Needing', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['Cognizer', '-', 'Requirement', 'Requirement', 'Requirement', 'Requirement', 'Requirement', 'Requirement', 'Requirement', '-']

====Annotation (`annoID` = 7285)====
text: Precisamos repensar radicalmente nossa visão de inteligência.
frameName: Needing
frameID: 627
luName: precisar.v
luID: 28347
lu_idx: [(0, 9, 453)]
fe_idx: [(11, 59, 'Requirement', 5112), (-1, -1, 'Cognizer', 5111), (-1, -1, 'Consequences', 5383)]
tokenized_text: Precisamos repensar radicalmente nossa visão de inteligência .
tokenized_lu_idx: ['precisar.v', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['Needing', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', 'Requirement', 'Requirement', 'Requirement', 'Requirement', 'Requirement', 'Requirement', '-']

===============================
====Annotation (`annoID` = 9845)====
text: I think math is very important, but so is dance.
frameName: Fields
frameID: 616
luName: math.n
luID: 23523
lu_idx: [(8, 11, 1)]
fe_idx: [(8, 11, 'Activity', 5025)]
tokenized_text: I think math is very important , but so is dance .
tokenized_lu_idx: ['-', '-', 'math.n', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', 'Fields', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', 'Activity', '-', '-', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 1587)====
text: Eu acho que matemática é importante, mas dança também.
frameName: Fields
frameID: 616
luName: matemática.n
luID: 26504
lu_idx: [(12, 21, 453)]
fe_idx: [(-1, -1, 'Salient_entity', 5027), (-1, -1, 'Practitioner', 5026), (-1, -1, 'Activity', 5025), (-1, -1, 'Work', 5028)]
tokenized_text: Eu acho que matemática é importante , mas dança também .
tokenized_lu_idx: ['-', '-', '-', 'matemática.n', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', 'Fields', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 2158)====
text: I believe our only hope for the future is to adopt a new conception of human ecology, one in which we start to reconstitute our conception of the richness of human capacity.
frameName: Adopt_selection
frameID: 709
luName: adopt.v
luID: 24050
lu_idx: [(45, 49, 1)]
fe_idx: [(-1, -1, 'Agent', 5827), (51, 171, 'Value', 5829)]
tokenized_text: I believe our only hope for the future is to adopt a new conception of human ecology , one in which we start to reconstitute our conception of the richness of human capacity .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'adopt.v', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Adopt_selection', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Value', 'Value', 'Value', 'Value', 'Value', 'Value', 'Value', 'Value', 'Value', 'Value', 'Value', 'Value', 'Value', 'Value', 'Value', 'Value', 'Value', 'Value', 'Value', 'Value', 'Value', 'Value', '-']

====Annotation (`annoID` = 6841)====
text: Eu acredito que nossa única esperança para o futuro é a adoção de uma nova concepção de ecologia humana, uma em que começamos a reconstituir nossa concepção da riqueza da capacidade humana.
frameName: Adopt_selection
frameID: 709
luName: adoção.n
luID: 28288
lu_idx: [(56, 61, 453)]
fe_idx: [(-1, -1, 'Agent', 5827), (63, 103, 'Value', 5829), (-1, -1, 'Attribute', 5828)]
tokenized_text: Eu acredito que nossa única esperança para o futuro é a adoção de uma nova concepção de ecologia humana , uma em que começamos a reconstituir nossa concepção da riqueza da capacidade humana .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'adoção.n', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Adopt_selection', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Value', 'Value', 'Value', 'Value', 'Value', 'Value', 'Value', 'Value', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 9811)====
text: At the top are mathematics and languages, then the humanities, and at the bottom are the arts.
frameName: Part_orientational
frameID: 131
luName: top.n
luID: 16639
lu_idx: [(7, 9, 1)]
fe_idx: [(15, 39, 'Part', 705), (-1, -1, 'Whole', 707)]
tokenized_text: At the top are mathematics and languages , then the humanities , and at the bottom are the arts .
tokenized_lu_idx: ['-', '-', 'top.n', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', 'Part_orientational', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', 'Part', 'Part', 'Part', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 1404)====
text: No topo estão a matemática e as línguas, depois as humanas e por último as artes.
frameName: Part_orientational
frameID: 131
luName: topo.n
luID: 26518
lu_idx: [(3, 6, 453)]
fe_idx: [(-1, -1, 'Whole', 707), (14, 38, 'Part', 705)]
tokenized_text: No topo estão a matemática e as línguas , depois as humanas e por último as artes .
tokenized_lu_idx: ['-', 'topo.n', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', 'Part_orientational', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', 'Part', 'Part', 'Part', 'Part', 'Part', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 10307)====
text: Our education system has mined our minds in the way that we strip-mine the earth: for a particular commodity.
frameName: System
frameID: 727
luName: system.n
luID: 24129
lu_idx: [(14, 19, 1)]
fe_idx: [(0, 2, 'Salient_entity', 6008), (4, 12, 'Function', 5997)]
tokenized_text: Our education system has mined our minds in the way that we strip-mine the earth : for a particular commodity .
tokenized_lu_idx: ['-', '-', 'system.n', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', 'System', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['Salient_entity', 'Function', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 7239)====
text: Nosso sistema educacional explorou nossas mentes como exploramos a terra: em busca de um recurso específico.
frameName: System
frameID: 727
luName: sistema.n
luID: 26471
lu_idx: [(6, 12, 453)]
fe_idx: [(14, 24, 'Function', 5997), (-1, -1, 'Complex', 5996)]
tokenized_text: Nosso sistema educacional explorou nossas mentes como exploramos a terra : em busca de um recurso específico .
tokenized_lu_idx: ['-', 'sistema.n', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', 'System', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', 'Function', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 10158)====
text: We think about the world in all the ways that we experience it.
frameName: Awareness
frameID: 14
luName: think.v
luID: 12780
lu_idx: [(3, 7, 1)]
fe_idx: [(9, 61, 'Content', 58), (0, 1, 'Cognizer', 57)]
tokenized_text: We think about the world in all the ways that we experience it .
tokenized_lu_idx: ['-', 'think.v', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', 'Awareness', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['Cognizer', '-', 'Content', 'Content', 'Content', 'Content', 'Content', 'Content', 'Content', 'Content', 'Content', 'Content', 'Content', '-']

====Annotation (`annoID` = 1154)====
text: Pensamos a respeito do mundo de todas as formas que o vivenciamos.
frameName: Awareness
frameID: 14
luName: pensar.v
luID: 26304
lu_idx: [(0, 7, 453)]
fe_idx: [(29, 64, 'Manner', 639), (-1, -1, 'Cognizer', 57), (9, 27, 'Topic', 60)]
tokenized_text: Pensamos a respeito do mundo de todas as formas que o vivenciamos .
tokenized_lu_idx: ['pensar.v', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['Awareness', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', 'Topic', 'Topic', 'Topic', 'Topic', 'Manner', 'Manner', 'Manner', 'Manner', 'Manner', 'Manner', 'Manner', '-']

===============================
====Annotation (`annoID` = 9679)====
text: They're not frightened of being wrong.
frameName: Fear
frameID: 917
luName: frightened.a
luID: 25031
lu_idx: [(12, 21, 1)]
fe_idx: [(0, 3, 'Experiencer', 8593), (23, 36, 'Stimulus', 8595)]
tokenized_text: They 're not frightened of being wrong .
tokenized_lu_idx: ['-', '-', '-', 'frightened.a', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', 'Fear', '-', '-', '-', '-']
tokenized_fe_idx: ['Experiencer', '-', '-', '-', 'Stimulus', 'Stimulus', 'Stimulus', '-']

====Annotation (`annoID` = 1221)====
text: Elas não tem medo de errar.
frameName: Fear
frameID: 917
luName: medo.n
luID: 26417
lu_idx: [(13, 16, 453)]
fe_idx: [(-1, -1, 'Experiencer', 8593), (18, 25, 'Stimulus', 8595), (-1, -1, 'State', 8601)]
tokenized_text: Elas não tem medo de errar .
tokenized_lu_idx: ['-', '-', '-', 'medo.n', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', 'Fear', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', 'Stimulus', 'Stimulus', '-']

===============================
====Annotation (`annoID` = 10155)====
text: We know three things about intelligence.
frameName: Entity
frameID: 226
luName: thing.n
luID: 18380
lu_idx: [(14, 19, 1)]
fe_idx: [(14, 19, 'Entity', 1843)]
tokenized_text: We know three things about intelligence .
tokenized_lu_idx: ['-', '-', '-', 'thing.n', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', 'Entity', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', 'Entity', '-', '-', '-']

====Annotation (`annoID` = 1199)====
text: Sabemos três coisas sobre inteligência.
frameName: Entity
frameID: 226
luName: coisa.n
luID: 26409
lu_idx: [(13, 18, 453)]
fe_idx: [(-1, -1, 'Entity', 1843)]
tokenized_text: Sabemos três coisas sobre inteligência .
tokenized_lu_idx: ['-', '-', 'coisa.n', '-', '-', '-']
tokenized_frame_idx: ['-', '-', 'Entity', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 10005)====
text: So the hierarchy is rooted on two ideas.
frameName: Causation
frameID: 1
luName: so.c
luID: 12529
lu_idx: [(0, 1, 1)]
fe_idx: [(3, 38, 'Effect', 5)]
tokenized_text: So the hierarchy is rooted on two ideas .
tokenized_lu_idx: ['so.c', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['Causation', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', 'Effect', 'Effect', 'Effect', 'Effect', 'Effect', 'Effect', 'Effect', '-']

====Annotation (`annoID` = 6965)====
text: Então a hierarquia está apoiada em duas idéias.
frameName: Causation
frameID: 1
luName: então.c
luID: 26541
lu_idx: [(0, 4, 453)]
fe_idx: [(-1, -1, 'Cause', 3), (6, 45, 'Effect', 5)]
tokenized_text: Então a hierarquia está apoiada em duas idéias .
tokenized_lu_idx: ['então.c', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['Causation', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', 'Effect', 'Effect', 'Effect', 'Effect', 'Effect', 'Effect', 'Effect', '-']

===============================
====Annotation (`annoID` = 10130)====
text: But now kids with degrees are often heading home to carry on playing video games, because you need an MA where the previous job required a BA, and now you need a PhD for the other.
frameName: Have_associated
frameID: 866
luName: with.prep
luID: 24889
lu_idx: [(13, 16, 1)]
fe_idx: [(18, 24, 'Entity', 7984), (8, 11, 'Topical_entity', 7993)]
tokenized_text: But now kids with degrees are often heading home to carry on playing video games , because you need an MA where the previous job required a BA , and now you need a PhD for the other .
tokenized_lu_idx: ['-', '-', '-', 'with.prep', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', 'Have_associated', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', 'Topical_entity', '-', 'Entity', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 7682)====
text: Mas agora garotos com diplomas estão voltando para casa para jogar video game porque pedem mestrado para o trabalho que necessitava bacharelado, e doutorado para o trabalho que necessitava mestrado.
frameName: Have_associated
frameID: 866
luName: com.prep
luID: 26485
lu_idx: [(18, 20, 453)]
fe_idx: [(10, 16, 'Entity', 7984), (22, 29, 'Topical_entity', 7993)]
tokenized_text: Mas agora garotos com diplomas estão voltando para casa para jogar video game porque pedem mestrado para o trabalho que necessitava bacharelado , e doutorado para o trabalho que necessitava mestrado .
tokenized_lu_idx: ['-', '-', '-', 'com.prep', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', 'Have_associated', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', 'Entity', '-', 'Topical_entity', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 10170)====
text: We think in abstract terms, we think in movement.
frameName: Awareness
frameID: 14
luName: think.v
luID: 12780
lu_idx: [(31, 35, 1)]
fe_idx: [(-1, -1, 'Content', 58), (37, 47, 'Manner', 639), (28, 29, 'Cognizer', 57)]
tokenized_text: We think in abstract terms , we think in movement .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', 'think.v', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', 'Awareness', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', 'Cognizer', '-', 'Manner', 'Manner', '-']

====Annotation (`annoID` = 1159)====
text: Pensamos em termo abstratos, pensamos em movimento.
frameName: Awareness
frameID: 14
luName: pensar.v
luID: 26304
lu_idx: [(29, 36, 453)]
fe_idx: [(-1, -1, 'Content', 58), (-1, -1, 'Topic', 60), (-1, -1, 'Cognizer', 57), (38, 49, 'Manner', 639)]
tokenized_text: Pensamos em termo abstratos , pensamos em movimento .
tokenized_lu_idx: ['-', '-', '-', '-', '-', 'pensar.v', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', 'Awareness', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', 'Manner', 'Manner', '-']

===============================
====Annotation (`annoID` = 9916)====
text: And I like university professors, but you know, we shouldn't hold them up as the high-water mark of all human achievement.
frameName: Experiencer_focus
frameID: 42
luName: like.v
luID: 13807
lu_idx: [(6, 9, 1)]
fe_idx: [(11, 31, 'Content', 169), (4, 4, 'Experiencer', 168)]
tokenized_text: And I like university professors , but you know , we should n't hold them up as the high-water mark of all human achievement .
tokenized_lu_idx: ['-', '-', 'like.v', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', 'Experiencer_focus', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', 'Experiencer', '-', 'Content', 'Content', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 6924)====
text: Eu gosto de professores universitários, mas nós não devemos colocá-los no topo das realizações humanas.
frameName: Experiencer_focus
frameID: 42
luName: gostar.v
luID: 26602
lu_idx: [(3, 7, 453)]
fe_idx: [(0, 1, 'Experiencer', 168), (9, 37, 'Content', 169)]
tokenized_text: Eu gosto de professores universitários , mas nós não devemos colocá-los no topo das realizações humanas .
tokenized_lu_idx: ['-', 'gostar.v', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', 'Experiencer_focus', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['Experiencer', '-', 'Content', 'Content', 'Content', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 2421)====
text: I lived in Stratford-on-Avon until about five years ago.
frameName: Residence
frameID: 100
luName: live.v
luID: 15831
lu_idx: [(2, 6, 1)]
fe_idx: [(0, 0, 'Resident', 425), (29, 54, 'Time', 7683), (8, 27, 'Location', 426)]
tokenized_text: I lived in Stratford-on-Avon until about five years ago .
tokenized_lu_idx: ['-', 'live.v', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', 'Residence', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', 'Location', 'Location', 'Time', 'Time', 'Time', 'Time', 'Time', '-']

====Annotation (`annoID` = 1104)====
text: Eu morei em Stratford-on-Avon até cinco anos atrás.
frameName: Residence
frameID: 100
luName: morar.v
luID: 26347
lu_idx: [(3, 7, 453)]
fe_idx: [(0, 1, 'Resident', 425), (9, 28, 'Location', 426), (30, 49, 'Time', 7683), (-1, -1, 'Co_resident', 427)]
tokenized_text: Eu morei em Stratford-on-Avon até cinco anos atrás .
tokenized_lu_idx: ['-', 'morar.v', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', 'Residence', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['Resident', '-', 'Location', 'Location', 'Time', 'Time', 'Time', 'Time', '-']

===============================
====Annotation (`annoID` = 9755)====
text: 'Must try harder.'
frameName: Attempt
frameID: 105
luName: try.v
luID: 16002
lu_idx: [(6, 8, 1)]
fe_idx: [(10, 15, 'Manner', 5298)]
tokenized_text: ' Must try harder . '
tokenized_lu_idx: ['-', '-', 'try.v', '-', '-', '-']
tokenized_frame_idx: ['-', '-', 'Attempt', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', 'Manner', '-', '-']

====Annotation (`annoID` = 2246)====
text: 'Se esforce mais.'
frameName: Attempt
frameID: 105
luName: esforçar.v
luID: 26635
lu_idx: [(4, 10, 453)]
fe_idx: [(12, 15, 'Effort', 497), (1, 2, 'Agent', 453)]
tokenized_text: ' Se esforce mais . '
tokenized_lu_idx: ['-', '-', 'esforçar.v', '-', '-', '-']
tokenized_frame_idx: ['-', '-', 'Attempt', '-', '-', '-']
tokenized_fe_idx: ['-', 'Agent', '-', 'Effort', '-', '-']

===============================
====Annotation (`annoID` = 10004)====
text: So the hierarchy is rooted on two ideas.
frameName: Cardinal_numbers
frameID: 196
luName: two.num
luID: 17844
lu_idx: [(30, 32, 1)]
fe_idx: [(34, 38, 'Entity', 2716), (30, 32, 'Number', 2715)]
tokenized_text: So the hierarchy is rooted on two ideas .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', 'two.num', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', 'Cardinal_numbers', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', 'Number', 'Entity', '-']

====Annotation (`annoID` = 6994)====
text: Então a hierarquia está apoiada em duas idéias.
frameName: Cardinal_numbers
frameID: 196
luName: dois.num
luID: 26466
lu_idx: [(35, 38, 453)]
fe_idx: [(-1, -1, 'Number', 2715), (40, 45, 'Entity', 2716)]
tokenized_text: Então a hierarquia está apoiada em duas idéias .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', 'dois.num', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', 'Cardinal_numbers', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', 'Entity', '-']

===============================
====Annotation (`annoID` = 4173)====
text: And our task is to educate their whole being, so they can face this future.
frameName: Being_obligated
frameID: 361
luName: task.n
luID: 20742
lu_idx: [(8, 11, 1)]
fe_idx: [(4, 6, 'Responsible_party', 2602), (16, 43, 'Duty', 2603)]
tokenized_text: And our task is to educate their whole being , so they can face this future .
tokenized_lu_idx: ['-', '-', 'task.n', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', 'Being_obligated', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', 'Responsible_party', '-', '-', 'Duty', 'Duty', 'Duty', 'Duty', 'Duty', '-', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 6816)====
text: Nossa tarefa é educá-las em sua totalidade, preparando-as para esse futuro.
frameName: Being_obligated
frameID: 361
luName: tarefa.n
luID: 28277
lu_idx: [(6, 11, 453)]
fe_idx: [(0, 4, 'Responsible_party', 2602), (13, 73, 'Duty', 2603)]
tokenized_text: Nossa tarefa é educá-las em sua totalidade , preparando-as para esse futuro .
tokenized_lu_idx: ['-', 'tarefa.n', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', 'Being_obligated', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['Responsible_party', '-', 'Duty', 'Duty', 'Duty', 'Duty', 'Duty', 'Duty', 'Duty', 'Duty', 'Duty', 'Duty', '-']

===============================
====Annotation (`annoID` = 2453)====
text: Being sent to bed by his dad, you know, to Shakespeare, 'Go to bed, now!
frameName: Sending
frameID: 219
luName: send.v
luID: 18333
lu_idx: [(6, 9, 1)]
fe_idx: [(18, 27, 'Sender', 1495), (11, 16, 'Goal', 1497), (-1, -1, 'Theme', 1499)]
tokenized_text: Being sent to bed by his dad , you know , to Shakespeare , ' Go to bed , now !
tokenized_lu_idx: ['-', 'send.v', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', 'Sending', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', 'Goal', 'Goal', 'Sender', 'Sender', 'Sender', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 2243)====
text: Ser mandado para cama com o pai dizendo 'Para cama, agora!',para William Shakespeare.
frameName: Sending
frameID: 219
luName: mandar.v
luID: 26325
lu_idx: [(4, 10, 453)]
fe_idx: [(12, 20, 'Goal', 1497), (-1, -1, 'Theme', 1499), (-1, -1, 'Sender', 1495)]
tokenized_text: Ser mandado para cama com o pai dizendo ' Para cama , agora !' , para William Shakespeare .
tokenized_lu_idx: ['-', 'mandar.v', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', 'Sending', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', 'Goal', 'Goal', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 2521)====
text: If you think of it, children starting school this year will be retiring in 2065.
frameName: Locale_by_use
frameID: 176
luName: school.n
luID: 17586
lu_idx: [(38, 43, 1)]
fe_idx: [(38, 43, 'Use', 4483), (38, 43, 'Locale', 1006)]
tokenized_text: If you think of it , children starting school this year will be retiring in 2065 .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', 'school.n', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', 'Locale_by_use', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', 'Locale', '-', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 4355)====
text: Se formos pensar, as crianças entrando na escola esse ano estarão se aposentando em 2065.
frameName: Locale_by_use
frameID: 176
luName: escola.n
luID: 26512
lu_idx: [(42, 47, 453)]
fe_idx: [(-1, -1, 'Use', 4483), (-1, -1, 'Locale', 1006)]
tokenized_text: Se formos pensar , as crianças entrando na escola esse ano estarão se aposentando em 2065 .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', 'escola.n', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', 'Locale_by_use', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 8793)====
text: Anyway, Gillian and I had lunch one day and I said, 'How did you get to be a dancer?'
frameName: Ingestion
frameID: 238
luName: have.v
luID: 18631
lu_idx: [(22, 24, 1)]
fe_idx: [(8, 20, 'Ingestor', 1537), (32, 38, 'Time', 1539), (26, 30, 'Ingestibles', 1540)]
tokenized_text: Anyway , Gillian and I had lunch one day and I said , ' How did you get to be a dancer ? '
tokenized_lu_idx: ['-', '-', '-', '-', '-', 'have.v', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', 'Ingestion', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', 'Ingestor', 'Ingestor', 'Ingestor', '-', 'Ingestibles', 'Time', 'Time', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 7539)====
text: Gillian e eu almoçamos um dia e eu perguntei: 'Gillian, como você se tornou dançarina?'
frameName: Ingestion
frameID: 238
luName: almoçar.v
luID: 28569
lu_idx: [(13, 21, 453)]
fe_idx: [(-1, -1, 'Ingestibles', 1540), (0, 11, 'Ingestor', 1537), (23, 28, 'Time', 1539)]
tokenized_text: Gillian e eu almoçamos um dia e eu perguntei : ' Gillian , como você se tornou dançarina ? '
tokenized_lu_idx: ['-', '-', '-', 'almoçar.v', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', 'Ingestion', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['Ingestor', 'Ingestor', 'Ingestor', '-', 'Time', 'Time', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 2579)====
text: Do you remember the story?
frameName: Memory
frameID: 124
luName: remember.v
luID: 16479
lu_idx: [(7, 14, 1)]
fe_idx: [(16, 24, 'Content', 610), (3, 5, 'Cognizer', 609)]
tokenized_text: Do you remember the story ?
tokenized_lu_idx: ['-', '-', 'remember.v', '-', '-', '-']
tokenized_frame_idx: ['-', '-', 'Memory', '-', '-', '-']
tokenized_fe_idx: ['-', 'Cognizer', '-', 'Content', 'Content', '-']

====Annotation (`annoID` = 6583)====
text: Se lembram da história?
frameName: Memory
frameID: 124
luName: lembrar.v
luID: 28182
lu_idx: [(3, 9, 453)]
fe_idx: [(11, 21, 'Content', 610), (0, 1, 'Cognizer', 609)]
tokenized_text: Se lembram da história ?
tokenized_lu_idx: ['-', 'lembrar.v', '-', '-', '-']
tokenized_frame_idx: ['-', 'Memory', '-', '-', '-']
tokenized_fe_idx: ['Cognizer', '-', 'Content', 'Content', '-']

===============================
====Annotation (`annoID` = 4199)====
text: And they watched for a few minutes and he turned to her mother and said, 'Mrs.Lynne, Gillian isn't sick; she's a dancer.
frameName: Measure_duration
frameID: 201
luName: minute.n
luID: 17990
lu_idx: [(27, 33, 1)]
fe_idx: [(27, 33, 'Unit', 1191), (21, 25, 'Count', 1190)]
tokenized_text: And they watched for a few minutes and he turned to her mother and said , ' Mrs.Lynne , Gillian is n't sick ; she 's a dancer .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', 'minute.n', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', 'Measure_duration', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', 'Count', 'Count', 'Unit', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 7242)====
text: Eles observaram por alguns minutos e ele se virou para a mãe e disse: 'Sra.Lynne, a Gillian não está doente, ela é uma dançarina.Leve-a para uma escola de dança.'
frameName: Measure_duration
frameID: 201
luName: minuto.n
luID: 26543
lu_idx: [(27, 33, 453)]
fe_idx: [(-1, -1, 'Unit', 1191), (20, 25, 'Count', 1190)]
tokenized_text: Eles observaram por alguns minutos e ele se virou para a mãe e disse : ' Sra.Lynne , a Gillian não está doente , ela é uma dançarina.Leve-a para uma escola de dança . '
tokenized_lu_idx: ['-', '-', '-', '-', 'minuto.n', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', 'Measure_duration', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', 'Count', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 10313)====
text: Our education system has mined our minds in the way that we strip-mine the earth: for a particular commodity.
frameName: Education_teaching
frameID: 101
luName: education.n
luID: 15868
lu_idx: [(4, 12, 1)]
fe_idx: [(-1, -1, 'Teacher', 431), (-1, -1, 'Subject', 434), (-1, -1, 'Student', 432)]
tokenized_text: Our education system has mined our minds in the way that we strip-mine the earth : for a particular commodity .
tokenized_lu_idx: ['-', 'education.n', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', 'Education_teaching', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 7240)====
text: Nosso sistema educacional explorou nossas mentes como exploramos a terra: em busca de um recurso específico.
frameName: Education_teaching
frameID: 101
luName: educacional.a
luID: 26492
lu_idx: [(14, 24, 453)]
fe_idx: [(-1, -1, 'Student', 432), (-1, -1, 'Role', 4378), (-1, -1, 'Fact', 4339), (6, 12, 'Institution', 433), (-1, -1, 'Subject', 434), (-1, -1, 'Teacher', 431)]
tokenized_text: Nosso sistema educacional explorou nossas mentes como exploramos a terra : em busca de um recurso específico .
tokenized_lu_idx: ['-', '-', 'educacional.a', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', 'Education_teaching', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', 'Institution', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 9660)====
text: I've been blown away by the whole thing.
frameName: Ranked_expectation
frameID: 680
luName: whole.a
luID: 23911
lu_idx: [(28, 32, 1)]
fe_idx: []
tokenized_text: I 've been blown away by the whole thing .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', 'whole.a', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', 'Ranked_expectation', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 1263)====
text: Fiquei maravilhado com a coisa toda.
frameName: Ranked_expectation
frameID: 680
luName: todo.a
luID: 26329
lu_idx: [(31, 34, 453)]
fe_idx: [(25, 29, 'Entity', 5583)]
tokenized_text: Fiquei maravilhado com a coisa toda .
tokenized_lu_idx: ['-', '-', '-', '-', '-', 'todo.a', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', 'Ranked_expectation', '-']
tokenized_fe_idx: ['-', '-', '-', '-', 'Entity', '-', '-']

===============================
====Annotation (`annoID` = 2489)====
text: We were sitting there and I think they just went out of sequence, because we talked to the little boy afterward and we said, 'You OK with that?'
frameName: Posture
frameID: 13
luName: sit.v
luID: 12743
lu_idx: [(8, 14, 1)]
fe_idx: [(16, 20, 'Location', 56), (0, 1, 'Agent', 55)]
tokenized_text: We were sitting there and I think they just went out of sequence , because we talked to the little boy afterward and we said , ' You OK with that ? '
tokenized_lu_idx: ['-', '-', 'sit.v', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', 'Posture', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['Agent', '-', '-', 'Location', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 6669)====
text: Estávamos lá sentados e eu acho que eles não seguiram a ordem porque nós conversamos com o garotinho depois e perguntamos: 'Tudo certo?'
frameName: Posture
frameID: 13
luName: sentar.v
luID: 28216
lu_idx: [(13, 20, 453)]
fe_idx: [(-1, -1, 'Point_of_contact', 3569), (10, 11, 'Location', 56), (-1, -1, 'Agent', 55)]
tokenized_text: Estávamos lá sentados e eu acho que eles não seguiram a ordem porque nós conversamos com o garotinho depois e perguntamos : ' Tudo certo ? '
tokenized_lu_idx: ['-', '-', 'sentar.v', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', 'Posture', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', 'Location', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 4265)====
text: Nobody has a clue, despite all the expertise that's been on parade for the past four days, what the world will look like in five years' time.
frameName: Political_locales
frameID: 175
luName: world.n
luID: 17538
lu_idx: [(100, 104, 1)]
fe_idx: [(100, 104, 'Locale', 1002)]
tokenized_text: Nobody has a clue , despite all the expertise that 's been on parade for the past four days , what the world will look like in five years' time .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'world.n', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Political_locales', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Locale', '-', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 4369)====
text: Ninguém tem noção, apesar de todo conhecimento que vimos nos últimos quatro dias, de como o mundo vai estar em cinco anos.
frameName: Political_locales
frameID: 175
luName: mundo.n
luID: 26327
lu_idx: [(92, 96, 453)]
fe_idx: [(-1, -1, 'Locale', 1002)]
tokenized_text: Ninguém tem noção , apesar de todo conhecimento que vimos nos últimos quatro dias , de como o mundo vai estar em cinco anos .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'mundo.n', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Political_locales', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 2505)====
text: What you have there is a person of extraordinary dedication who found a talent.
frameName: People
frameID: 278
luName: person.n
luID: 19343
lu_idx: [(25, 30, 1)]
fe_idx: [(25, 30, 'Person', 1854)]
tokenized_text: What you have there is a person of extraordinary dedication who found a talent .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', 'person.n', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', 'People', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', 'Person', '-', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 1479)====
text: O que vemos ali é uma pessoa de extrema dedicação que achou seu talento.
frameName: People
frameID: 278
luName: pessoa.n
luID: 26555
lu_idx: [(22, 27, 453)]
fe_idx: [(29, 48, 'Persistent_characteristic', 1855), (-1, -1, 'Person', 1854)]
tokenized_text: O que vemos ali é uma pessoa de extrema dedicação que achou seu talento .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', 'pessoa.n', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', 'People', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', 'Persistent_characteristic', 'Persistent_characteristic', 'Persistent_characteristic', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 10165)====
text: We think visually, we think in sound, we think kinesthetically.
frameName: Awareness
frameID: 14
luName: think.v
luID: 12780
lu_idx: [(3, 7, 1)]
fe_idx: [(-1, -1, 'Content', 58), (0, 1, 'Cognizer', 57), (9, 16, 'Manner', 639)]
tokenized_text: We think visually , we think in sound , we think kinesthetically .
tokenized_lu_idx: ['-', 'think.v', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', 'Awareness', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['Cognizer', '-', 'Manner', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 1032)====
text: Pensamos visualmente, pensamos auditivamente, pensamos cinestesicamente.
frameName: Awareness
frameID: 14
luName: pensar.v
luID: 26304
lu_idx: [(0, 7, 453)]
fe_idx: [(-1, -1, 'Content', 58), (9, 19, 'Manner', 639), (-1, -1, 'Topic', 60), (-1, -1, 'Cognizer', 57)]
tokenized_text: Pensamos visualmente , pensamos auditivamente , pensamos cinestesicamente .
tokenized_lu_idx: ['pensar.v', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['Awareness', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', 'Manner', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 10295)====
text: And when they got out, he said to her mother, 'Just stand and watch her.'
frameName: Temporal_collocation
frameID: 838
luName: when.adv
luID: 24707
lu_idx: [(4, 7, 1)]
fe_idx: [(9, 20, 'Landmark_event', 7736), (23, 43, 'Trajector_event', 8244)]
tokenized_text: And when they got out , he said to her mother , ' Just stand and watch her . '
tokenized_lu_idx: ['-', 'when.adv', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', 'Temporal_collocation', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', 'Landmark_event', 'Landmark_event', 'Landmark_event', '-', 'Trajector_event', 'Trajector_event', 'Trajector_event', 'Trajector_event', 'Trajector_event', '-', '-', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 7254)====
text: E quando eles saíram da sala, ele disse para a mãe: 'Só a escute e a observe.'
frameName: Temporal_collocation
frameID: 838
luName: quando.c
luID: 26491
lu_idx: [(2, 7, 453)]
fe_idx: [(9, 27, 'Landmark_event', 7736), (30, 76, 'Trajector_event', 8244)]
tokenized_text: E quando eles saíram da sala , ele disse para a mãe : ' Só a escute e a observe . '
tokenized_lu_idx: ['-', 'quando.c', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', 'Temporal_collocation', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', 'Landmark_event', 'Landmark_event', 'Landmark_event', 'Landmark_event', '-', 'Trajector_event', 'Trajector_event', 'Trajector_event', 'Trajector_event', 'Trajector_event', 'Trajector_event', 'Trajector_event', 'Trajector_event', 'Trajector_event', 'Trajector_event', 'Trajector_event', 'Trajector_event', 'Trajector_event', 'Trajector_event', '-']

===============================
====Annotation (`annoID` = 2159)====
text: I believe our only hope for the future is to adopt a new conception of human ecology, one in which we start to reconstitute our conception of the richness of human capacity.
frameName: Awareness
frameID: 14
luName: conception.n
luID: 12767
lu_idx: [(57, 66, 1)]
fe_idx: [(53, 55, 'Manner', 639), (86, 171, 'Content', 58), (68, 83, 'Topic', 60)]
tokenized_text: I believe our only hope for the future is to adopt a new conception of human ecology , one in which we start to reconstitute our conception of the richness of human capacity .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'conception.n', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Awareness', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Manner', '-', 'Topic', 'Topic', 'Topic', '-', 'Content', 'Content', 'Content', 'Content', 'Content', 'Content', 'Content', 'Content', 'Content', 'Content', 'Content', 'Content', 'Content', 'Content', 'Content', '-']

====Annotation (`annoID` = 6842)====
text: Eu acredito que nossa única esperança para o futuro é a adoção de uma nova concepção de ecologia humana, uma em que começamos a reconstituir nossa concepção da riqueza da capacidade humana.
frameName: Awareness
frameID: 14
luName: concepção.n
luID: 28290
lu_idx: [(75, 83, 453)]
fe_idx: [(85, 102, 'Topic', 60), (-1, -1, 'Cognizer', 57)]
tokenized_text: Eu acredito que nossa única esperança para o futuro é a adoção de uma nova concepção de ecologia humana , uma em que começamos a reconstituir nossa concepção da riqueza da capacidade humana .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'concepção.n', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Awareness', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Topic', 'Topic', 'Topic', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 9568)====
text: And the result is that we are educating people out of their creative capacities.
frameName: Education_teaching
frameID: 101
luName: educate.v
luID: 15860
lu_idx: [(30, 38, 1)]
fe_idx: [(40, 45, 'Student', 432), (23, 24, 'Teacher', 431), (47, 78, 'Result', 462)]
tokenized_text: And the result is that we are educating people out of their creative capacities .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', 'educate.v', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', 'Education_teaching', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', 'Teacher', '-', '-', 'Student', 'Result', 'Result', 'Result', 'Result', 'Result', '-']

====Annotation (`annoID` = 2201)====
text: O resultado disso é que estamos educando as pessoas para serem menos criativas.
frameName: Education_teaching
frameID: 101
luName: educar.v
luID: 26345
lu_idx: [(32, 39, 453)]
fe_idx: [(41, 50, 'Student', 432), (-1, -1, 'Fact', 4339), (-1, -1, 'Role', 4378), (-1, -1, 'Subject', 434), (-1, -1, 'Teacher', 431), (52, 77, 'Purpose', 7154)]
tokenized_text: O resultado disso é que estamos educando as pessoas para serem menos criativas .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', 'educar.v', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', 'Education_teaching', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', 'Student', 'Student', 'Purpose', 'Purpose', 'Purpose', 'Purpose', '-']

===============================
====Annotation (`annoID` = 10272)====
text: I'm fascinated by how people got to be there.
frameName: Means
frameID: 798
luName: how.adv
luID: 24492
lu_idx: [(18, 20, 1)]
fe_idx: [(-1, -1, 'Purpose', 7278), (-1, -1, 'Agent', 7276), (22, 43, 'Means', 7277)]
tokenized_text: I 'm fascinated by how people got to be there .
tokenized_lu_idx: ['-', '-', '-', '-', 'how.adv', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', 'Means', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', 'Means', 'Means', 'Means', 'Means', 'Means', '-']

====Annotation (`annoID` = 7474)====
text: Sou fascinado por como elas chegaram onde estão.
frameName: Means
frameID: 798
luName: como.c
luID: 26483
lu_idx: [(18, 21, 453)]
fe_idx: [(23, 35, 'Means', 7277), (-1, -1, 'Agent', 7276), (37, 46, 'Purpose', 7278)]
tokenized_text: Sou fascinado por como elas chegaram onde estão .
tokenized_lu_idx: ['-', '-', '-', 'como.c', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', 'Means', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', 'Means', 'Means', 'Purpose', 'Purpose', '-']

===============================
====Annotation (`annoID` = 4400)====
text: The second is that it's put us in a place where we have no idea what's going to happen, in terms of the future.
frameName: Ordinal_numbers
frameID: 547
luName: second.a
luID: 23149
lu_idx: [(4, 9, 1)]
fe_idx: [(-1, -1, 'Basis_of_order', 4429), (-1, -1, 'Type', 4427)]
tokenized_text: The second is that it 's put us in a place where we have no idea what 's going to happen , in terms of the future .
tokenized_lu_idx: ['-', 'second.a', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', 'Ordinal_numbers', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 2353)====
text: O segundo é o fato de que não fazemos a menor idéia do que vai acontecer no futuro.
frameName: Ordinal_numbers
frameID: 547
luName: segundo.a
luID: 26323
lu_idx: [(2, 8, 453)]
fe_idx: [(-1, -1, 'Basis_of_order', 4429), (-1, -1, 'Type', 4427), (-1, -1, 'Comparison_set', 4431), (-1, -1, 'Starting_point', 4428), (12, 81, 'Item', 4430)]
tokenized_text: O segundo é o fato de que não fazemos a menor idéia do que vai acontecer no futuro .
tokenized_lu_idx: ['-', 'segundo.a', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', 'Ordinal_numbers', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', 'Item', 'Item', 'Item', 'Item', 'Item', 'Item', 'Item', 'Item', 'Item', 'Item', 'Item', 'Item', 'Item', 'Item', 'Item', '-']

===============================
====Annotation (`annoID` = 9966)====
text: If you want real evidence of out-of-body experiences, get yourself along to a residential conference of senior academics, and pop into the discotheque on the final night.
frameName: Desiring
frameID: 338
luName: want.v
luID: 20296
lu_idx: [(7, 10, 1)]
fe_idx: [(3, 5, 'Experiencer', 2467), (12, 51, 'Focal_participant', 2472)]
tokenized_text: If you want real evidence of out-of-body experiences , get yourself along to a residential conference of senior academics , and pop into the discotheque on the final night .
tokenized_lu_idx: ['-', '-', 'want.v', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', 'Desiring', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', 'Experiencer', '-', 'Focal_participant', 'Focal_participant', 'Focal_participant', 'Focal_participant', 'Focal_participant', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 7118)====
text: Se você quiser evidências concretas de experiências extra-corpóreas, por sinal, é só participar de uma conferência de acadêmicos sênior, e aparecer na discoteca na noite final.
frameName: Desiring
frameID: 338
luName: querer.v
luID: 26406
lu_idx: [(8, 13, 453)]
fe_idx: [(15, 66, 'Focal_participant', 2472), (3, 6, 'Experiencer', 2467)]
tokenized_text: Se você quiser evidências concretas de experiências extra-corpóreas , por sinal , é só participar de uma conferência de acadêmicos sênior , e aparecer na discoteca na noite final .
tokenized_lu_idx: ['-', '-', 'querer.v', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', 'Desiring', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', 'Experiencer', '-', 'Focal_participant', 'Focal_participant', 'Focal_participant', 'Focal_participant', 'Focal_participant', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 2451)====
text: In fact, we moved from Stratford to Los Angeles.
frameName: Motion
frameID: 3
luName: move.v
luID: 12553
lu_idx: [(12, 16, 1)]
fe_idx: [(18, 31, 'Source', 12), (9, 10, 'Theme', 11), (33, 46, 'Goal', 14)]
tokenized_text: In fact , we moved from Stratford to Los Angeles .
tokenized_lu_idx: ['-', '-', '-', '-', 'move.v', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', 'Motion', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', 'Theme', '-', 'Source', 'Source', 'Goal', 'Goal', 'Goal', '-']

====Annotation (`annoID` = 1108)====
text: Na realidade, mudamos de Stratford para Los Angeles.
frameName: Motion
frameID: 3
luName: mudar.v
luID: 26350
lu_idx: [(14, 20, 453)]
fe_idx: [(22, 33, 'Source', 12), (35, 50, 'Goal', 14), (-1, -1, 'Theme', 11)]
tokenized_text: Na realidade , mudamos de Stratford para Los Angeles .
tokenized_lu_idx: ['-', '-', '-', 'mudar.v', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', 'Motion', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', 'Source', 'Source', 'Goal', 'Goal', 'Goal', '-']

===============================
====Annotation (`annoID` = 9770)====
text: And the second boy said, 'I bring you myrrh.'
frameName: People_by_age
frameID: 490
luName: boy.n
luID: 22623
lu_idx: [(15, 17, 1)]
fe_idx: [(-1, -1, 'Age', 3967), (15, 17, 'Person', 3964)]
tokenized_text: And the second boy said , ' I bring you myrrh . '
tokenized_lu_idx: ['-', '-', '-', 'boy.n', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', 'People_by_age', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', 'Person', '-', '-', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 1139)====
text: O segundo garoto disse: 'Eu trago mirra.'
frameName: People_by_age
frameID: 490
luName: garoto.n
luID: 26301
lu_idx: [(10, 15, 453)]
fe_idx: [(-1, -1, 'Age', 3967), (-1, -1, 'Person', 3964)]
tokenized_text: O segundo garoto disse : ' Eu trago mirra . '
tokenized_lu_idx: ['-', '-', 'garoto.n', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', 'People_by_age', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 10088)====
text: And the consequence is that many highly-talented, brilliant, creative people think they're not, because the thing they were good at at school wasn't valued, or was actually stigmatized.
frameName: Mental_property
frameID: 24
luName: brilliant.a
luID: 13021
lu_idx: [(50, 58, 1)]
fe_idx: [(70, 75, 'Protagonist', 94)]
tokenized_text: And the consequence is that many highly-talented , brilliant , creative people think they 're not , because the thing they were good at at school was n't valued , or was actually stigmatized .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', 'brilliant.a', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', 'Mental_property', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Protagonist', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 7163)====
text: A consequência disso é que muitas pessoas altamente talentosas brilhantes e criativas, pensam que não são, porque aquilo que elas eram boas na escola não era valorizado, ou era até estigmatizado.
frameName: Mental_property
frameID: 24
luName: brilhante.a
luID: 28420
lu_idx: [(63, 72, 453)]
fe_idx: [(27, 40, 'Protagonist', 94), (-1, -1, 'Practice', 96), (42, 50, 'Degree', 932)]
tokenized_text: A consequência disso é que muitas pessoas altamente talentosas brilhantes e criativas , pensam que não são , porque aquilo que elas eram boas na escola não era valorizado , ou era até estigmatizado .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', 'brilhante.a', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', 'Mental_property', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', 'Protagonist', 'Protagonist', 'Degree', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 10018)====
text: So you were probably steered benignly away from things at school when you were a kid, things you liked, on the grounds that you would never get a job doing that.
frameName: Getting
frameID: 161
luName: get.v
luID: 17150
lu_idx: [(140, 142, 1)]
fe_idx: []
tokenized_text: So you were probably steered benignly away from things at school when you were a kid , things you liked , on the grounds that you would never get a job doing that .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'get.v', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Getting', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 6767)====
text: Então você era bondosamente afastado na escola quando era criança de certas coisas, coisas que gostava, com a premissa que você nunca iria conseguir um emprego fazendo aquilo.
frameName: Getting
frameID: 161
luName: conseguir.v
luID: 28260
lu_idx: [(139, 147, 453)]
fe_idx: []
tokenized_text: Então você era bondosamente afastado na escola quando era criança de certas coisas , coisas que gostava , com a premissa que você nunca iria conseguir um emprego fazendo aquilo .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'conseguir.v', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Getting', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 10053)====
text: And the second is academic ability, which has really come to dominate our view of intelligence, because the universities designed the system in their image.
frameName: Ordinal_numbers
frameID: 547
luName: second.a
luID: 23149
lu_idx: [(8, 13, 1)]
fe_idx: [(36, 40, 'Item', 4430), (-1, -1, 'Type', 4427), (18, 33, 'Item', 4430)]
tokenized_text: And the second is academic ability , which has really come to dominate our view of intelligence , because the universities designed the system in their image .
tokenized_lu_idx: ['-', '-', 'second.a', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', 'Ordinal_numbers', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', 'Item', 'Item', '-', 'Item', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 1068)====
text: A segunda é a aptidão acadêmica, que veio a dominar nossa visão de inteligência, porque as universidades planejaram o sistema à sua própria imagem.
frameName: Ordinal_numbers
frameID: 547
luName: segundo.a
luID: 26323
lu_idx: [(2, 8, 453)]
fe_idx: [(-1, -1, 'Item', 4430), (-1, -1, 'Basis_of_order', 4429), (-1, -1, 'Type', 4427), (-1, -1, 'Comparison_set', 4431), (-1, -1, 'Starting_point', 4428)]
tokenized_text: A segunda é a aptidão acadêmica , que veio a dominar nossa visão de inteligência , porque as universidades planejaram o sistema à sua própria imagem .
tokenized_lu_idx: ['-', 'segundo.a', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', 'Ordinal_numbers', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 2162)====
text: I find this very interesting.
frameName: Mental_stimulus_stimulus_focus
frameID: 912
luName: interesting.a
luID: 25011
lu_idx: [(17, 27, 1)]
fe_idx: [(12, 15, 'Degree', 8536), (0, 0, 'Experiencer', 8534), (7, 10, 'Stimulus', 8535)]
tokenized_text: I find this very interesting .
tokenized_lu_idx: ['-', '-', '-', '-', 'interesting.a', '-']
tokenized_frame_idx: ['-', '-', '-', '-', 'Mental_stimulus_stimulus_focus', '-']
tokenized_fe_idx: ['-', '-', 'Stimulus', 'Degree', '-', '-']

====Annotation (`annoID` = 2392)====
text: Eu acho isso muito interessante.
frameName: Mental_stimulus_stimulus_focus
frameID: 912
luName: interessante.a
luID: 26690
lu_idx: [(19, 30, 453)]
fe_idx: [(13, 17, 'Degree', 8536), (8, 11, 'Stimulus', 8535), (0, 1, 'Experiencer', 8534)]
tokenized_text: Eu acho isso muito interessante .
tokenized_lu_idx: ['-', '-', '-', '-', 'interessante.a', '-']
tokenized_frame_idx: ['-', '-', '-', '-', 'Mental_stimulus_stimulus_focus', '-']
tokenized_fe_idx: ['Experiencer', '-', 'Stimulus', 'Degree', '-', '-']

===============================
====Annotation (`annoID` = 9621)====
text: I lived in Stratford-on-Avon until about five years ago.
frameName: Cardinal_numbers
frameID: 196
luName: five.num
luID: 17852
lu_idx: [(41, 44, 1)]
fe_idx: [(46, 50, 'Entity', 2716), (41, 44, 'Number', 2715)]
tokenized_text: I lived in Stratford-on-Avon until about five years ago .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', 'five.num', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', 'Cardinal_numbers', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', 'Number', 'Entity', '-', '-']

====Annotation (`annoID` = 1106)====
text: Eu morei em Stratford-on-Avon até cinco anos atrás.
frameName: Cardinal_numbers
frameID: 196
luName: cinco.num
luID: 26393
lu_idx: [(34, 38, 453)]
fe_idx: [(-1, -1, 'Number', 2715), (40, 43, 'Unit', 11398)]
tokenized_text: Eu morei em Stratford-on-Avon até cinco anos atrás .
tokenized_lu_idx: ['-', '-', '-', '-', '-', 'cinco.num', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', 'Cardinal_numbers', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', 'Unit', '-', '-']

===============================
====Annotation (`annoID` = 2523)====
text: Nobody has a clue, despite all the expertise that's been on parade for the past four days, what the world will look like in five years' time.
frameName: Awareness
frameID: 14
luName: clue.n
luID: 26698
lu_idx: [(13, 16, 1)]
fe_idx: [(0, 5, 'Cognizer', 57), (91, 139, 'Content', 58)]
tokenized_text: Nobody has a clue , despite all the expertise that 's been on parade for the past four days , what the world will look like in five years' time .
tokenized_lu_idx: ['-', '-', '-', 'clue.n', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', 'Awareness', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['Cognizer', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Content', 'Content', 'Content', 'Content', 'Content', 'Content', 'Content', 'Content', 'Content', 'Content', '-']

====Annotation (`annoID` = 4360)====
text: Ninguém tem noção, apesar de todo conhecimento que vimos nos últimos quatro dias, de como o mundo vai estar em cinco anos.
frameName: Awareness
frameID: 14
luName: noção.n
luID: 27265
lu_idx: [(12, 16, 453)]
fe_idx: [(82, 120, 'Content', 58), (0, 6, 'Cognizer', 57)]
tokenized_text: Ninguém tem noção , apesar de todo conhecimento que vimos nos últimos quatro dias , de como o mundo vai estar em cinco anos .
tokenized_lu_idx: ['-', '-', 'noção.n', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', 'Awareness', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['Cognizer', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Content', 'Content', 'Content', 'Content', 'Content', 'Content', 'Content', 'Content', 'Content', '-']

===============================
====Annotation (`annoID` = 10007)====
text: Number one, that the most useful subjects for work are at the top.
frameName: Usefulness
frameID: 451
luName: useful.a
luID: 22170
lu_idx: [(26, 31, 1)]
fe_idx: [(33, 40, 'Entity', 3448), (42, 49, 'Purpose', 3449), (21, 24, 'Degree', 3450)]
tokenized_text: Number one , that the most useful subjects for work are at the top .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', 'useful.a', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', 'Usefulness', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', 'Degree', '-', 'Entity', 'Purpose', 'Purpose', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 7342)====
text: A primeira é que as disciplinas mais úteis para o trabalho estão no topo.
frameName: Usefulness
frameID: 451
luName: útil.a
luID: 28474
lu_idx: [(37, 41, 453)]
fe_idx: [(43, 71, 'Purpose', 3449), (20, 30, 'Entity', 3448)]
tokenized_text: A primeira é que as disciplinas mais úteis para o trabalho estão no topo .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', 'útil.a', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', 'Usefulness', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', 'Entity', '-', '-', 'Purpose', 'Purpose', 'Purpose', 'Purpose', 'Purpose', 'Purpose', '-']

===============================
====Annotation (`annoID` = 4284)====
text: My contention is that creativity now is as important in education as literacy, and we should treat it with the same status.
frameName: Education_teaching
frameID: 101
luName: education.n
luID: 15868
lu_idx: [(56, 64, 1)]
fe_idx: [(-1, -1, 'Student', 432)]
tokenized_text: My contention is that creativity now is as important in education as literacy , and we should treat it with the same status .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'education.n', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Education_teaching', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 1467)====
text: Minha convicção é que a criatividade hoje é tão importante na educação como a alfabetização, e deve ser tratada com a mesma importância.
frameName: Education_teaching
frameID: 101
luName: educação.n
luID: 26479
lu_idx: [(62, 69, 453)]
fe_idx: [(-1, -1, 'Student', 432), (-1, -1, 'Role', 4378), (-1, -1, 'Fact', 4339), (-1, -1, 'Course', 4798), (-1, -1, 'Subject', 434)]
tokenized_text: Minha convicção é que a criatividade hoje é tão importante na educação como a alfabetização , e deve ser tratada com a mesma importância .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'educação.n', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Education_teaching', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 4520)====
text: I lived in Stratford-on-Avon until about five years ago.
frameName: Time_vector
frameID: 349
luName: until.prep
luID: 20558
lu_idx: [(29, 33, 1)]
fe_idx: [(35, 54, 'Landmark_event', 2501), (0, 27, 'Event', 3489)]
tokenized_text: I lived in Stratford-on-Avon until about five years ago .
tokenized_lu_idx: ['-', '-', '-', '-', 'until.prep', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', 'Time_vector', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['Event', 'Event', 'Event', 'Event', '-', 'Landmark_event', 'Landmark_event', 'Landmark_event', 'Landmark_event', '-']

====Annotation (`annoID` = 2244)====
text: Eu morei em Stratford-on-Avon até cinco anos atrás.
frameName: Time_vector
frameID: 349
luName: até.prep
luID: 26633
lu_idx: [(30, 32, 453)]
fe_idx: [(-1, -1, 'Direction', 2503), (34, 49, 'Landmark_event', 2501), (0, 28, 'Event', 3489)]
tokenized_text: Eu morei em Stratford-on-Avon até cinco anos atrás .
tokenized_lu_idx: ['-', '-', '-', '-', 'até.prep', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', 'Time_vector', '-', '-', '-', '-']
tokenized_fe_idx: ['Event', 'Event', 'Event', 'Event', '-', 'Landmark_event', 'Landmark_event', 'Landmark_event', '-']

===============================
====Annotation (`annoID` = 10148)====
text: And it indicates the whole structure of education is shifting beneath our feet.
frameName: Undergo_change
frameID: 565
luName: shift.v
luID: 23258
lu_idx: [(53, 60, 1)]
fe_idx: [(62, 77, 'Circumstances', 4559), (17, 48, 'Entity', 4532)]
tokenized_text: And it indicates the whole structure of education is shifting beneath our feet .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', 'shift.v', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', 'Undergo_change', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', 'Entity', 'Entity', 'Entity', 'Entity', 'Entity', '-', '-', 'Circumstances', 'Circumstances', 'Circumstances', '-']

====Annotation (`annoID` = 7338)====
text: E é um indicativo de que toda a estrutura educacional está mudando na frente do nosso nariz.
frameName: Undergo_change
frameID: 565
luName: mudar.v
luID: 28473
lu_idx: [(59, 65, 453)]
fe_idx: [(-1, -1, 'Final_category', 4533), (-1, -1, 'Initial_category', 4552), (25, 52, 'Entity', 4532), (-1, -1, 'Final_situation', 11289), (67, 90, 'Place', 11286)]
tokenized_text: E é um indicativo de que toda a estrutura educacional está mudando na frente do nosso nariz .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'mudar.v', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Undergo_change', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', 'Entity', 'Entity', 'Entity', 'Entity', '-', '-', 'Place', 'Place', 'Place', 'Place', 'Place', '-']

===============================
====Annotation (`annoID` = 2457)====
text: Because she was the main reason we were leaving the country.
frameName: Departing
frameID: 51
luName: leave.v
luID: 14039
lu_idx: [(40, 46, 1)]
fe_idx: [(32, 33, 'Theme', 206), (48, 58, 'Source', 207)]
tokenized_text: Because she was the main reason we were leaving the country .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', 'leave.v', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', 'Departing', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', 'Theme', '-', '-', 'Source', 'Source', '-']

====Annotation (`annoID` = 1345)====
text: Porque ela era a principal razão de estarmos deixando o país.
frameName: Departing
frameID: 51
luName: deixar.v
luID: 26488
lu_idx: [(45, 52, 453)]
fe_idx: [(54, 59, 'Source', 207), (-1, -1, 'Theme', 206)]
tokenized_text: Porque ela era a principal razão de estarmos deixando o país .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', 'deixar.v', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', 'Departing', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', 'Source', 'Source', '-']

===============================
====Annotation (`annoID` = 2531)====
text: So I want to talk about education and I want to talk about creativity.
frameName: Statement
frameID: 37
luName: talk.v
luID: 13411
lu_idx: [(13, 16, 1)]
fe_idx: [(3, 3, 'Speaker', 152), (18, 32, 'Topic', 155)]
tokenized_text: So I want to talk about education and I want to talk about creativity .
tokenized_lu_idx: ['-', '-', '-', '-', 'talk.v', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', 'Statement', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', 'Speaker', '-', '-', '-', 'Topic', 'Topic', '-', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 1494)====
text: Por isso eu quero falar sobre educação e quero falar sobre criatividade.
frameName: Statement
frameID: 37
luName: falar.v
luID: 26299
lu_idx: [(18, 22, 453)]
fe_idx: [(24, 37, 'Topic', 155), (9, 10, 'Speaker', 152), (-1, -1, 'Medium', 956), (-1, -1, 'Message', 154)]
tokenized_text: Por isso eu quero falar sobre educação e quero falar sobre criatividade .
tokenized_lu_idx: ['-', '-', '-', '-', 'falar.v', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', 'Statement', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', 'Speaker', '-', '-', 'Topic', 'Topic', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 9648)====
text: But something strikes you when you move to America and travel around the world: 
frameName: Temporal_collocation
frameID: 838
luName: when.adv
luID: 24707
lu_idx: [(26, 29, 1)]
fe_idx: [(31, 77, 'Landmark_event', 7736), (4, 24, 'Trajector_event', 8244)]
tokenized_text: But something strikes you when you move to America and travel around the world :
tokenized_lu_idx: ['-', '-', '-', '-', 'when.adv', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', 'Temporal_collocation', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', 'Trajector_event', 'Trajector_event', 'Trajector_event', '-', 'Landmark_event', 'Landmark_event', 'Landmark_event', 'Landmark_event', 'Landmark_event', 'Landmark_event', 'Landmark_event', 'Landmark_event', 'Landmark_event', '-']

====Annotation (`annoID` = 1354)====
text: Uma coisa chama atenção quando se vem para os EUA e quando se viaja pelo mundo: todo sistema educacional do planeta tem a mesma hierarquia de disciplinas.
frameName: Temporal_collocation
frameID: 838
luName: quando.c
luID: 26491
lu_idx: [(52, 57, 453)]
fe_idx: []
tokenized_text: Uma coisa chama atenção quando se vem para os EUA e quando se viaja pelo mundo : todo sistema educacional do planeta tem a mesma hierarquia de disciplinas .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'quando.c', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Temporal_collocation', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 9998)====
text: Around the world, there were no public systems of education, really, before the 19th century.
frameName: Time_vector
frameID: 349
luName: before.prep
luID: 20534
lu_idx: [(69, 74, 1)]
fe_idx: [(0, 58, 'Event', 3489), (76, 91, 'Landmark_event', 2501)]
tokenized_text: Around the world , there were no public systems of education , really , before the 19th century .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'before.prep', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Time_vector', '-', '-', '-', '-']
tokenized_fe_idx: ['Event', 'Event', 'Event', 'Event', 'Event', 'Event', 'Event', 'Event', 'Event', 'Event', 'Event', '-', '-', '-', '-', 'Landmark_event', 'Landmark_event', 'Landmark_event', '-']

====Annotation (`annoID` = 7174)====
text: O sistema foi concebido, e no mundo todo, não existiam sistemas públicos de educação antes do Séc.XIX.
frameName: Time_vector
frameID: 349
luName: antes.adv
luID: 28424
lu_idx: [(85, 89, 453)]
fe_idx: [(-1, -1, 'Distance', 2502), (-1, -1, 'Direction', 2503), (42, 83, 'Event', 3489), (91, 100, 'Landmark_event', 2501)]
tokenized_text: O sistema foi concebido , e no mundo todo , não existiam sistemas públicos de educação antes do Séc.XIX .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'antes.adv', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Time_vector', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Event', 'Event', 'Event', 'Event', 'Event', 'Event', '-', 'Landmark_event', 'Landmark_event', '-']

===============================
====Annotation (`annoID` = 2570)====
text: And the third boy said, 'Frank sent this.'
frameName: Statement
frameID: 37
luName: say.v
luID: 13406
lu_idx: [(18, 21, 1)]
fe_idx: [(4, 16, 'Speaker', 152), (25, 39, 'Message', 154)]
tokenized_text: And the third boy said , ' Frank sent this . '
tokenized_lu_idx: ['-', '-', '-', '-', 'say.v', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', 'Statement', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', 'Speaker', 'Speaker', 'Speaker', '-', '-', '-', 'Message', 'Message', 'Message', '-', '-']

====Annotation (`annoID` = 1144)====
text: E o terceiro garoto disse: 'O Frank mandou isso.'
frameName: Statement
frameID: 37
luName: dizer.v
luID: 26321
lu_idx: [(20, 24, 453)]
fe_idx: [(28, 46, 'Message', 154), (-1, -1, 'Medium', 956), (-1, -1, 'Topic', 155), (2, 18, 'Speaker', 152)]
tokenized_text: E o terceiro garoto disse : ' O Frank mandou isso . '
tokenized_lu_idx: ['-', '-', '-', '-', 'dizer.v', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', 'Statement', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', 'Speaker', 'Speaker', 'Speaker', '-', '-', '-', 'Message', 'Message', 'Message', 'Message', '-', '-']

===============================
====Annotation (`annoID` = 9857)====
text: We all have bodies, don't we?
frameName: Possession
frameID: 107
luName: have.v
luID: 16047
lu_idx: [(7, 10, 1)]
fe_idx: [(0, 5, 'Owner', 457), (12, 17, 'Possession', 463)]
tokenized_text: We all have bodies , do n't we ?
tokenized_lu_idx: ['-', '-', 'have.v', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', 'Possession', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['Owner', 'Owner', '-', 'Possession', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 1581)====
text: Nós todos temos corpos, não temos?
frameName: Possession
frameID: 107
luName: ter.v
luID: 26331
lu_idx: [(10, 14, 453)]
fe_idx: [(0, 2, 'Owner', 457), (16, 21, 'Possession', 463)]
tokenized_text: Nós todos temos corpos , não temos ?
tokenized_lu_idx: ['-', '-', 'ter.v', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', 'Possession', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['Owner', '-', '-', 'Possession', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 2509)====
text: I have an interest in education.
frameName: Education_teaching
frameID: 101
luName: education.n
luID: 15868
lu_idx: [(22, 30, 1)]
fe_idx: [(-1, -1, 'Student', 432)]
tokenized_text: I have an interest in education .
tokenized_lu_idx: ['-', '-', '-', '-', '-', 'education.n', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', 'Education_teaching', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 4297)====
text: Eu me interesso por educação.
frameName: Education_teaching
frameID: 101
luName: educação.n
luID: 26479
lu_idx: [(20, 27, 453)]
fe_idx: [(-1, -1, 'Teacher', 431), (-1, -1, 'Subject', 434), (-1, -1, 'Student', 432)]
tokenized_text: Eu me interesso por educação .
tokenized_lu_idx: ['-', '-', '-', '-', 'educação.n', '-']
tokenized_frame_idx: ['-', '-', '-', '-', 'Education_teaching', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 9859)====
text: Did I miss a meeting?
frameName: Discussion
frameID: 28
luName: meeting.n
luID: 13185
lu_idx: [(13, 19, 1)]
fe_idx: [(-1, -1, 'Topic', 112), (-1, -1, 'Interlocutors', 111)]
tokenized_text: Did I miss a meeting ?
tokenized_lu_idx: ['-', '-', '-', '-', 'meeting.n', '-']
tokenized_frame_idx: ['-', '-', '-', '-', 'Discussion', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 1591)====
text: Eu faltei uma reunião?
frameName: Discussion
frameID: 28
luName: reunião.n
luID: 26583
lu_idx: [(14, 20, 453)]
fe_idx: [(-1, -1, 'Topic', 112), (-1, -1, 'Interlocutors', 111)]
tokenized_text: Eu faltei uma reunião ?
tokenized_lu_idx: ['-', '-', '-', 'reunião.n', '-']
tokenized_frame_idx: ['-', '-', '-', 'Discussion', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 2157)====
text: I believe our only hope for the future is to adopt a new conception of human ecology, one in which we start to reconstitute our conception of the richness of human capacity.
frameName: Desiring
frameID: 338
luName: hope.n
luID: 20325
lu_idx: [(19, 22, 1)]
fe_idx: [(24, 37, 'Time_of_event', 2484), (10, 12, 'Experiencer', 2467), (42, 171, 'Event', 2469)]
tokenized_text: I believe our only hope for the future is to adopt a new conception of human ecology , one in which we start to reconstitute our conception of the richness of human capacity .
tokenized_lu_idx: ['-', '-', '-', '-', 'hope.n', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', 'Desiring', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', 'Experiencer', '-', '-', 'Time_of_event', 'Time_of_event', 'Time_of_event', '-', 'Event', 'Event', 'Event', 'Event', 'Event', 'Event', 'Event', 'Event', 'Event', 'Event', 'Event', 'Event', 'Event', 'Event', 'Event', 'Event', 'Event', 'Event', 'Event', 'Event', 'Event', 'Event', 'Event', 'Event', '-']

====Annotation (`annoID` = 2338)====
text: Eu acredito que nossa única esperança para o futuro é a adoção de uma nova concepção de ecologia humana, uma em que começamos a reconstituir nossa concepção da riqueza da capacidade humana.
frameName: Desiring
frameID: 338
luName: esperança.n
luID: 26657
lu_idx: [(28, 36, 453)]
fe_idx: [(38, 50, 'Focal_participant', 2472), (16, 20, 'Experiencer', 2467), (52, 102, 'Event', 2469), (-1, -1, 'Location_of_event', 2486)]
tokenized_text: Eu acredito que nossa única esperança para o futuro é a adoção de uma nova concepção de ecologia humana , uma em que começamos a reconstituir nossa concepção da riqueza da capacidade humana .
tokenized_lu_idx: ['-', '-', '-', '-', '-', 'esperança.n', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', 'Desiring', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', 'Experiencer', '-', '-', 'Focal_participant', 'Focal_participant', 'Focal_participant', 'Event', 'Event', 'Event', 'Event', 'Event', 'Event', 'Event', 'Event', 'Event', 'Event', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 10009)====
text: Number one, that the most useful subjects for work are at the top.
frameName: Locative_relation
frameID: 179
luName: at.prep
luID: 17699
lu_idx: [(55, 56, 1)]
fe_idx: [(58, 64, 'Ground', 1029), (17, 49, 'Figure', 1030)]
tokenized_text: Number one , that the most useful subjects for work are at the top .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'at.prep', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Locative_relation', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', 'Figure', 'Figure', 'Figure', 'Figure', 'Figure', 'Figure', '-', '-', 'Ground', 'Ground', '-']

====Annotation (`annoID` = 7352)====
text: A primeira é que as disciplinas mais úteis para o trabalho estão no topo.
frameName: Locative_relation
frameID: 179
luName: no topo.adv
luID: 28481
lu_idx: [(68, 71, 453), (65, 66, 453)]
fe_idx: [(-1, -1, 'Ground', 1029), (17, 30, 'Figure', 1030), (-1, -1, 'Profiled_region', 11219)]
tokenized_text: A primeira é que as disciplinas mais úteis para o trabalho estão no topo .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'no topo.adv', 'no topo.adv', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Locative_relation', 'Locative_relation', '-']
tokenized_fe_idx: ['-', '-', '-', '-', 'Figure', 'Figure', '-', '-', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 2454)====
text: Anyway, we moved from Stratford to Los Angeles, and I just want to say a word about the transition.
frameName: Motion
frameID: 3
luName: move.v
luID: 12553
lu_idx: [(11, 15, 1)]
fe_idx: [(8, 9, 'Theme', 11), (17, 30, 'Source', 12), (32, 45, 'Goal', 14)]
tokenized_text: Anyway , we moved from Stratford to Los Angeles , and I just want to say a word about the transition .
tokenized_lu_idx: ['-', '-', '-', 'move.v', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', 'Motion', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', 'Theme', '-', 'Source', 'Source', 'Goal', 'Goal', 'Goal', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 1278)====
text: Enfim, nos mudamos de Stratford para Los Angeles, e eu só quero dizer uma coisa sobre essa transição.
frameName: Motion
frameID: 3
luName: mudar.v
luID: 26350
lu_idx: [(11, 17, 453)]
fe_idx: [(7, 9, 'Theme', 11), (-1, -1, 'Distance', 1298), (19, 30, 'Source', 12), (-1, -1, 'Path', 13), (-1, -1, 'Direction', 4310), (32, 47, 'Goal', 14)]
tokenized_text: Enfim , nos mudamos de Stratford para Los Angeles , e eu só quero dizer uma coisa sobre essa transição .
tokenized_lu_idx: ['-', '-', '-', 'mudar.v', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', 'Motion', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', 'Theme', '-', 'Source', 'Source', 'Goal', 'Goal', 'Goal', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 4217)====
text: One is the extraordinary evidence of human creativity in all of the presentations that we've had and in all of the people here.
frameName: Evidence
frameID: 20
luName: evidence.n
luID: 12913
lu_idx: [(25, 32, 1)]
fe_idx: [(54, 125, 'Support', 81), (34, 52, 'Proposition', 82)]
tokenized_text: One is the extraordinary evidence of human creativity in all of the presentations that we 've had and in all of the people here .
tokenized_lu_idx: ['-', '-', '-', '-', 'evidence.n', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', 'Evidence', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', 'Proposition', 'Proposition', 'Proposition', 'Support', 'Support', 'Support', 'Support', 'Support', 'Support', 'Support', 'Support', 'Support', 'Support', 'Support', 'Support', 'Support', 'Support', 'Support', 'Support', '-']

====Annotation (`annoID` = 2344)====
text: O primeiro é a extraordinária evidência da criatividade humana em todas as apresentações que tivemos e em todas as pessoas presentes.
frameName: Evidence
frameID: 20
luName: evidência.n
luID: 26680
lu_idx: [(30, 38, 453)]
fe_idx: [(40, 61, 'Proposition', 82), (63, 131, 'Support', 81), (15, 28, 'Depictive', 666)]
tokenized_text: O primeiro é a extraordinária evidência da criatividade humana em todas as apresentações que tivemos e em todas as pessoas presentes .
tokenized_lu_idx: ['-', '-', '-', '-', '-', 'evidência.n', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', 'Evidence', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', 'Depictive', '-', 'Proposition', 'Proposition', 'Proposition', 'Support', 'Support', 'Support', 'Support', 'Support', 'Support', 'Support', 'Support', 'Support', 'Support', 'Support', 'Support', '-']

===============================
====Annotation (`annoID` = 4399)====
text: The second is that it's put us in a place where we have no idea what's going to happen, in terms of the future.
frameName: Event
frameID: 168
luName: happen.v
luID: 17170
lu_idx: [(80, 85, 1)]
fe_idx: [(64, 67, 'Event', 903), (88, 109, 'Manner', 3547)]
tokenized_text: The second is that it 's put us in a place where we have no idea what 's going to happen , in terms of the future .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'happen.v', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Event', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Event', '-', '-', '-', '-', '-', 'Manner', 'Manner', 'Manner', 'Manner', 'Manner', '-']

====Annotation (`annoID` = 2354)====
text: O segundo é o fato de que não fazemos a menor idéia do que vai acontecer no futuro.
frameName: Event
frameID: 168
luName: acontecer.v
luID: 26335
lu_idx: [(63, 71, 453)]
fe_idx: [(55, 57, 'Event', 903), (52, 53, 'Event', 903), (-1, -1, 'Place', 904), (73, 81, 'Time', 906)]
tokenized_text: O segundo é o fato de que não fazemos a menor idéia do que vai acontecer no futuro .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'acontecer.v', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Event', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Event', 'Event', '-', '-', 'Time', 'Time', '-']

===============================
====Annotation (`annoID` = 4403)====
text: No idea how this may play out.
frameName: Awareness
frameID: 14
luName: idea.n
luID: 12788
lu_idx: [(3, 6, 1)]
fe_idx: [(8, 28, 'Content', 58), (-1, -1, 'Cognizer', 57)]
tokenized_text: No idea how this may play out .
tokenized_lu_idx: ['-', 'idea.n', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', 'Awareness', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', 'Content', 'Content', 'Content', 'Content', 'Content', '-']

====Annotation (`annoID` = 2356)====
text: Nenhuma idéia do que nos espera.
frameName: Awareness
frameID: 14
luName: ideia.n
luID: 26410
lu_idx: [(8, 12, 453)]
fe_idx: [(14, 30, 'Content', 58), (-1, -1, 'Cognizer', 57)]
tokenized_text: Nenhuma idéia do que nos espera .
tokenized_lu_idx: ['-', 'ideia.n', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', 'Awareness', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', 'Content', 'Content', 'Content', 'Content', '-']

===============================
====Annotation (`annoID` = 9807)====
text: Because she was the main reason we were leaving the country.
frameName: Political_locales
frameID: 175
luName: country.n
luID: 17523
lu_idx: [(52, 58, 1)]
fe_idx: [(52, 58, 'Locale', 1002)]
tokenized_text: Because she was the main reason we were leaving the country .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'country.n', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Political_locales', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Locale', '-']

====Annotation (`annoID` = 1348)====
text: Porque ela era a principal razão de estarmos deixando o país.
frameName: Political_locales
frameID: 175
luName: país.n
luID: 26489
lu_idx: [(56, 59, 453)]
fe_idx: [(-1, -1, 'Locale', 1002)]
tokenized_text: Porque ela era a principal razão de estarmos deixando o país .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'país.n', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Political_locales', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 9965)====
text: If you want real evidence of out-of-body experiences, get yourself along to a residential conference of senior academics, and pop into the discotheque on the final night.
frameName: Conditional_occurrence
frameID: 1192
luName: if.scon
luID: 26122
lu_idx: [(0, 1, 1)]
fe_idx: [(54, 168, 'Consequence', 11107), (3, 51, 'Profiled_possibility', 11106)]
tokenized_text: If you want real evidence of out-of-body experiences , get yourself along to a residential conference of senior academics , and pop into the discotheque on the final night .
tokenized_lu_idx: ['if.scon', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['Conditional_occurrence', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', 'Profiled_possibility', 'Profiled_possibility', 'Profiled_possibility', 'Profiled_possibility', 'Profiled_possibility', 'Profiled_possibility', 'Profiled_possibility', '-', 'Consequence', 'Consequence', 'Consequence', 'Consequence', 'Consequence', 'Consequence', 'Consequence', 'Consequence', 'Consequence', 'Consequence', 'Consequence', 'Consequence', 'Consequence', 'Consequence', 'Consequence', 'Consequence', 'Consequence', 'Consequence', 'Consequence', 'Consequence', '-']

====Annotation (`annoID` = 7117)====
text: Se você quiser evidências concretas de experiências extra-corpóreas, por sinal, é só participar de uma conferência de acadêmicos sênior, e aparecer na discoteca na noite final.
frameName: Conditional_occurrence
frameID: 1192
luName: se.c
luID: 26411
lu_idx: [(0, 1, 453)]
fe_idx: [(3, 77, 'Profiled_possibility', 11106), (80, 174, 'Consequence', 11107)]
tokenized_text: Se você quiser evidências concretas de experiências extra-corpóreas , por sinal , é só participar de uma conferência de acadêmicos sênior , e aparecer na discoteca na noite final .
tokenized_lu_idx: ['se.c', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['Conditional_occurrence', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', 'Profiled_possibility', 'Profiled_possibility', 'Profiled_possibility', 'Profiled_possibility', 'Profiled_possibility', 'Profiled_possibility', 'Profiled_possibility', 'Profiled_possibility', 'Profiled_possibility', 'Profiled_possibility', '-', 'Consequence', 'Consequence', 'Consequence', 'Consequence', 'Consequence', 'Consequence', 'Consequence', 'Consequence', 'Consequence', 'Consequence', 'Consequence', 'Consequence', 'Consequence', 'Consequence', 'Consequence', 'Consequence', 'Consequence', '-']

===============================
====Annotation (`annoID` = 2582)====
text: I say, 'Terry, please, I'm trying to fry an egg in here.'
frameName: Statement
frameID: 37
luName: say.v
luID: 13406
lu_idx: [(2, 4, 1)]
fe_idx: [(0, 0, 'Speaker', 152), (8, 54, 'Message', 154)]
tokenized_text: I say , ' Terry , please , I 'm trying to fry an egg in here . '
tokenized_lu_idx: ['-', 'say.v', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', 'Statement', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', 'Message', '-', '-']

====Annotation (`annoID` = 7607)====
text: Eu digo: 'Terry, por favor, estou tentando fritar um ovo aqui.Me deixa em paz.'
frameName: Statement
frameID: 37
luName: dizer.v
luID: 26321
lu_idx: [(3, 6, 453)]
fe_idx: [(0, 1, 'Speaker', 152), (10, 77, 'Topic', 155)]
tokenized_text: Eu digo : ' Terry , por favor , estou tentando fritar um ovo aqui.Me deixa em paz . '
tokenized_lu_idx: ['-', 'dizer.v', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', 'Statement', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['Speaker', '-', '-', '-', 'Topic', 'Topic', 'Topic', 'Topic', 'Topic', 'Topic', 'Topic', 'Topic', 'Topic', 'Topic', 'Topic', 'Topic', 'Topic', 'Topic', 'Topic', '-']

===============================
====Annotation (`annoID` = 9865)====
text: And then we focus on their heads.
frameName: Emphasizing
frameID: 685
luName: focus.v
luID: 23942
lu_idx: [(12, 16, 1)]
fe_idx: [(18, 31, 'Consideration', 5619), (9, 10, 'Agent', 5623), (-1, -1, 'Competing_consideration', 5626)]
tokenized_text: And then we focus on their heads .
tokenized_lu_idx: ['-', '-', '-', 'focus.v', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', 'Emphasizing', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', 'Agent', '-', 'Consideration', 'Consideration', 'Consideration', '-']

====Annotation (`annoID` = 1866)====
text: E depois nos focamos na cabeça.
frameName: Emphasizing
frameID: 685
luName: focar.v
luID: 26588
lu_idx: [(13, 19, 453)]
fe_idx: [(9, 11, 'Agent', 5623), (2, 7, 'Time', 5627)]
tokenized_text: E depois nos focamos na cabeça .
tokenized_lu_idx: ['-', '-', '-', 'focar.v', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', 'Emphasizing', '-', '-', '-']
tokenized_fe_idx: ['-', 'Time', 'Agent', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 9779)====
text: Being sent to bed by his dad, you know, to Shakespeare, 'Go to bed, now!
frameName: Kinship
frameID: 95
luName: dad.n
luID: 15677
lu_idx: [(25, 27, 1)]
fe_idx: [(21, 23, 'Ego', 414), (25, 27, 'Alter', 413)]
tokenized_text: Being sent to bed by his dad , you know , to Shakespeare , ' Go to bed , now !
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', 'dad.n', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', 'Kinship', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', 'Ego', 'Alter', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 1235)====
text: Ser mandado para cama com o pai dizendo 'Para cama, agora!',para William Shakespeare.
frameName: Kinship
frameID: 95
luName: pai.n
luID: 26361
lu_idx: [(28, 30, 453)]
fe_idx: [(-1, -1, 'Ego', 414), (-1, -1, 'Alter', 413)]
tokenized_text: Ser mandado para cama com o pai dizendo ' Para cama , agora !' , para William Shakespeare .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', 'pai.n', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', 'Kinship', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 9956)====
text: They look upon their body as a form of transport for their heads.
frameName: Body_parts
frameID: 108
luName: body.n
luID: 16075
lu_idx: [(21, 24, 1)]
fe_idx: [(21, 24, 'Body_part', 516), (15, 19, 'Possessor', 472)]
tokenized_text: They look upon their body as a form of transport for their heads .
tokenized_lu_idx: ['-', '-', '-', '-', 'body.n', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', 'Body_parts', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', 'Possessor', 'Body_part', '-', '-', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 1095)====
text: Eles vêem o próprio corpo como uma forma de transporte para a cabeça.
frameName: Body_parts
frameID: 108
luName: corpo.n
luID: 26353
lu_idx: [(20, 24, 453)]
fe_idx: [(10, 18, 'Descriptor', 515), (0, 3, 'Possessor', 472), (-1, -1, 'Body_part', 516)]
tokenized_text: Eles vêem o próprio corpo como uma forma de transporte para a cabeça .
tokenized_lu_idx: ['-', '-', '-', '-', 'corpo.n', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', 'Body_parts', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['Possessor', '-', 'Descriptor', 'Descriptor', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 9803)====
text: Because she was the main reason we were leaving the country.
frameName: Causation
frameID: 1
luName: because.c
luID: 12518
lu_idx: [(0, 6, 1)]
fe_idx: [(8, 58, 'Cause', 3)]
tokenized_text: Because she was the main reason we were leaving the country .
tokenized_lu_idx: ['because.c', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['Causation', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', 'Cause', 'Cause', 'Cause', 'Cause', 'Cause', 'Cause', 'Cause', 'Cause', 'Cause', 'Cause', '-']

====Annotation (`annoID` = 1344)====
text: Porque ela era a principal razão de estarmos deixando o país.
frameName: Causation
frameID: 1
luName: porque.c
luID: 26364
lu_idx: [(0, 5, 453)]
fe_idx: [(7, 9, 'Actor', 4756), (-1, -1, 'Affected', 4), (11, 59, 'Cause', 3), (-1, -1, 'Effect', 5)]
tokenized_text: Porque ela era a principal razão de estarmos deixando o país .
tokenized_lu_idx: ['porque.c', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['Causation', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', 'Actor', 'Cause', 'Cause', 'Cause', 'Cause', 'Cause', 'Cause', 'Cause', 'Cause', 'Cause', '-']

===============================
====Annotation (`annoID` = 10147)====
text: And it indicates the whole structure of education is shifting beneath our feet.
frameName: Education_teaching
frameID: 101
luName: education.n
luID: 15868
lu_idx: [(40, 48, 1)]
fe_idx: [(-1, -1, 'Teacher', 431), (-1, -1, 'Student', 432), (-1, -1, 'Subject', 434)]
tokenized_text: And it indicates the whole structure of education is shifting beneath our feet .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', 'education.n', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', 'Education_teaching', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 7336)====
text: E é um indicativo de que toda a estrutura educacional está mudando na frente do nosso nariz.
frameName: Education_teaching
frameID: 101
luName: educacional.a
luID: 26492
lu_idx: [(42, 52, 453)]
fe_idx: [(-1, -1, 'Student', 432), (-1, -1, 'Fact', 4339), (-1, -1, 'Role', 4378), (-1, -1, 'Subject', 434), (-1, -1, 'Teacher', 431)]
tokenized_text: E é um indicativo de que toda a estrutura educacional está mudando na frente do nosso nariz .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', 'educacional.a', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', 'Education_teaching', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 2502)====
text: Just seeing what she could do.
frameName: Perception_experience
frameID: 64
luName: see.v
luID: 14689
lu_idx: [(5, 10, 1)]
fe_idx: [(12, 28, 'Phenomenon', 288), (-1, -1, 'Perceiver_passive', 287)]
tokenized_text: Just seeing what she could do .
tokenized_lu_idx: ['-', 'see.v', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', 'Perception_experience', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', 'Phenomenon', 'Phenomenon', 'Phenomenon', 'Phenomenon', '-']

====Annotation (`annoID` = 4392)====
text: Ver do que ela é capaz.
frameName: Perception_experience
frameID: 64
luName: ver.v
luID: 27242
lu_idx: [(0, 2, 453)]
fe_idx: [(4, 21, 'Phenomenon', 288), (-1, -1, 'Perceiver_passive', 287)]
tokenized_text: Ver do que ela é capaz .
tokenized_lu_idx: ['ver.v', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['Perception_experience', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', 'Phenomenon', 'Phenomenon', 'Phenomenon', 'Phenomenon', 'Phenomenon', '-']

===============================
====Annotation (`annoID` = 2541)====
text: There have been three themes running through the conference which are relevant to what I want to talk about.
frameName: Being_relevant
frameID: 1039
luName: relevant.a
luID: 25523
lu_idx: [(70, 77, 1)]
fe_idx: [(60, 64, 'Phenomenon', 9731), (16, 58, 'Phenomenon', 9731), (79, 106, 'Endeavor', 9732)]
tokenized_text: There have been three themes running through the conference which are relevant to what I want to talk about .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'relevant.a', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Being_relevant', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', 'Phenomenon', 'Phenomenon', 'Phenomenon', 'Phenomenon', 'Phenomenon', 'Phenomenon', 'Phenomenon', '-', '-', 'Endeavor', 'Endeavor', 'Endeavor', 'Endeavor', 'Endeavor', 'Endeavor', 'Endeavor', '-']

====Annotation (`annoID` = 1017)====
text: Existem três tópicos abordados ao longo da conferência que são relevantes para o que eu vou falar.
frameName: Being_relevant
frameID: 1039
luName: relevante.a
luID: 26294
lu_idx: [(63, 72, 453)]
fe_idx: [(74, 96, 'Endeavor', 9732), (-1, -1, 'Cognizer', 9733), (55, 57, 'Phenomenon', 9731), (8, 53, 'Phenomenon', 9731)]
tokenized_text: Existem três tópicos abordados ao longo da conferência que são relevantes para o que eu vou falar .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'relevante.a', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Being_relevant', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', 'Phenomenon', 'Phenomenon', 'Phenomenon', 'Phenomenon', 'Phenomenon', 'Phenomenon', 'Phenomenon', 'Phenomenon', '-', '-', 'Endeavor', 'Endeavor', 'Endeavor', 'Endeavor', 'Endeavor', 'Endeavor', '-']

===============================
====Annotation (`annoID` = 10068)====
text: And I think we can't afford to go on that way.
frameName: Opinion
frameID: 642
luName: think.v
luID: 23709
lu_idx: [(6, 10, 1)]
fe_idx: [(4, 4, 'Cognizer', 5228), (12, 44, 'Opinion', 5229)]
tokenized_text: And I think we ca n't afford to go on that way .
tokenized_lu_idx: ['-', '-', 'think.v', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', 'Opinion', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', 'Cognizer', '-', 'Opinion', 'Opinion', 'Opinion', 'Opinion', 'Opinion', 'Opinion', 'Opinion', 'Opinion', 'Opinion', '-']

====Annotation (`annoID` = 7175)====
text: Eu acho que não podemos nos dar ao luxo de ir por esse caminho.
frameName: Opinion
frameID: 642
luName: achar.v
luID: 26333
lu_idx: [(3, 6, 453)]
fe_idx: [(0, 1, 'Cognizer', 5228), (12, 61, 'Opinion', 5229), (8, 10, 'Opinion', 5229)]
tokenized_text: Eu acho que não podemos nos dar ao luxo de ir por esse caminho .
tokenized_lu_idx: ['-', 'achar.v', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', 'Opinion', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['Cognizer', '-', 'Opinion', 'Opinion', 'Opinion', 'Opinion', 'Opinion', 'Opinion', 'Opinion', 'Opinion', 'Opinion', 'Opinion', 'Opinion', 'Opinion', '-']

===============================
====Annotation (`annoID` = 9746)====
text: The problem is to remain an artist as we grow up.
frameName: State_continue
frameID: 554
luName: remain.v
luID: 23200
lu_idx: [(18, 23, 1)]
fe_idx: [(35, 47, 'Time', 4467), (25, 33, 'State', 4466)]
tokenized_text: The problem is to remain an artist as we grow up .
tokenized_lu_idx: ['-', '-', '-', '-', 'remain.v', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', 'State_continue', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', 'State', 'State', 'Time', 'Time', 'Time', 'Time', '-']

====Annotation (`annoID` = 2214)====
text: O problema é permanecer artista enquanto crescemos.
frameName: State_continue
frameID: 554
luName: permanecer.v
luID: 26628
lu_idx: [(13, 22, 453)]
fe_idx: [(24, 30, 'State', 4466), (32, 49, 'Duration', 6186), (-1, -1, 'Entity', 4465)]
tokenized_text: O problema é permanecer artista enquanto crescemos .
tokenized_lu_idx: ['-', '-', '-', 'permanecer.v', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', 'State_continue', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', 'State', 'Duration', 'Duration', '-']

===============================
====Annotation (`annoID` = 4190)====
text: People who had to move to think.'
frameName: Cogitation
frameID: 17
luName: think.v
luID: 12862
lu_idx: [(26, 30, 1)]
fe_idx: [(-1, -1, 'Topic', 71), (7, 9, 'Cognizer', 70), (0, 5, 'Cognizer', 70)]
tokenized_text: People who had to move to think . '
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', 'think.v', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', 'Cogitation', '-', '-']
tokenized_fe_idx: ['Cognizer', 'Cognizer', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 6989)====
text: Pessoas que precisavam se mexer para pensar.
frameName: Cogitation
frameID: 17
luName: pensar.v
luID: 27246
lu_idx: [(37, 42, 453)]
fe_idx: [(-1, -1, 'Topic', 71), (0, 6, 'Cognizer', 70)]
tokenized_text: Pessoas que precisavam se mexer para pensar .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', 'pensar.v', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', 'Cogitation', '-']
tokenized_fe_idx: ['Cognizer', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 9830)====
text: Art and music are normally given a higher status in schools than drama and dance.
frameName: Fields
frameID: 616
luName: art.n
luID: 23515
lu_idx: [(0, 2, 1)]
fe_idx: [(0, 2, 'Activity', 5025)]
tokenized_text: Art and music are normally given a higher status in schools than drama and dance .
tokenized_lu_idx: ['art.n', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['Fields', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['Activity', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 1379)====
text: Arte e música normalmente tem uma importância maior nas escolas do que drama e dança.
frameName: Fields
frameID: 616
luName: arte.n
luID: 26506
lu_idx: [(0, 3, 453)]
fe_idx: [(-1, -1, 'Salient_entity', 5027), (-1, -1, 'Practitioner', 5026), (-1, -1, 'Activity', 5025), (-1, -1, 'Work', 5028)]
tokenized_text: Arte e música normalmente tem uma importância maior nas escolas do que drama e dança .
tokenized_lu_idx: ['arte.n', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['Fields', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 8821)====
text: But as they went out of the room, he turned on the radio that was sitting on his desk.
frameName: Change_operational_state
frameID: 772
luName: turn on.v
luID: 24381
lu_idx: [(44, 45, 1), (37, 42, 1)]
fe_idx: [(4, 31, 'Time', 6590), (34, 35, 'Agent', 6592), (47, 84, 'Device', 6589)]
tokenized_text: But as they went out of the room , he turned on the radio that was sitting on his desk .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'turn on.v', 'turn on.v', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Change_operational_state', 'Change_operational_state', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', 'Time', 'Time', 'Time', 'Time', 'Time', 'Time', 'Time', '-', 'Agent', '-', '-', 'Device', 'Device', 'Device', 'Device', 'Device', 'Device', 'Device', 'Device', '-']

====Annotation (`annoID` = 7488)====
text: Mas enquanto eles saiam da sala, ele ligou o rádio que estava sobre a mesa.
frameName: Change_operational_state
frameID: 772
luName: ligar.v
luID: 28540
lu_idx: [(37, 41, 453)]
fe_idx: [(51, 73, 'Place', 6591), (43, 49, 'Device', 6589), (33, 35, 'Agent', 6592)]
tokenized_text: Mas enquanto eles saiam da sala , ele ligou o rádio que estava sobre a mesa .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', 'ligar.v', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', 'Change_operational_state', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', 'Agent', '-', 'Device', 'Device', 'Place', 'Place', 'Place', 'Place', 'Place', '-']

===============================
====Annotation (`annoID` = 4283)====
text: My contention is that creativity now is as important in education as literacy, and we should treat it with the same status.
frameName: Importance
frameID: 376
luName: important.a
luID: 21016
lu_idx: [(43, 51, 1)]
fe_idx: [(66, 76, 'Degree', 2836), (53, 64, 'Field', 2854), (22, 31, 'Factor', 2835), (40, 41, 'Degree', 2836)]
tokenized_text: My contention is that creativity now is as important in education as literacy , and we should treat it with the same status .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', 'important.a', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', 'Importance', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', 'Factor', '-', '-', 'Degree', '-', 'Field', 'Field', 'Degree', 'Degree', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 1475)====
text: Minha convicção é que a criatividade hoje é tão importante na educação como a alfabetização, e deve ser tratada com a mesma importância.
frameName: Importance
frameID: 376
luName: importante.a
luID: 26551
lu_idx: [(48, 57, 453)]
fe_idx: [(22, 35, 'Factor', 2835), (-1, -1, 'Undertaking', 2837), (37, 40, 'Time', 6896), (59, 69, 'Field', 2854)]
tokenized_text: Minha convicção é que a criatividade hoje é tão importante na educação como a alfabetização , e deve ser tratada com a mesma importância .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', 'importante.a', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', 'Importance', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', 'Factor', 'Factor', 'Time', '-', '-', '-', 'Field', 'Field', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 10063)====
text: And the second is academic ability, which has really come to dominate our view of intelligence, because the universities designed the system in their image.
frameName: Locale_by_use
frameID: 176
luName: university.n
luID: 17587
lu_idx: [(108, 119, 1)]
fe_idx: [(108, 119, 'Locale', 1006)]
tokenized_text: And the second is academic ability , which has really come to dominate our view of intelligence , because the universities designed the system in their image .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'university.n', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Locale_by_use', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Locale', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 1163)====
text: A segunda é a aptidão acadêmica, que veio a dominar nossa visão de inteligência, porque as universidades planejaram o sistema à sua própria imagem.
frameName: Locale_by_use
frameID: 176
luName: universidade.n
luID: 26381
lu_idx: [(91, 103, 453)]
fe_idx: [(-1, -1, 'Use', 4483), (-1, -1, 'Locale', 1006)]
tokenized_text: A segunda é a aptidão acadêmica , que veio a dominar nossa visão de inteligência , porque as universidades planejaram o sistema à sua própria imagem .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'universidade.n', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Locale_by_use', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 2520)====
text: If you think of it, children starting school this year will be retiring in 2065.
frameName: Quitting
frameID: 297
luName: retire.v
luID: 19594
lu_idx: [(63, 70, 1)]
fe_idx: [(20, 53, 'Employee', 2020), (72, 78, 'Time', 2027)]
tokenized_text: If you think of it , children starting school this year will be retiring in 2065 .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'retire.v', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Quitting', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', 'Employee', 'Employee', 'Employee', 'Employee', 'Employee', '-', '-', '-', 'Time', 'Time', '-']

====Annotation (`annoID` = 4357)====
text: Se formos pensar, as crianças entrando na escola esse ano estarão se aposentando em 2065.
frameName: Quitting
frameID: 297
luName: aposentar.v
luID: 27264
lu_idx: [(69, 79, 453)]
fe_idx: [(-1, -1, 'Position', 2025), (18, 28, 'Employee', 2020), (81, 87, 'Time', 2027)]
tokenized_text: Se formos pensar , as crianças entrando na escola esse ano estarão se aposentando em 2065 .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'aposentar.v', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Quitting', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', 'Employee', 'Employee', '-', '-', '-', '-', '-', '-', '-', '-', 'Time', 'Time', '-']

===============================
====Annotation (`annoID` = 2607)====
text: One is the extraordinary evidence of human creativity in all of the presentations that we've had and in all of the people here.
frameName: Text
frameID: 272
luName: presentation.n
luID: 26699
lu_idx: [(68, 80, 1)]
fe_idx: [(68, 80, 'Text', 1784)]
tokenized_text: One is the extraordinary evidence of human creativity in all of the presentations that we 've had and in all of the people here .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'presentation.n', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Text', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Text', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 4290)====
text: O primeiro é a extraordinária evidência da criatividade humana em todas as apresentações que tivemos e em todas as pessoas presentes.
frameName: Text
frameID: 272
luName: apresentação.n
luID: 27224
lu_idx: [(75, 87, 453)]
fe_idx: [(-1, -1, 'Text', 1784)]
tokenized_text: O primeiro é a extraordinária evidência da criatividade humana em todas as apresentações que tivemos e em todas as pessoas presentes .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'apresentação.n', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Text', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 4527)====
text: If they don't know, they'll have a go.
frameName: Conditional_occurrence
frameID: 1192
luName: if.scon
luID: 26122
lu_idx: [(0, 1, 1)]
fe_idx: [(20, 36, 'Consequence', 11107), (3, 17, 'Profiled_possibility', 11106)]
tokenized_text: If they do n't know , they 'll have a go .
tokenized_lu_idx: ['if.scon', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['Conditional_occurrence', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', 'Profiled_possibility', 'Profiled_possibility', 'Profiled_possibility', 'Profiled_possibility', '-', 'Consequence', 'Consequence', 'Consequence', 'Consequence', 'Consequence', '-']

====Annotation (`annoID` = 1215)====
text: Se elas não sabem, elas chutam.
frameName: Conditional_occurrence
frameID: 1192
luName: se.c
luID: 26411
lu_idx: [(0, 1, 453)]
fe_idx: [(3, 16, 'Profiled_possibility', 11106), (19, 29, 'Consequence', 11107)]
tokenized_text: Se elas não sabem , elas chutam .
tokenized_lu_idx: ['se.c', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['Conditional_occurrence', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', 'Profiled_possibility', 'Profiled_possibility', 'Profiled_possibility', '-', 'Consequence', 'Consequence', '-']

===============================
====Annotation (`annoID` = 2424)====
text: But if you ask about their education, they pin you to the wall.
frameName: Conditional_occurrence
frameID: 1192
luName: if.scon
luID: 26122
lu_idx: [(4, 5, 1)]
fe_idx: [(7, 35, 'Profiled_possibility', 11106), (38, 61, 'Consequence', 11107)]
tokenized_text: But if you ask about their education , they pin you to the wall .
tokenized_lu_idx: ['-', 'if.scon', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', 'Conditional_occurrence', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', 'Profiled_possibility', 'Profiled_possibility', 'Profiled_possibility', 'Profiled_possibility', 'Profiled_possibility', '-', 'Consequence', 'Consequence', 'Consequence', 'Consequence', 'Consequence', 'Consequence', '-']

====Annotation (`annoID` = 2236)====
text: Mas se você perguntar sobre a educação deles, eles te põem contra a parede.
frameName: Conditional_occurrence
frameID: 1192
luName: se.c
luID: 26411
lu_idx: [(4, 5, 453)]
fe_idx: [(7, 43, 'Profiled_possibility', 11106), (46, 73, 'Consequence', 11107)]
tokenized_text: Mas se você perguntar sobre a educação deles , eles te põem contra a parede .
tokenized_lu_idx: ['-', 'se.c', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', 'Conditional_occurrence', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', 'Profiled_possibility', 'Profiled_possibility', 'Profiled_possibility', 'Profiled_possibility', 'Profiled_possibility', 'Profiled_possibility', '-', 'Consequence', 'Consequence', 'Consequence', 'Consequence', 'Consequence', 'Consequence', '-']

===============================
====Annotation (`annoID` = 2165)====
text: There have been three themes running through the conference which are relevant to what I want to talk about.
frameName: Topic
frameID: 343
luName: theme.n
luID: 20467
lu_idx: [(22, 27, 1)]
fe_idx: [(22, 27, 'Topic', 2452)]
tokenized_text: There have been three themes running through the conference which are relevant to what I want to talk about .
tokenized_lu_idx: ['-', '-', '-', '-', 'theme.n', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', 'Topic', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', 'Topic', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 1014)====
text: Existem três tópicos abordados ao longo da conferência que são relevantes para o que eu vou falar.
frameName: Topic
frameID: 343
luName: abordar.v
luID: 26296
lu_idx: [(21, 29, 453)]
fe_idx: [(8, 19, 'Topic', 2452), (31, 53, 'Text', 2453), (31, 53, 'Time', 7567)]
tokenized_text: Existem três tópicos abordados ao longo da conferência que são relevantes para o que eu vou falar .
tokenized_lu_idx: ['-', '-', '-', 'abordar.v', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', 'Topic', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', 'Topic', 'Topic', '-', 'Time', 'Time', 'Time', 'Time', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 10020)====
text: So you were probably steered benignly away from things at school when you were a kid, things you liked, on the grounds that you would never get a job doing that.
frameName: Locale_by_use
frameID: 176
luName: school.n
luID: 17586
lu_idx: [(58, 63, 1)]
fe_idx: [(58, 63, 'Locale', 1006)]
tokenized_text: So you were probably steered benignly away from things at school when you were a kid , things you liked , on the grounds that you would never get a job doing that .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'school.n', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Locale_by_use', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Locale', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 6725)====
text: Então você era bondosamente afastado na escola quando era criança de certas coisas, coisas que gostava, com a premissa que você nunca iria conseguir um emprego fazendo aquilo.
frameName: Locale_by_use
frameID: 176
luName: escola.n
luID: 26512
lu_idx: [(40, 45, 453)]
fe_idx: []
tokenized_text: Então você era bondosamente afastado na escola quando era criança de certas coisas , coisas que gostava , com a premissa que você nunca iria conseguir um emprego fazendo aquilo .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', 'escola.n', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', 'Locale_by_use', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 10304)====
text: I believe our only hope for the future is to adopt a new conception of human ecology, one in which we start to reconstitute our conception of the richness of human capacity.
frameName: Awareness
frameID: 14
luName: conception.n
luID: 12767
lu_idx: [(128, 137, 1)]
fe_idx: [(124, 126, 'Cognizer', 57), (139, 171, 'Content', 58)]
tokenized_text: I believe our only hope for the future is to adopt a new conception of human ecology , one in which we start to reconstitute our conception of the richness of human capacity .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'conception.n', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Awareness', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Cognizer', '-', 'Content', 'Content', 'Content', 'Content', 'Content', 'Content', '-']

====Annotation (`annoID` = 6848)====
text: Eu acredito que nossa única esperança para o futuro é a adoção de uma nova concepção de ecologia humana, uma em que começamos a reconstituir nossa concepção da riqueza da capacidade humana.
frameName: Awareness
frameID: 14
luName: concepção.n
luID: 28290
lu_idx: [(147, 155, 453)]
fe_idx: [(157, 187, 'Topic', 60), (141, 145, 'Cognizer', 57)]
tokenized_text: Eu acredito que nossa única esperança para o futuro é a adoção de uma nova concepção de ecologia humana , uma em que começamos a reconstituir nossa concepção da riqueza da capacidade humana .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'concepção.n', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Awareness', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Cognizer', '-', 'Topic', 'Topic', 'Topic', 'Topic', 'Topic', '-']

===============================
====Annotation (`annoID` = 4426)====
text: If you think of it, children starting school this year will be retiring in 2065.
frameName: Temporal_collocation
frameID: 838
luName: in.prep
luID: 24700
lu_idx: [(72, 73, 1)]
fe_idx: [(75, 78, 'Landmark_period', 8243), (20, 70, 'Trajector_event', 8244)]
tokenized_text: If you think of it , children starting school this year will be retiring in 2065 .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'in.prep', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Temporal_collocation', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', 'Trajector_event', 'Trajector_event', 'Trajector_event', 'Trajector_event', 'Trajector_event', 'Trajector_event', 'Trajector_event', 'Trajector_event', '-', 'Landmark_period', '-']

====Annotation (`annoID` = 4358)====
text: Se formos pensar, as crianças entrando na escola esse ano estarão se aposentando em 2065.
frameName: Temporal_collocation
frameID: 838
luName: em.prep
luID: 27226
lu_idx: [(81, 82, 453)]
fe_idx: [(18, 79, 'Trajector_event', 8244), (84, 87, 'Landmark_period', 8243)]
tokenized_text: Se formos pensar , as crianças entrando na escola esse ano estarão se aposentando em 2065 .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'em.prep', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Temporal_collocation', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', 'Trajector_event', 'Trajector_event', 'Trajector_event', 'Trajector_event', 'Trajector_event', 'Trajector_event', 'Trajector_event', 'Trajector_event', 'Trajector_event', 'Trajector_event', '-', 'Landmark_period', '-']

===============================
====Annotation (`annoID` = 9782)====
text: Anyway, we moved from Stratford to Los Angeles, and I just want to say a word about the transition.
frameName: Topic
frameID: 343
luName: about.prep
luID: 20457
lu_idx: [(78, 82, 1)]
fe_idx: [(71, 76, 'Text', 2453), (84, 97, 'Topic', 2452)]
tokenized_text: Anyway , we moved from Stratford to Los Angeles , and I just want to say a word about the transition .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'about.prep', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Topic', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Text', 'Text', '-', 'Topic', 'Topic', '-']

====Annotation (`annoID` = 1285)====
text: Enfim, nos mudamos de Stratford para Los Angeles, e eu só quero dizer uma coisa sobre essa transição.
frameName: Topic
frameID: 343
luName: sobre.prep
luID: 26435
lu_idx: [(80, 84, 453)]
fe_idx: [(52, 53, 'Communicator', 2454), (86, 99, 'Topic', 2452), (-1, -1, 'Text', 2453)]
tokenized_text: Enfim , nos mudamos de Stratford para Los Angeles , e eu só quero dizer uma coisa sobre essa transição .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'sobre.prep', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Topic', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Communicator', '-', '-', '-', '-', '-', '-', 'Topic', 'Topic', '-']

===============================
====Annotation (`annoID` = 9828)====
text: Art and music are normally given a higher status in schools than drama and dance.
frameName: Frequency
frameID: 74
luName: normally.adv
luID: 15103
lu_idx: [(18, 25, 1)]
fe_idx: [(27, 79, 'Event', 326), (0, 16, 'Event', 326)]
tokenized_text: Art and music are normally given a higher status in schools than drama and dance .
tokenized_lu_idx: ['-', '-', '-', '-', 'normally.adv', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', 'Frequency', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['Event', 'Event', 'Event', 'Event', '-', 'Event', 'Event', 'Event', 'Event', 'Event', 'Event', 'Event', 'Event', 'Event', 'Event', '-']

====Annotation (`annoID` = 1382)====
text: Arte e música normalmente tem uma importância maior nas escolas do que drama e dança.
frameName: Frequency
frameID: 74
luName: normalmente.adv
luID: 26509
lu_idx: [(14, 24, 453)]
fe_idx: [(-1, -1, 'Attribute', 6005), (26, 83, 'Event', 326), (-1, -1, 'Interval', 3283), (-1, -1, 'Time_span', 3284), (0, 12, 'Salient_entity', 6004), (-1, -1, 'Rate', 6003), (-1, -1, 'Degree', 1254)]
tokenized_text: Arte e música normalmente tem uma importância maior nas escolas do que drama e dança .
tokenized_lu_idx: ['-', '-', '-', 'normalmente.adv', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', 'Frequency', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['Salient_entity', 'Salient_entity', 'Salient_entity', '-', 'Event', 'Event', 'Event', 'Event', 'Event', 'Event', 'Event', 'Event', 'Event', 'Event', 'Event', '-']

===============================
====Annotation (`annoID` = 4193)====
text: We walked in this room and it was full of people like me.
frameName: Building_subparts
frameID: 169
luName: room.n
luID: 17179
lu_idx: [(18, 21, 1)]
fe_idx: [(18, 21, 'Building_part', 6571)]
tokenized_text: We walked in this room and it was full of people like me .
tokenized_lu_idx: ['-', '-', '-', '-', 'room.n', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', 'Building_subparts', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', 'Building_part', '-', '-', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 7415)====
text: Entramos numa sala cheia de pessoas como eu.
frameName: Building_subparts
frameID: 169
luName: sala.n
luID: 28497
lu_idx: [(14, 17, 453)]
fe_idx: [(19, 42, 'Descriptor', 10801), (-1, -1, 'Building_part', 6571)]
tokenized_text: Entramos numa sala cheia de pessoas como eu .
tokenized_lu_idx: ['-', '-', 'sala.n', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', 'Building_subparts', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', 'Descriptor', 'Descriptor', 'Descriptor', 'Descriptor', 'Descriptor', '-']

===============================
====Annotation (`annoID` = 9846)====
text: I think math is very important, but so is dance.
frameName: Importance
frameID: 376
luName: important.a
luID: 21016
lu_idx: [(21, 29, 1)]
fe_idx: [(8, 11, 'Factor', 2835), (16, 19, 'Degree', 2836)]
tokenized_text: I think math is very important , but so is dance .
tokenized_lu_idx: ['-', '-', '-', '-', '-', 'important.a', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', 'Importance', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', 'Factor', '-', 'Degree', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 1542)====
text: Eu acho que matemática é importante, mas dança também.
frameName: Importance
frameID: 376
luName: importante.a
luID: 26551
lu_idx: [(25, 34, 453)]
fe_idx: [(-1, -1, 'Factor', 2835), (-1, -1, 'Interested_party', 2853), (-1, -1, 'Undertaking', 2837), (12, 21, 'Field', 2854)]
tokenized_text: Eu acho que matemática é importante , mas dança também .
tokenized_lu_idx: ['-', '-', '-', '-', '-', 'importante.a', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', 'Importance', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', 'Field', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 9661)====
text: There have been three themes running through the conference which are relevant to what I want to talk about.
frameName: Discussion
frameID: 28
luName: conference.n
luID: 13186
lu_idx: [(49, 58, 1)]
fe_idx: [(-1, -1, 'Interlocutors', 111)]
tokenized_text: There have been three themes running through the conference which are relevant to what I want to talk about .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', 'conference.n', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', 'Discussion', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 1016)====
text: Existem três tópicos abordados ao longo da conferência que são relevantes para o que eu vou falar.
frameName: Discussion
frameID: 28
luName: conferência.n
luID: 26298
lu_idx: [(43, 53, 453)]
fe_idx: [(-1, -1, 'Topic', 112), (-1, -1, 'Interlocutors', 111)]
tokenized_text: Existem três tópicos abordados ao longo da conferência que são relevantes para o que eu vou falar .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', 'conferência.n', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', 'Discussion', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 10082)====
text: And the second is academic ability, which has really come to dominate our view of intelligence, because the universities designed the system in their image.
frameName: Opinion
frameID: 642
luName: view.n
luID: 23707
lu_idx: [(74, 77, 1)]
fe_idx: [(74, 77, 'Opinion', 5229), (79, 93, 'Topic', 5231), (70, 72, 'Cognizer', 5228)]
tokenized_text: And the second is academic ability , which has really come to dominate our view of intelligence , because the universities designed the system in their image .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'view.n', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Opinion', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Cognizer', 'Opinion', 'Topic', 'Topic', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 1162)====
text: A segunda é a aptidão acadêmica, que veio a dominar nossa visão de inteligência, porque as universidades planejaram o sistema à sua própria imagem.
frameName: Opinion
frameID: 642
luName: visão.n
luID: 26380
lu_idx: [(58, 62, 453)]
fe_idx: [(52, 56, 'Cognizer', 5228), (64, 78, 'Topic', 5231)]
tokenized_text: A segunda é a aptidão acadêmica , que veio a dominar nossa visão de inteligência , porque as universidades planejaram o sistema à sua própria imagem .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'visão.n', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Opinion', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Cognizer', '-', 'Topic', 'Topic', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 4513)====
text: But James got the part of Joseph, which we were thrilled about.
frameName: Performers_and_roles
frameID: 382
luName: part.n
luID: 21105
lu_idx: [(18, 21, 1)]
fe_idx: [(23, 31, 'Role', 2877), (4, 8, 'Performer', 2872)]
tokenized_text: But James got the part of Joseph , which we were thrilled about .
tokenized_lu_idx: ['-', '-', '-', '-', 'part.n', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', 'Performers_and_roles', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', 'Performer', '-', '-', '-', 'Role', 'Role', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 6604)====
text: Mas o James ganhou o papel de José, o que nos deixou empolgados.
frameName: Performers_and_roles
frameID: 382
luName: papel.n
luID: 27260
lu_idx: [(21, 25, 453)]
fe_idx: [(-1, -1, 'Script', 2874), (27, 33, 'Role', 2877), (-1, -1, 'Medium', 2870), (-1, -1, 'Performance', 2871), (-1, -1, 'Audience', 2869), (-1, -1, 'Score', 2873), (4, 10, 'Performer', 2872), (-1, -1, 'Type', 2875)]
tokenized_text: Mas o James ganhou o papel de José , o que nos deixou empolgados .
tokenized_lu_idx: ['-', '-', '-', '-', '-', 'papel.n', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', 'Performers_and_roles', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', 'Performer', 'Performer', '-', '-', '-', 'Role', 'Role', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 4061)====
text: The teacher was fascinated.
frameName: Education_teaching
frameID: 101
luName: teacher.n
luID: 15849
lu_idx: [(4, 10, 1)]
fe_idx: [(4, 10, 'Teacher', 431)]
tokenized_text: The teacher was fascinated .
tokenized_lu_idx: ['-', 'teacher.n', '-', '-', '-']
tokenized_frame_idx: ['-', 'Education_teaching', '-', '-', '-']
tokenized_fe_idx: ['-', 'Teacher', '-', '-', '-']

====Annotation (`annoID` = 1525)====
text: A professora ficou fascinada, foi até ela e perguntou: 'O que você está desenhando?'
frameName: Education_teaching
frameID: 101
luName: professor.n
luID: 26567
lu_idx: [(2, 11, 453)]
fe_idx: [(-1, -1, 'Student', 432), (-1, -1, 'Fact', 4339), (-1, -1, 'Role', 4378), (19, 27, 'Depictive', 459), (-1, -1, 'Subject', 434), (-1, -1, 'Teacher', 431)]
tokenized_text: A professora ficou fascinada , foi até ela e perguntou : ' O que você está desenhando ? '
tokenized_lu_idx: ['-', 'professor.n', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', 'Education_teaching', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', 'Depictive', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 9986)====
text: Waiting until it ends so they can go home and write a paper about it.
frameName: Text
frameID: 272
luName: paper [article].n
luID: 19261
lu_idx: [(54, 58, 1)]
fe_idx: [(54, 58, 'Text', 1784), (25, 28, 'Author', 1783)]
tokenized_text: Waiting until it ends so they can go home and write a paper about it .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'paper [article].n', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Text', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', 'Author', '-', '-', '-', '-', '-', '-', 'Text', '-', '-', '-']

====Annotation (`annoID` = 6716)====
text: Só esperando que o evento acabe e eles possam escrever um artigo a respeito.
frameName: Text
frameID: 272
luName: artigo.n
luID: 28230
lu_idx: [(58, 63, 453)]
fe_idx: [(-1, -1, 'Text', 1784)]
tokenized_text: Só esperando que o evento acabe e eles possam escrever um artigo a respeito .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'artigo.n', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Text', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 10171)====
text: We think in abstract terms, we think in movement.
frameName: Domain
frameID: 399
luName: in terms.idio
luID: 21465
lu_idx: [(9, 10, 1), (21, 25, 1)]
fe_idx: [(12, 19, 'Domain', 3026), (0, 7, 'Predicate', 3025)]
tokenized_text: We think in abstract terms , we think in movement .
tokenized_lu_idx: ['-', '-', 'in terms.idio', '-', 'in terms.idio', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', 'Domain', '-', 'Domain', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['Predicate', 'Predicate', '-', 'Domain', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 7375)====
text: Pensamos em termo abstratos, pensamos em movimento.
frameName: Domain
frameID: 399
luName: em termos.idio
luID: 28495
lu_idx: [(12, 16, 453), (9, 10, 453)]
fe_idx: [(18, 26, 'Predicate', 3025), (-1, -1, 'Domain', 3026)]
tokenized_text: Pensamos em termo abstratos , pensamos em movimento .
tokenized_lu_idx: ['-', 'em termos.idio', 'em termos.idio', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', 'Domain', 'Domain', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', 'Predicate', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 9734)====
text: And the result is that we are educating people out of their creative capacities.
frameName: Causation
frameID: 1
luName: result.n
luID: 12523
lu_idx: [(8, 13, 1)]
fe_idx: [(-1, -1, 'Cause', 3), (18, 78, 'Effect', 5)]
tokenized_text: And the result is that we are educating people out of their creative capacities .
tokenized_lu_idx: ['-', '-', 'result.n', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', 'Causation', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', 'Effect', 'Effect', 'Effect', 'Effect', 'Effect', 'Effect', 'Effect', 'Effect', 'Effect', 'Effect', '-']

====Annotation (`annoID` = 2200)====
text: O resultado disso é que estamos educando as pessoas para serem menos criativas.
frameName: Causation
frameID: 1
luName: resultado.n
luID: 26597
lu_idx: [(2, 10, 453)]
fe_idx: [(12, 16, 'Cause', 3), (-1, -1, 'Actor', 4756), (24, 77, 'Effect', 5)]
tokenized_text: O resultado disso é que estamos educando as pessoas para serem menos criativas .
tokenized_lu_idx: ['-', 'resultado.n', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', 'Causation', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', 'Cause', '-', '-', 'Effect', 'Effect', 'Effect', 'Effect', 'Effect', 'Effect', 'Effect', 'Effect', '-']

===============================
====Annotation (`annoID` = 4501)====
text: When my son was four in England -- 
frameName: Kinship
frameID: 95
luName: son.n
luID: 15672
lu_idx: [(8, 10, 1)]
fe_idx: [(8, 10, 'Alter', 413), (5, 6, 'Ego', 414)]
tokenized_text: When my son was four in England --
tokenized_lu_idx: ['-', '-', 'son.n', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', 'Kinship', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', 'Ego', 'Alter', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 6569)====
text: Quando meu filho tinha quatro anos na Inglaterra...
frameName: Kinship
frameID: 95
luName: filho.n
luID: 26385
lu_idx: [(11, 15, 453)]
fe_idx: [(-1, -1, 'Ego', 414), (7, 9, 'Alter', 413)]
tokenized_text: Quando meu filho tinha quatro anos na Inglaterra ...
tokenized_lu_idx: ['-', '-', 'filho.n', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', 'Kinship', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', 'Alter', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 4398)====
text: The second is that it's put us in a place where we have no idea what's going to happen, in terms of the future.
frameName: Awareness
frameID: 14
luName: idea.n
luID: 12788
lu_idx: [(59, 62, 1)]
fe_idx: [(48, 49, 'Cognizer', 57), (64, 109, 'Content', 58)]
tokenized_text: The second is that it 's put us in a place where we have no idea what 's going to happen , in terms of the future .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'idea.n', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Awareness', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Cognizer', '-', '-', '-', 'Content', 'Content', 'Content', 'Content', 'Content', 'Content', 'Content', 'Content', 'Content', 'Content', 'Content', '-']

====Annotation (`annoID` = 4292)====
text: O segundo é o fato de que não fazemos a menor idéia do que vai acontecer no futuro.
frameName: Awareness
frameID: 14
luName: fazer ideia.v
luID: 27225
lu_idx: [(30, 50, 453)]
fe_idx: [(52, 81, 'Content', 58), (-1, -1, 'Cognizer', 57), (38, 44, 'Degree', 638)]
tokenized_text: O segundo é o fato de que não fazemos a menor idéia do que vai acontecer no futuro .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', 'fazer ideia.v', 'fazer ideia.v', 'fazer ideia.v', 'fazer ideia.v', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', 'Awareness', 'Awareness', 'Awareness', 'Awareness', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', 'Degree', 'Degree', '-', 'Content', 'Content', 'Content', 'Content', 'Content', 'Content', '-']

===============================
====Annotation (`annoID` = 9582)====
text: When my son was four in England -- 
frameName: Cardinal_numbers
frameID: 196
luName: four.num
luID: 17868
lu_idx: [(16, 19, 1)]
fe_idx: [(-1, -1, 'Unit', 11398), (16, 19, 'Number', 2715)]
tokenized_text: When my son was four in England --
tokenized_lu_idx: ['-', '-', '-', '-', 'four.num', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', 'Cardinal_numbers', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', 'Number', '-', '-', '-']

====Annotation (`annoID` = 6571)====
text: Quando meu filho tinha quatro anos na Inglaterra...
frameName: Cardinal_numbers
frameID: 196
luName: quatro.num
luID: 26313
lu_idx: [(23, 28, 453)]
fe_idx: [(-1, -1, 'Number', 2715), (30, 33, 'Entity', 2716)]
tokenized_text: Quando meu filho tinha quatro anos na Inglaterra ...
tokenized_lu_idx: ['-', '-', '-', '-', 'quatro.num', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', 'Cardinal_numbers', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', 'Entity', '-', '-', '-']

===============================
====Annotation (`annoID` = 9815)====
text: So I want to talk about education and I want to talk about creativity.
frameName: Topic
frameID: 343
luName: about.prep
luID: 20457
lu_idx: [(53, 57, 1)]
fe_idx: [(38, 38, 'Communicator', 2454), (-1, -1, 'Text', 2453), (59, 68, 'Topic', 2452)]
tokenized_text: So I want to talk about education and I want to talk about creativity .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'about.prep', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Topic', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', 'Communicator', '-', '-', '-', '-', 'Topic', '-']

====Annotation (`annoID` = 1500)====
text: Por isso eu quero falar sobre educação e quero falar sobre criatividade.
frameName: Topic
frameID: 343
luName: sobre.prep
luID: 26435
lu_idx: [(53, 57, 453)]
fe_idx: [(-1, -1, 'Communicator', 2454), (59, 70, 'Topic', 2452), (-1, -1, 'Text', 2453)]
tokenized_text: Por isso eu quero falar sobre educação e quero falar sobre criatividade .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'sobre.prep', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Topic', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'Topic', '-']

===============================
====Annotation (`annoID` = 2539)====
text: Am I right?
frameName: Correctness
frameID: 668
luName: right.a
luID: 23839
lu_idx: [(5, 9, 1)]
fe_idx: [(-1, -1, 'Information', 5488), (3, 3, 'Source', 8019)]
tokenized_text: Am I right ?
tokenized_lu_idx: ['-', '-', 'right.a', '-']
tokenized_frame_idx: ['-', '-', 'Correctness', '-']
tokenized_fe_idx: ['-', 'Source', '-', '-']

====Annotation (`annoID` = 1217)====
text: Estou certo?
frameName: Correctness
frameID: 668
luName: certo.a
luID: 26416
lu_idx: [(6, 10, 453)]
fe_idx: [(-1, -1, 'Information', 5488), (-1, -1, 'Source', 8019), (-1, -1, 'Communicative_act', 8981)]
tokenized_text: Estou certo ?
tokenized_lu_idx: ['-', 'certo.a', '-']
tokenized_frame_idx: ['-', 'Correctness', '-']
tokenized_fe_idx: ['-', '-', '-']

===============================
====Annotation (`annoID` = 9735)====
text: And the result is that we are educating people out of their creative capacities.
frameName: People
frameID: 278
luName: people.n
luID: 19342
lu_idx: [(40, 45, 1)]
fe_idx: [(40, 45, 'Person', 1854)]
tokenized_text: And the result is that we are educating people out of their creative capacities .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', 'people.n', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', 'People', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', 'Person', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 2202)====
text: O resultado disso é que estamos educando as pessoas para serem menos criativas.
frameName: People
frameID: 278
luName: pessoa.n
luID: 26555
lu_idx: [(44, 50, 453)]
fe_idx: [(-1, -1, 'Person', 1854)]
tokenized_text: O resultado disso é que estamos educando as pessoas para serem menos criativas .
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', 'pessoa.n', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', 'People', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 2411)====
text: You don't think of Shakespeare having a father, do you?
frameName: Awareness
frameID: 14
luName: think.v
luID: 12780
lu_idx: [(10, 14, 1)]
fe_idx: [(0, 2, 'Cognizer', 57), (31, 45, 'Content', 58), (16, 29, 'Content', 58)]
tokenized_text: You do n't think of Shakespeare having a father , do you ?
tokenized_lu_idx: ['-', '-', '-', 'think.v', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', 'Awareness', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['Cognizer', '-', '-', '-', 'Content', 'Content', 'Content', 'Content', 'Content', '-', '-', '-', '-']

====Annotation (`annoID` = 1043)====
text: Você nunca pensou que Shakespeare teve um pai, pensou?
frameName: Awareness
frameID: 14
luName: pensar.v
luID: 26304
lu_idx: [(11, 16, 453)]
fe_idx: [(18, 44, 'Content', 58), (5, 9, 'Degree', 638), (0, 3, 'Cognizer', 57)]
tokenized_text: Você nunca pensou que Shakespeare teve um pai , pensou ?
tokenized_lu_idx: ['-', '-', 'pensar.v', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', 'Awareness', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['Cognizer', 'Degree', '-', 'Content', 'Content', 'Content', 'Content', 'Content', '-', '-', '-']

===============================
====Annotation (`annoID` = 9799)====
text: And we were rather pleased about that, frankly -- 
frameName: Emotion_directed
frameID: 40
luName: pleased.a
luID: 13478
lu_idx: [(19, 25, 1)]
fe_idx: [(4, 5, 'Experiencer', 163), (12, 17, 'Degree', 1251), (27, 36, 'Stimulus', 165)]
tokenized_text: And we were rather pleased about that , frankly --
tokenized_lu_idx: ['-', '-', '-', '-', 'pleased.a', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', 'Emotion_directed', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', 'Experiencer', '-', 'Degree', '-', 'Stimulus', 'Stimulus', '-', '-', '-']

====Annotation (`annoID` = 1341)====
text: E nós ficamos bastante contentes com isso, francamente.
frameName: Emotion_directed
frameID: 40
luName: contente.a
luID: 26484
lu_idx: [(23, 31, 453)]
fe_idx: [(2, 4, 'Experiencer', 163), (-1, -1, 'State', 2577), (33, 40, 'Stimulus', 165), (-1, -1, 'Expressor', 1253), (-1, -1, 'Topic', 164), (14, 21, 'Degree', 1251)]
tokenized_text: E nós ficamos bastante contentes com isso , francamente .
tokenized_lu_idx: ['-', '-', '-', '-', 'contente.a', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', 'Emotion_directed', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', 'Experiencer', '-', 'Degree', '-', 'Stimulus', 'Stimulus', '-', '-', '-']

===============================
====Annotation (`annoID` = 10195)====
text: Because you are, aren't you?
frameName: Causation
frameID: 1
luName: because.c
luID: 12518
lu_idx: [(0, 6, 1)]
fe_idx: [(8, 14, 'Cause', 3)]
tokenized_text: Because you are , are n't you ?
tokenized_lu_idx: ['because.c', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['Causation', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', 'Cause', 'Cause', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 7313)====
text: Porque vocês são, não são?
frameName: Causation
frameID: 1
luName: porque.c
luID: 26364
lu_idx: [(0, 5, 453)]
fe_idx: [(-1, -1, 'Cause', 3), (7, 16, 'Effect', 5)]
tokenized_text: Porque vocês são , não são ?
tokenized_lu_idx: ['porque.c', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['Causation', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', 'Effect', 'Effect', 'Effect', '-', '-', '-']

===============================
====Annotation (`annoID` = 2164)====
text: There have been three themes running through the conference which are relevant to what I want to talk about.
frameName: Cardinal_numbers
frameID: 196
luName: three.num
luID: 17845
lu_idx: [(16, 20, 1)]
fe_idx: [(16, 20, 'Number', 2715), (22, 27, 'Entity', 2716)]
tokenized_text: There have been three themes running through the conference which are relevant to what I want to talk about .
tokenized_lu_idx: ['-', '-', '-', 'three.num', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', 'Cardinal_numbers', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', 'Number', 'Entity', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 1012)====
text: Existem três tópicos abordados ao longo da conferência que são relevantes para o que eu vou falar.
frameName: Cardinal_numbers
frameID: 196
luName: três.num
luID: 26291
lu_idx: [(8, 11, 453)]
fe_idx: [(-1, -1, 'Number', 2715), (13, 19, 'Entity', 2716)]
tokenized_text: Existem três tópicos abordados ao longo da conferência que são relevantes para o que eu vou falar .
tokenized_lu_idx: ['-', 'três.num', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', 'Cardinal_numbers', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', 'Entity', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 8816)====
text: Wait here.
frameName: Waiting
frameID: 690
luName: wait.v
luID: 23977
lu_idx: [(0, 3, 1)]
fe_idx: [(-1, -1, 'Protagonist', 5669), (5, 8, 'Place', 5672)]
tokenized_text: Wait here .
tokenized_lu_idx: ['wait.v', '-', '-']
tokenized_frame_idx: ['Waiting', '-', '-']
tokenized_fe_idx: ['-', 'Place', '-']

====Annotation (`annoID` = 7492)====
text: Ele disse: 'Espere aqui, já voltamos.Não vai demorar.',e eles deixaram ela sozinha.
frameName: Waiting
frameID: 690
luName: esperar.v
luID: 28545
lu_idx: [(12, 17, 453)]
fe_idx: [(-1, -1, 'Protagonist', 5669), (-1, -1, 'Expected_event', 5675), (19, 22, 'Place', 5672)]
tokenized_text: Ele disse : ' Espere aqui , já voltamos.Não vai demorar. ' , e eles deixaram ela sozinha .
tokenized_lu_idx: ['-', '-', '-', '-', 'esperar.v', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', 'Waiting', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', 'Place', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 2410)====
text: You don't think of Shakespeare having a father, do you?
frameName: Kinship
frameID: 95
luName: father.n
luID: 15670
lu_idx: [(40, 45, 1)]
fe_idx: [(40, 45, 'Alter', 413), (19, 29, 'Ego', 414)]
tokenized_text: You do n't think of Shakespeare having a father , do you ?
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', '-', 'father.n', '-', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', '-', 'Kinship', '-', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', 'Ego', '-', '-', 'Alter', '-', '-', '-', '-']

====Annotation (`annoID` = 1172)====
text: Você nunca pensou que Shakespeare teve um pai, pensou?
frameName: Kinship
frameID: 95
luName: pai.n
luID: 26361
lu_idx: [(42, 44, 453)]
fe_idx: [(-1, -1, 'Ego', 414), (-1, -1, 'Alter', 413)]
tokenized_text: Você nunca pensou que Shakespeare teve um pai , pensou ?
tokenized_lu_idx: ['-', '-', '-', '-', '-', '-', '-', 'pai.n', '-', '-', '-']
tokenized_frame_idx: ['-', '-', '-', '-', '-', '-', '-', 'Kinship', '-', '-', '-']
tokenized_fe_idx: ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']

===============================
====Annotation (`annoID` = 9631)====
text: My son didn't want to come.
frameName: Kinship
frameID: 95
luName: son.n
luID: 15672
lu_idx: [(3, 5, 1)]
fe_idx: [(0, 1, 'Ego', 414), (3, 5, 'Alter', 413)]
tokenized_text: My son did n't want to come .
tokenized_lu_idx: ['-', 'son.n', '-', '-', '-', '-', '-', '-']
tokenized_frame_idx: ['-', 'Kinship', '-', '-', '-', '-', '-', '-']
tokenized_fe_idx: ['Ego', 'Alter', '-', '-', '-', '-', '-', '-']

====Annotation (`annoID` = 1093)====
text: Meu filho não queria vir.
frameName: Kinship
frameID: 95
luName: filho.n
luID: 26385
lu_idx: [(4, 8, 453)]
fe_idx: [(0, 2, 'Alter', 413), (-1, -1, 'Relatives', 415), (-1, -1, 'Ego', 414)]
tokenized_text: Meu filho não queria vir .
tokenized_lu_idx: ['-', 'filho.n', '-', '-', '-', '-']
tokenized_frame_idx: ['-', 'Kinship', '-', '-', '-', '-']
tokenized_fe_idx: ['Alter', '-', '-', '-', '-', '-']
